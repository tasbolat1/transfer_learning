{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "CURRENT_TEST_DIR = os.getcwd()\n",
    "sys.path.append(CURRENT_TEST_DIR + \"/../../../slayerPytorch/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fec29b2e6d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import slayerSNN as snn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dtw import dtw, accelerated_dtw\n",
    "from numpy.linalg import norm\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load('auxiliaries/electrodes.npy')\n",
    "X = torch.load('../BioTac_Icub_data/Bio_all.pt').permute(0,2,1).numpy()\n",
    "X_i = torch.load('../BioTac_Icub_data/ICUB_all.pt').reshape([1000, 60, 75]).numpy()\n",
    "#Y = np.load('auxiliaries/labels.npy')\n",
    "Y = np.load('../BioTac_Icub_data/ICUB_all_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 19, 150), (1000,), (1000, 60, 75))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, X_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohe(_Y):\n",
    "    target_class = np.zeros([_Y.shape[0], 20])\n",
    "    for i in range(target_class.shape[0]):\n",
    "        target_class[i, int(_Y[i])] = 1\n",
    "    return target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], 1, 1, X.shape[-1])\n",
    "X_i = X_i.reshape(X_i.shape[0], X_i.shape[1], 1, 1, X_i.shape[-1])\n",
    "indices = np.arange(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, ind_train, ind_test = train_test_split(X, Y, indices, test_size=0.30, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([700, 19, 1, 1, 150]),\n",
       " torch.Size([700]),\n",
       " torch.Size([700, 20, 1, 1, 1]),\n",
       " torch.Size([700, 60, 1, 1, 75]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "target_class_train = torch.FloatTensor(get_ohe(y_train).reshape(-1, 20, 1, 1, 1))\n",
    "    \n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "target_class_test= torch.FloatTensor(get_ohe(y_test).reshape(-1, 20, 1, 1, 1))\n",
    "\n",
    "X_train_i= torch.FloatTensor(X_i[ind_train])\n",
    "X_test_i = torch.FloatTensor(X_i[ind_test])\n",
    "\n",
    "X_train.shape, y_train.shape, target_class_train.shape, X_train_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"neuron\": {\n",
    "        \"type\": \"SRMALPHA\",\n",
    "        \"theta\": 5, # 10\n",
    "        \"tauSr\": 10.0,\n",
    "        \"tauRef\": 2.0,\n",
    "        \"scaleRef\": 2,\n",
    "        \"tauRho\": 1,\n",
    "        \"scaleRho\": 1,\n",
    "    },\n",
    "    \"simulation\": {\"Ts\": 1.0, \"tSample\": 150, \"nSample\": 1},\n",
    "    \"training\": {\n",
    "        \"error\": {\n",
    "            \"type\": \"NumSpikes\",  # \"NumSpikes\" or \"ProbSpikes\"\n",
    "            \"probSlidingWin\": 20,  # only valid for ProbSpikes\n",
    "            \"tgtSpikeRegion\": {  # valid for NumSpikes and ProbSpikes\n",
    "                \"start\": 0,\n",
    "                \"stop\": 150,\n",
    "            },\n",
    "            \"tgtSpikeCount\": {True: 120, False: 20},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "params2 = {\n",
    "    \"neuron\": {\n",
    "        \"type\": \"SRMALPHA\",\n",
    "        \"theta\": 5, # 10\n",
    "        \"tauSr\": 10.0,\n",
    "        \"tauRef\": 2.0,\n",
    "        \"scaleRef\": 2,\n",
    "        \"tauRho\": 1,\n",
    "        \"scaleRho\": 1,\n",
    "    },\n",
    "    \"simulation\": {\"Ts\": 1.0, \"tSample\": 150, \"nSample\": 1},\n",
    "    \"training\": {\n",
    "        \"error\": {\n",
    "            \"type\": \"SpikeTime\",  # \"NumSpikes\" or \"ProbSpikes\"\n",
    "            \"probSlidingWin\": 20,  # only valid for ProbSpikes\n",
    "            \"tgtSpikeRegion\": {  # valid for NumSpikes and ProbSpikes\n",
    "                \"start\": 0,\n",
    "                \"stop\": 150,\n",
    "            },\n",
    "            \"tgtSpikeCount\": {True: 120, False: 20},\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train_i, X_train, target_class_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True,batch_size=8)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_i, X_test, target_class_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioAEMLP(torch.nn.Module):\n",
    "    def __init__(self, params, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(BioAEMLP, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.slayer = snn.layer(params[\"neuron\"], params[\"simulation\"])\n",
    "        self.fc1 = self.slayer.dense(input_size, hidden_size1)\n",
    "        self.fc2 = self.slayer.dense(hidden_size1, hidden_size2)\n",
    "        self.fc3 = self.slayer.dense(hidden_size2, output_size)\n",
    "        \n",
    "        self.fc_decoder1 = self.slayer.dense(hidden_size2, 30)\n",
    "        self.fc_decoder2 = self.slayer.dense(30, input_size)\n",
    "\n",
    "    def get_spike(self, inp):\n",
    "        return self.slayer.spike(inp)\n",
    "    \n",
    "    def forward(self, spike_input):\n",
    "        spike_1 = self.slayer.spike(self.slayer.psp(self.fc1(spike_input)))\n",
    "        spike_2 = self.slayer.spike(self.slayer.psp(self.fc2(spike_1)))\n",
    "        spike_output = self.slayer.spike(self.slayer.psp(self.fc3(spike_2)))\n",
    "        \n",
    "        spike_hat1 = self.slayer.spike(self.slayer.psp(self.fc_decoder1(spike_2)))\n",
    "        spike_hat2 = self.slayer.spike(self.slayer.psp(self.fc_decoder2(spike_hat1)))\n",
    "        \n",
    "        return spike_output, spike_hat2, spike_2, spike_hat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "net = BioAEMLP(params, 19, 50, 50, 20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = snn.loss(params).to(device)\n",
    "error2 = snn.loss(params2).to(device)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  --------------------------\n",
      "Train loss (all, class, reg): 136.07010890415737 0.26728572300502235 0.21336587053571432\n",
      "Train accuracy: 0.13428571428571429\n",
      "Test loss (all, class, reg): 88.65200327555338 0.6181667073567708 0.7240790625000001\n",
      "Test accuracy: 0.17333333333333334\n",
      "Epoch:  10  --------------------------\n",
      "Train loss (all, class, reg): 41.606898345947265 0.10999524797712054 0.08646699776785714\n",
      "Train accuracy: 0.5485714285714286\n",
      "Test loss (all, class, reg): 40.51021977742513 0.3091333516438802 0.159544375\n",
      "Test accuracy: 0.5466666666666666\n",
      "Epoch:  20  --------------------------\n",
      "Train loss (all, class, reg): 32.891622249058315 0.12799047197614397 0.06027156808035715\n",
      "Train accuracy: 0.6714285714285714\n",
      "Test loss (all, class, reg): 32.28609085083008 0.3380000305175781 0.12591208333333334\n",
      "Test accuracy: 0.64\n",
      "Epoch:  30  --------------------------\n",
      "Train loss (all, class, reg): 28.502526648385185 0.08157618931361607 0.055209531250000006\n",
      "Train accuracy: 0.7528571428571429\n",
      "Test loss (all, class, reg): 28.460005137125652 0.317933349609375 0.10360097005208334\n",
      "Test accuracy: 0.7166666666666667\n",
      "Epoch:  40  --------------------------\n",
      "Train loss (all, class, reg): 25.71215787615095 0.12642381940569197 0.03714346819196429\n",
      "Train accuracy: 0.7914285714285715\n",
      "Test loss (all, class, reg): 25.745248870849608 0.21343332926432293 0.15779428385416666\n",
      "Test accuracy: 0.7733333333333333\n",
      "Epoch:  50  --------------------------\n",
      "Train loss (all, class, reg): 23.664088200160435 0.11698571341378348 0.03150266741071429\n",
      "Train accuracy: 0.83\n",
      "Test loss (all, class, reg): 23.991945088704426 0.13304444630940757 0.08809506510416666\n",
      "Test accuracy: 0.7633333333333333\n",
      "Epoch:  60  --------------------------\n",
      "Train loss (all, class, reg): 22.33058888026646 0.07656666346958706 0.03264308035714286\n",
      "Train accuracy: 0.8414285714285714\n",
      "Test loss (all, class, reg): 22.228652674357097 0.13247777303059896 0.09250220052083333\n",
      "Test accuracy: 0.8233333333333334\n",
      "Epoch:  70  --------------------------\n",
      "Train loss (all, class, reg): 21.155679168701173 0.08196190970284598 0.028382940848214286\n",
      "Train accuracy: 0.8657142857142858\n",
      "Test loss (all, class, reg): 21.185655263264973 0.18227776845296223 0.07182830729166666\n",
      "Test accuracy: 0.82\n",
      "Epoch:  80  --------------------------\n",
      "Train loss (all, class, reg): 20.068568801879884 0.11382857186453683 0.030556702008928575\n",
      "Train accuracy: 0.88\n",
      "Test loss (all, class, reg): 20.309490458170572 0.2612444559733073 0.07000204427083334\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  90  --------------------------\n",
      "Train loss (all, class, reg): 19.279754878452845 0.06230476379394531 0.042136729910714286\n",
      "Train accuracy: 0.8971428571428571\n",
      "Test loss (all, class, reg): 20.14772026062012 0.22828887939453124 0.06905046875\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  100  --------------------------\n",
      "Train loss (all, class, reg): 18.6080999646868 0.10660476684570312 0.0342610546875\n",
      "Train accuracy: 0.9042857142857142\n",
      "Test loss (all, class, reg): 18.896519241333007 0.3086555480957031 0.07322529947916667\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  110  --------------------------\n",
      "Train loss (all, class, reg): 17.760868268694196 0.0811952372959682 0.040436975446428575\n",
      "Train accuracy: 0.9\n",
      "Test loss (all, class, reg): 18.69095120747884 0.13966667175292968 0.08023149739583334\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  120  --------------------------\n",
      "Train loss (all, class, reg): 17.2576804460798 0.031980953216552734 0.023345615234375\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss (all, class, reg): 17.766663869222004 0.16646666208902994 0.09263227213541668\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  130  --------------------------\n",
      "Train loss (all, class, reg): 16.817985567365373 0.07168571472167969 0.026602466517857144\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss (all, class, reg): 17.45463124593099 0.10188888549804688 0.06096216145833334\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  140  --------------------------\n",
      "Train loss (all, class, reg): 16.37465309688023 0.05602857317243304 0.03510433035714286\n",
      "Train accuracy: 0.9257142857142857\n",
      "Test loss (all, class, reg): 16.96583911895752 0.08267777760823568 0.06542078125\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  150  --------------------------\n",
      "Train loss (all, class, reg): 15.76756090436663 0.04790952954973493 0.02333399832589286\n",
      "Train accuracy: 0.9271428571428572\n",
      "Test loss (all, class, reg): 17.007313690185548 0.14711111704508464 0.0500693359375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  160  --------------------------\n",
      "Train loss (all, class, reg): 15.41295555114746 0.06313333783830916 0.034610909598214286\n",
      "Train accuracy: 0.93\n",
      "Test loss (all, class, reg): 16.404924392700195 0.1481000010172526 0.06420481119791667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  170  --------------------------\n",
      "Train loss (all, class, reg): 15.085770481654576 0.09544761657714844 0.022122645089285714\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 15.887975641886394 0.062222226460774736 0.04765954427083333\n",
      "Test accuracy: 0.91\n",
      "Epoch:  180  --------------------------\n",
      "Train loss (all, class, reg): 14.784647505623953 0.03175237928118024 0.02876740513392857\n",
      "Train accuracy: 0.93\n",
      "Test loss (all, class, reg): 15.51689961751302 0.08448888778686524 0.08622428385416668\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  190  --------------------------\n",
      "Train loss (all, class, reg): 14.431414217267717 0.07582857404436384 0.02457595982142857\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss (all, class, reg): 15.295928751627605 0.05504444122314453 0.08245217447916667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  200  --------------------------\n",
      "Train loss (all, class, reg): 14.121228245326451 0.07122380937848773 0.027845295758928575\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 15.18445805867513 0.1071999994913737 0.06981414062499999\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  210  --------------------------\n",
      "Train loss (all, class, reg): 13.812517078944614 0.04015238080705915 0.04021797991071428\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 14.82702491760254 0.06173333485921224 0.066342421875\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  220  --------------------------\n",
      "Train loss (all, class, reg): 13.564270117623465 0.06385714394705636 0.035148878348214285\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 14.525926691691081 0.11324445088704427 0.07019854817708333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  230  --------------------------\n",
      "Train loss (all, class, reg): 13.296745518275669 0.03278571537562779 0.025744422433035714\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 14.500354804992675 0.06583333333333333 0.05663539713541667\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  240  --------------------------\n",
      "Train loss (all, class, reg): 13.07272203717913 0.02401904787336077 0.025736082589285714\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 14.191143493652344 0.12604443868001303 0.06828147135416666\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  250  --------------------------\n",
      "Train loss (all, class, reg): 12.859592426845005 0.02905238015311105 0.0280258984375\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 13.794386825561524 0.170477778116862 0.06716083333333334\n",
      "Test accuracy: 0.93\n",
      "Epoch:  260  --------------------------\n",
      "Train loss (all, class, reg): 12.595898197719029 0.05699047633579799 0.026117806919642855\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss (all, class, reg): 13.667172203063965 0.09467778523763021 0.06310288411458334\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  270  --------------------------\n",
      "Train loss (all, class, reg): 12.398583292279925 0.06136666434151786 0.03563449497767857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 13.779549306233724 0.05129999796549479 0.08330201822916666\n",
      "Test accuracy: 0.92\n",
      "Epoch:  280  --------------------------\n",
      "Train loss (all, class, reg): 12.2367291532244 0.07582857404436384 0.03402702287946428\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 13.806659901936849 0.09755555470784505 0.049234560546875\n",
      "Test accuracy: 0.9333333333333333\n",
      "Epoch:  290  --------------------------\n",
      "Train loss (all, class, reg): 11.998603177751814 0.031209523337227957 0.02550474888392857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 13.077723846435546 0.11037776947021484 0.0610368359375\n",
      "Test accuracy: 0.9333333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  300  --------------------------\n",
      "Train loss (all, class, reg): 11.908030951363699 0.030109522683279856 0.024269545200892858\n",
      "Train accuracy: 0.9614285714285714\n",
      "Test loss (all, class, reg): 12.919648081461588 0.047577775319417315 0.07116599609375\n",
      "Test accuracy: 0.9233333333333333\n",
      "Epoch:  310  --------------------------\n",
      "Train loss (all, class, reg): 11.773166313171387 0.030171429770333425 0.021985132533482145\n",
      "Train accuracy: 0.96\n",
      "Test loss (all, class, reg): 13.033081385294595 0.19042221069335938 0.0549683984375\n",
      "Test accuracy: 0.9366666666666666\n",
      "Epoch:  320  --------------------------\n",
      "Train loss (all, class, reg): 11.589767761230469 0.06580475943429129 0.029164419642857143\n",
      "Train accuracy: 0.9614285714285714\n",
      "Test loss (all, class, reg): 13.096604919433593 0.046288890838623045 0.07885377604166667\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  330  --------------------------\n",
      "Train loss (all, class, reg): 11.407644440787179 0.042738097054617744 0.018437294921875\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 13.115950851440429 0.13804443359375 0.06366373697916666\n",
      "Test accuracy: 0.9333333333333333\n",
      "Epoch:  340  --------------------------\n",
      "Train loss (all, class, reg): 11.29526017325265 0.04527618953159877 0.02616422433035714\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 12.389487660725912 0.10813334147135417 0.0588655078125\n",
      "Test accuracy: 0.95\n",
      "Epoch:  350  --------------------------\n",
      "Train loss (all, class, reg): 11.212930605752128 0.015066667284284319 0.018831116071428573\n",
      "Train accuracy: 0.9642857142857143\n",
      "Test loss (all, class, reg): 12.255112101236978 0.10728889465332031 0.07120951822916667\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  360  --------------------------\n",
      "Train loss (all, class, reg): 11.097336621965681 0.02589047568184989 0.017843702566964284\n",
      "Train accuracy: 0.96\n",
      "Test loss (all, class, reg): 12.23987033843994 0.07658889134724935 0.043638574218750004\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  370  --------------------------\n",
      "Train loss (all, class, reg): 10.971937195914132 0.10433333260672432 0.021978032924107143\n",
      "Train accuracy: 0.9657142857142857\n",
      "Test loss (all, class, reg): 12.205479329427083 0.16890000661214194 0.061852447916666664\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  380  --------------------------\n",
      "Train loss (all, class, reg): 10.836313863481793 0.028366666521344865 0.033261397879464284\n",
      "Train accuracy: 0.9628571428571429\n",
      "Test loss (all, class, reg): 12.101538441975912 0.10984443664550782 0.04830716145833334\n",
      "Test accuracy: 0.9333333333333333\n",
      "Epoch:  390  --------------------------\n",
      "Train loss (all, class, reg): 10.717932799203055 0.04687143053327288 0.01996775111607143\n",
      "Train accuracy: 0.9614285714285714\n",
      "Test loss (all, class, reg): 12.016030909220378 0.10707776387532553 0.059347285156250006\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  400  --------------------------\n",
      "Train loss (all, class, reg): 10.698466617039271 0.08527618408203125 0.03658881696428572\n",
      "Train accuracy: 0.9614285714285714\n",
      "Test loss (all, class, reg): 11.969536628723144 0.07439999898274739 0.04715490885416667\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  410  --------------------------\n",
      "Train loss (all, class, reg): 10.575523959568569 0.04746666499546596 0.026079199218749998\n",
      "Train accuracy: 0.9628571428571429\n",
      "Test loss (all, class, reg): 11.808676617940266 0.10302222569783528 0.07465388671874999\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  420  --------------------------\n",
      "Train loss (all, class, reg): 10.532238202776227 0.04496666499546596 0.022975669642857143\n",
      "Train accuracy: 0.9685714285714285\n",
      "Test loss (all, class, reg): 11.724889742533366 0.08036666870117187 0.06433798177083333\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  430  --------------------------\n",
      "Train loss (all, class, reg): 10.340395371573312 0.030861903599330356 0.021618724888392858\n",
      "Train accuracy: 0.9614285714285714\n",
      "Test loss (all, class, reg): 11.998735186258951 0.0645111083984375 0.09657973958333334\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  440  --------------------------\n",
      "Train loss (all, class, reg): 10.368749520438058 0.017476190839494976 0.027828750000000003\n",
      "Train accuracy: 0.9714285714285714\n",
      "Test loss (all, class, reg): 11.58131233215332 0.09204444885253907 0.05730819010416667\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  450  --------------------------\n",
      "Train loss (all, class, reg): 10.250634836469377 0.02958571297781808 0.021073297991071428\n",
      "Train accuracy: 0.9671428571428572\n",
      "Test loss (all, class, reg): 11.965519752502441 0.0729444440205892 0.06165397786458333\n",
      "Test accuracy: 0.95\n",
      "Epoch:  460  --------------------------\n",
      "Train loss (all, class, reg): 10.203017169407437 0.05430952344621931 0.02245296875\n",
      "Train accuracy: 0.9614285714285714\n",
      "Test loss (all, class, reg): 11.688996086120605 0.08607777913411459 0.06975227864583333\n",
      "Test accuracy: 0.9366666666666666\n",
      "Epoch:  470  --------------------------\n",
      "Train loss (all, class, reg): 10.109303588867187 0.016628571919032505 0.020324044363839285\n",
      "Train accuracy: 0.97\n",
      "Test loss (all, class, reg): 11.26987840016683 0.11491109212239584 0.07269418619791668\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  480  --------------------------\n",
      "Train loss (all, class, reg): 9.980957167489189 0.020652381352015903 0.03163751116071429\n",
      "Train accuracy: 0.9671428571428572\n",
      "Test loss (all, class, reg): 11.992412230173747 0.031899998982747396 0.06557431640625\n",
      "Test accuracy: 0.94\n",
      "Epoch:  490  --------------------------\n",
      "Train loss (all, class, reg): 9.929464067731585 0.049566672188895086 0.022015583147321428\n",
      "Train accuracy: 0.9657142857142857\n",
      "Test loss (all, class, reg): 11.329706013997395 0.1718999989827474 0.041941328125\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  500  --------------------------\n",
      "Train loss (all, class, reg): 9.872931423187255 0.022533332279750278 0.020133823939732145\n",
      "Train accuracy: 0.9642857142857143\n",
      "Test loss (all, class, reg): 11.395608952840169 0.06691111246744792 0.06465729166666667\n",
      "Test accuracy: 0.95\n",
      "Epoch:  510  --------------------------\n",
      "Train loss (all, class, reg): 9.774477381025042 0.06228571210588728 0.024340814732142856\n",
      "Train accuracy: 0.97\n",
      "Test loss (all, class, reg): 11.18776632944743 0.0642555554707845 0.06846908854166667\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  520  --------------------------\n",
      "Train loss (all, class, reg): 9.781715932573592 0.02623333249773298 0.025863984375\n",
      "Train accuracy: 0.9714285714285714\n",
      "Test loss (all, class, reg): 11.087021789550782 0.05891111373901367 0.05902697916666667\n",
      "Test accuracy: 0.94\n",
      "Epoch:  530  --------------------------\n",
      "Train loss (all, class, reg): 9.686642058236258 0.01465238162449428 0.021456085379464286\n",
      "Train accuracy: 0.9714285714285714\n",
      "Test loss (all, class, reg): 10.925081634521485 0.028966668446858725 0.048784153645833335\n",
      "Test accuracy: 0.95\n",
      "Epoch:  540  --------------------------\n",
      "Train loss (all, class, reg): 9.662639933994837 0.014752381188528878 0.022016039341517857\n",
      "Train accuracy: 0.9742857142857143\n",
      "Test loss (all, class, reg): 10.970952835083008 0.12136667887369791 0.06303002604166667\n",
      "Test accuracy: 0.95\n",
      "Epoch:  550  --------------------------\n",
      "Train loss (all, class, reg): 9.57134007045201 0.03246666499546596 0.027052505580357145\n",
      "Train accuracy: 0.97\n",
      "Test loss (all, class, reg): 11.010633455912272 0.1260333506266276 0.06394416666666668\n",
      "Test accuracy: 0.9366666666666666\n",
      "Epoch:  560  --------------------------\n",
      "Train loss (all, class, reg): 9.518974816458567 0.020076189041137695 0.018517243303571428\n",
      "Train accuracy: 0.9714285714285714\n",
      "Test loss (all, class, reg): 11.325857836405437 0.0948555564880371 0.08720647786458334\n",
      "Test accuracy: 0.9366666666666666\n",
      "Epoch:  570  --------------------------\n",
      "Train loss (all, class, reg): 9.503977271488735 0.011600001198904855 0.025404983258928572\n",
      "Train accuracy: 0.9657142857142857\n",
      "Test loss (all, class, reg): 10.831401430765787 0.24072219848632812 0.056581022135416666\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  580  --------------------------\n",
      "Train loss (all, class, reg): 9.443039883204868 0.015038095201764788 0.030264614955357143\n",
      "Train accuracy: 0.9685714285714285\n",
      "Test loss (all, class, reg): 10.768831825256347 0.13053333282470703 0.048724055989583334\n",
      "Test accuracy: 0.95\n",
      "Epoch:  590  --------------------------\n",
      "Train loss (all, class, reg): 9.368101583208357 0.015028572082519532 0.026286506696428572\n",
      "Train accuracy: 0.9771428571428571\n",
      "Test loss (all, class, reg): 10.650548922220866 0.07293333689371745 0.06986514322916666\n",
      "Test accuracy: 0.9466666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  600  --------------------------\n",
      "Train loss (all, class, reg): 9.322371515546527 0.040680953434535434 0.039871124441964285\n",
      "Train accuracy: 0.9757142857142858\n",
      "Test loss (all, class, reg): 10.825257428487141 0.2753111267089844 0.050840234375\n",
      "Test accuracy: 0.95\n",
      "Epoch:  610  --------------------------\n",
      "Train loss (all, class, reg): 9.318598572867257 0.0364428574698312 0.03753232700892858\n",
      "Train accuracy: 0.9714285714285714\n",
      "Test loss (all, class, reg): 10.949124857584636 0.04831111272176107 0.041257086588541665\n",
      "Test accuracy: 0.94\n",
      "Epoch:  620  --------------------------\n",
      "Train loss (all, class, reg): 9.205428913661413 0.022771427971976142 0.022319796316964284\n",
      "Train accuracy: 0.9771428571428571\n",
      "Test loss (all, class, reg): 11.032321688334147 0.04688888549804687 0.04532494791666667\n",
      "Test accuracy: 0.95\n",
      "Epoch:  630  --------------------------\n",
      "Train loss (all, class, reg): 9.084408016204835 0.013623809814453125 0.024067042410714286\n",
      "Train accuracy: 0.9757142857142858\n",
      "Test loss (all, class, reg): 10.749394137064616 0.11100001017252605 0.0931303125\n",
      "Test accuracy: 0.95\n",
      "Epoch:  640  --------------------------\n",
      "Train loss (all, class, reg): 9.105193416050502 0.025742857796805244 0.02238184012276786\n",
      "Train accuracy: 0.9742857142857143\n",
      "Test loss (all, class, reg): 10.772771555582683 0.06707777659098307 0.050272389322916666\n",
      "Test accuracy: 0.95\n",
      "Epoch:  650  --------------------------\n",
      "Train loss (all, class, reg): 9.033619771684918 0.023899999346051897 0.028295047433035715\n",
      "Train accuracy: 0.9771428571428571\n",
      "Test loss (all, class, reg): 10.954356346130371 0.08027777353922526 0.053694765624999995\n",
      "Test accuracy: 0.9633333333333334\n",
      "Epoch:  660  --------------------------\n",
      "Train loss (all, class, reg): 9.024020832606725 0.03214761734008789 0.027997759486607144\n",
      "Train accuracy: 0.9757142857142858\n",
      "Test loss (all, class, reg): 10.461829058329265 0.05512222290039062 0.05758472656250001\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  670  --------------------------\n",
      "Train loss (all, class, reg): 9.005847336905344 0.025966668810163226 0.025827500000000003\n",
      "Train accuracy: 0.9728571428571429\n",
      "Test loss (all, class, reg): 10.689200274149577 0.07445555369059245 0.07441030598958334\n",
      "Test accuracy: 0.9366666666666666\n",
      "Epoch:  680  --------------------------\n",
      "Train loss (all, class, reg): 8.97976330620902 0.008866667066301619 0.02270097935267857\n",
      "Train accuracy: 0.9742857142857143\n",
      "Test loss (all, class, reg): 10.57762082417806 0.08547776540120443 0.051153919270833334\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  690  --------------------------\n",
      "Train loss (all, class, reg): 8.892886107308524 0.018752380098615375 0.029252974330357142\n",
      "Train accuracy: 0.9757142857142858\n",
      "Test loss (all, class, reg): 10.738621419270833 0.07133333206176758 0.041790182291666665\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  700  --------------------------\n",
      "Train loss (all, class, reg): 8.841365378243582 0.022914287022181918 0.024928504464285715\n",
      "Train accuracy: 0.9757142857142858\n",
      "Test loss (all, class, reg): 10.736846656799317 0.04082221984863281 0.053138108723958334\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  710  --------------------------\n",
      "Train loss (all, class, reg): 8.770575539725167 0.024985716683523996 0.03729894252232143\n",
      "Train accuracy: 0.9742857142857143\n",
      "Test loss (all, class, reg): 10.369292011260987 0.03293333053588867 0.06599148437499999\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  720  --------------------------\n",
      "Train loss (all, class, reg): 8.779882828848702 0.018780952181134906 0.016771784319196428\n",
      "Train accuracy: 0.9785714285714285\n",
      "Test loss (all, class, reg): 10.54444403330485 0.0631000010172526 0.03848730794270833\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  730  --------------------------\n",
      "Train loss (all, class, reg): 8.71304289681571 0.027609519958496094 0.019903106863839285\n",
      "Train accuracy: 0.9814285714285714\n",
      "Test loss (all, class, reg): 10.597537994384766 0.0441444460550944 0.04770031575520833\n",
      "Test accuracy: 0.9366666666666666\n",
      "Epoch:  740  --------------------------\n",
      "Train loss (all, class, reg): 8.669253760746548 0.01145238058907645 0.029416004464285713\n",
      "Train accuracy: 0.9785714285714285\n",
      "Test loss (all, class, reg): 10.330647150675455 0.023877776463826498 0.06469463541666666\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  750  --------------------------\n",
      "Train loss (all, class, reg): 8.71009325844901 0.012542856761387416 0.02085376674107143\n",
      "Train accuracy: 0.9771428571428571\n",
      "Test loss (all, class, reg): 10.287914924621582 0.01752222220102946 0.05819246093750001\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  760  --------------------------\n",
      "Train loss (all, class, reg): 8.622552013397216 0.011342857224600655 0.023194567522321432\n",
      "Train accuracy: 0.9785714285714285\n",
      "Test loss (all, class, reg): 10.298121007283529 0.2539666748046875 0.051490703124999995\n",
      "Test accuracy: 0.95\n",
      "Epoch:  770  --------------------------\n",
      "Train loss (all, class, reg): 8.651682167053222 0.02380476270403181 0.021558530970982145\n",
      "Train accuracy: 0.9757142857142858\n",
      "Test loss (all, class, reg): 10.931727511088054 0.03053333282470703 0.09343143880208334\n",
      "Test accuracy: 0.9366666666666666\n",
      "Epoch:  780  --------------------------\n",
      "Train loss (all, class, reg): 8.60265087400164 0.019128570556640623 0.020033331473214285\n",
      "Train accuracy: 0.9728571428571429\n",
      "Test loss (all, class, reg): 10.285784975687664 0.047611109415690106 0.052147731119791665\n",
      "Test accuracy: 0.95\n",
      "Epoch:  790  --------------------------\n",
      "Train loss (all, class, reg): 8.478039114815848 0.02345238276890346 0.03240267578125\n",
      "Train accuracy: 0.98\n",
      "Test loss (all, class, reg): 10.231825536092122 0.06993333180745442 0.051844088541666666\n",
      "Test accuracy: 0.95\n",
      "Epoch:  800  --------------------------\n",
      "Train loss (all, class, reg): 8.49418815612793 0.01775714329310826 0.024092977120535715\n",
      "Train accuracy: 0.9828571428571429\n",
      "Test loss (all, class, reg): 10.185016657511394 0.02947778065999349 0.0604469921875\n",
      "Test accuracy: 0.95\n",
      "Epoch:  810  --------------------------\n",
      "Train loss (all, class, reg): 8.441403416224889 0.021476191111973353 0.03124830357142857\n",
      "Train accuracy: 0.98\n",
      "Test loss (all, class, reg): 10.19584186553955 0.047000001271565756 0.063093515625\n",
      "Test accuracy: 0.95\n",
      "Epoch:  820  --------------------------\n",
      "Train loss (all, class, reg): 8.430116664341519 0.013090475627354213 0.017390354352678574\n",
      "Train accuracy: 0.9742857142857143\n",
      "Test loss (all, class, reg): 10.228602282206218 0.1109222157796224 0.05667139322916667\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  830  --------------------------\n",
      "Train loss (all, class, reg): 8.346139913286482 0.05224761962890625 0.025825753348214287\n",
      "Train accuracy: 0.9742857142857143\n",
      "Test loss (all, class, reg): 10.283496729532878 0.12844444274902345 0.04448286783854167\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  840  --------------------------\n",
      "Train loss (all, class, reg): 8.340260799952915 0.011914285932268415 0.041779737723214284\n",
      "Train accuracy: 0.9828571428571429\n",
      "Test loss (all, class, reg): 10.259264068603516 0.06384445190429687 0.06255830729166667\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  850  --------------------------\n",
      "Train loss (all, class, reg): 8.343530341557093 0.016195237295968192 0.021564582868303574\n",
      "Train accuracy: 0.9771428571428571\n",
      "Test loss (all, class, reg): 10.093949279785157 0.061122220357259116 0.06026895833333333\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  860  --------------------------\n",
      "Train loss (all, class, reg): 8.339733428955078 0.00857619081224714 0.03423959821428571\n",
      "Train accuracy: 0.9785714285714285\n",
      "Test loss (all, class, reg): 10.019752578735352 0.08061111450195313 0.06488048177083333\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  870  --------------------------\n",
      "Train loss (all, class, reg): 8.231066823686872 0.042952382223946706 0.023603741629464287\n",
      "Train accuracy: 0.98\n",
      "Test loss (all, class, reg): 10.330400733947753 0.1296444320678711 0.06728379557291668\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  880  --------------------------\n",
      "Train loss (all, class, reg): 8.280814882005965 0.01642381123134068 0.022657546037946428\n",
      "Train accuracy: 0.98\n",
      "Test loss (all, class, reg): 9.99580181757609 0.04147777557373047 0.053476923828125\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  890  --------------------------\n",
      "Train loss (all, class, reg): 8.202237494332449 0.05279523577008929 0.02437212890625\n",
      "Train accuracy: 0.98\n",
      "Test loss (all, class, reg): 9.891084632873536 0.03256666819254557 0.04798242838541667\n",
      "Test accuracy: 0.9466666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  900  --------------------------\n",
      "Train loss (all, class, reg): 8.1391697038923 0.012114285060337612 0.020749566127232145\n",
      "Train accuracy: 0.9857142857142858\n",
      "Test loss (all, class, reg): 10.327837740580241 0.11664442698160807 0.054081360677083336\n",
      "Test accuracy: 0.9366666666666666\n",
      "Epoch:  910  --------------------------\n",
      "Train loss (all, class, reg): 8.073117997305733 0.037257145472935266 0.028139642857142856\n",
      "Train accuracy: 0.9828571428571429\n",
      "Test loss (all, class, reg): 10.290081837972005 0.05196666717529297 0.0772002734375\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  920  --------------------------\n",
      "Train loss (all, class, reg): 8.037932112557547 0.07421904972621372 0.026395309709821426\n",
      "Train accuracy: 0.9814285714285714\n",
      "Test loss (all, class, reg): 10.206868591308593 0.023577775955200195 0.09250143229166667\n",
      "Test accuracy: 0.95\n",
      "Epoch:  930  --------------------------\n",
      "Train loss (all, class, reg): 8.059851330348424 0.03410952431815011 0.018162455357142858\n",
      "Train accuracy: 0.9828571428571429\n",
      "Test loss (all, class, reg): 10.001974182128906 0.08643332799275716 0.06902854166666667\n",
      "Test accuracy: 0.95\n",
      "Epoch:  940  --------------------------\n",
      "Train loss (all, class, reg): 8.02046008518764 0.04249523707798549 0.01871948939732143\n",
      "Train accuracy: 0.9814285714285714\n",
      "Test loss (all, class, reg): 10.11082046508789 0.07517777760823567 0.06511778645833334\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  950  --------------------------\n",
      "Train loss (all, class, reg): 7.993028815133231 0.009000000272478376 0.033201484375\n",
      "Train accuracy: 0.98\n",
      "Test loss (all, class, reg): 9.858032849629721 0.16072222391764324 0.046561669921875\n",
      "Test accuracy: 0.95\n",
      "Epoch:  960  --------------------------\n",
      "Train loss (all, class, reg): 7.981339705330985 0.00850952420915876 0.03378740234375\n",
      "Train accuracy: 0.9785714285714285\n",
      "Test loss (all, class, reg): 9.865607045491537 0.08736666361490886 0.06726537760416666\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  970  --------------------------\n",
      "Train loss (all, class, reg): 7.892167554582868 0.017690476008823938 0.02359923270089286\n",
      "Train accuracy: 0.9871428571428571\n",
      "Test loss (all, class, reg): 9.973722400665283 0.035588887532552085 0.05681783203125001\n",
      "Test accuracy: 0.95\n",
      "Epoch:  980  --------------------------\n",
      "Train loss (all, class, reg): 7.8678760310581755 0.017361905234200614 0.0239953515625\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 9.85946647644043 0.14975555419921874 0.06631493489583333\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  990  --------------------------\n",
      "Train loss (all, class, reg): 7.846791043962751 0.007138094902038574 0.02936862723214286\n",
      "Train accuracy: 0.9857142857142858\n",
      "Test loss (all, class, reg): 10.039371299743653 0.0686555544535319 0.051683977864583334\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1000  --------------------------\n",
      "Train loss (all, class, reg): 7.817109407697405 0.01933333260672433 0.01847029575892857\n",
      "Train accuracy: 0.9885714285714285\n",
      "Test loss (all, class, reg): 9.825199279785156 0.07342222213745117 0.07538424479166667\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1010  --------------------------\n",
      "Train loss (all, class, reg): 7.7243286296299525 0.05774761199951172 0.022024949776785714\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 9.701051559448242 0.06044443766276042 0.06181619791666667\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1020  --------------------------\n",
      "Train loss (all, class, reg): 7.720327660696847 0.010895238603864398 0.04163615792410714\n",
      "Train accuracy: 0.9885714285714285\n",
      "Test loss (all, class, reg): 9.89184014638265 0.06654444376627604 0.07989975911458334\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  1030  --------------------------\n",
      "Train loss (all, class, reg): 7.727910769326346 0.0211000006539481 0.01760368582589286\n",
      "Train accuracy: 0.9885714285714285\n",
      "Test loss (all, class, reg): 9.632734038035075 0.027677777608235678 0.055469199218749994\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  1040  --------------------------\n",
      "Train loss (all, class, reg): 7.652045522417341 0.01632857186453683 0.022193042689732143\n",
      "Train accuracy: 0.9914285714285714\n",
      "Test loss (all, class, reg): 9.865099067687987 0.04660000165303548 0.05814879557291667\n",
      "Test accuracy: 0.9366666666666666\n",
      "Epoch:  1050  --------------------------\n",
      "Train loss (all, class, reg): 7.66578056880406 0.03624285561697824 0.029443487723214288\n",
      "Train accuracy: 0.9857142857142858\n",
      "Test loss (all, class, reg): 9.794943186442056 0.03523333549499512 0.060676959635416666\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  1060  --------------------------\n",
      "Train loss (all, class, reg): 7.680999968392508 0.014423809051513671 0.028108080357142858\n",
      "Train accuracy: 0.9857142857142858\n",
      "Test loss (all, class, reg): 9.955211906433105 0.057477779388427734 0.06301723307291666\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1070  --------------------------\n",
      "Train loss (all, class, reg): 7.5813893699646 0.010366666657584055 0.022490178571428574\n",
      "Train accuracy: 0.9871428571428571\n",
      "Test loss (all, class, reg): 9.584366010030111 0.11604445139567057 0.05669525390625\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1080  --------------------------\n",
      "Train loss (all, class, reg): 7.5425783647809705 0.023628572736467634 0.021491658761160715\n",
      "Train accuracy: 0.9871428571428571\n",
      "Test loss (all, class, reg): 9.69928955078125 0.11123334248860677 0.060015716145833335\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  1090  --------------------------\n",
      "Train loss (all, class, reg): 7.514629437582833 0.021038096291678292 0.021253246372767858\n",
      "Train accuracy: 0.9885714285714285\n",
      "Test loss (all, class, reg): 9.27501594543457 0.20546666463216146 0.07017453125\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  1100  --------------------------\n",
      "Train loss (all, class, reg): 7.456731747218541 0.009057143075125559 0.02389671316964286\n",
      "Train accuracy: 0.9885714285714285\n",
      "Test loss (all, class, reg): 9.525888582865397 0.0984999974568685 0.07043811197916666\n",
      "Test accuracy: 0.96\n",
      "Epoch:  1110  --------------------------\n",
      "Train loss (all, class, reg): 7.450801770346505 0.010542857306344168 0.02245178013392857\n",
      "Train accuracy: 0.9857142857142858\n",
      "Test loss (all, class, reg): 9.411095657348632 0.03486666679382324 0.06747947916666666\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1120  --------------------------\n",
      "Train loss (all, class, reg): 7.4051877294267925 0.01262857164655413 0.023536297433035713\n",
      "Train accuracy: 0.9885714285714285\n",
      "Test loss (all, class, reg): 9.30583112080892 0.12113332112630208 0.05983408203125\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1130  --------------------------\n",
      "Train loss (all, class, reg): 7.414492481776646 0.02288095201764788 0.02383580078125\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 9.422115707397461 0.03450000127156576 0.05575424479166667\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1140  --------------------------\n",
      "Train loss (all, class, reg): 7.377535858154297 0.010761904716491699 0.023968002232142856\n",
      "Train accuracy: 0.9871428571428571\n",
      "Test loss (all, class, reg): 9.211303278605143 0.06991111755371093 0.09307721354166666\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1150  --------------------------\n",
      "Train loss (all, class, reg): 7.408540818350656 0.019580952780587333 0.025563883928571427\n",
      "Train accuracy: 0.9871428571428571\n",
      "Test loss (all, class, reg): 9.293355166117351 0.038322219848632814 0.05077443359375\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  1160  --------------------------\n",
      "Train loss (all, class, reg): 7.29517947605678 0.013557142530168806 0.024437285156250002\n",
      "Train accuracy: 0.9914285714285714\n",
      "Test loss (all, class, reg): 9.137630907694499 0.04911110877990723 0.052754606119791665\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1170  --------------------------\n",
      "Train loss (all, class, reg): 7.278931912013463 0.04459047317504883 0.025904148995535715\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 9.274179560343425 0.04647778193155924 0.06137273437500001\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  1180  --------------------------\n",
      "Train loss (all, class, reg): 7.309974362509592 0.006538095474243164 0.02197180385044643\n",
      "Train accuracy: 0.9885714285714285\n",
      "Test loss (all, class, reg): 9.114184913635254 0.11543333689371744 0.04485093424479167\n",
      "Test accuracy: 0.9433333333333334\n",
      "Epoch:  1190  --------------------------\n",
      "Train loss (all, class, reg): 7.216062714712961 0.008880953107561384 0.021316417410714286\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 9.253329385121663 0.037044442494710283 0.05451617838541666\n",
      "Test accuracy: 0.9466666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1200  --------------------------\n",
      "Train loss (all, class, reg): 7.1931052480425155 0.019771427427019393 0.01942584263392857\n",
      "Train accuracy: 0.9914285714285714\n",
      "Test loss (all, class, reg): 9.29268559773763 0.03985555648803711 0.07412285156250001\n",
      "Test accuracy: 0.96\n",
      "Epoch:  1210  --------------------------\n",
      "Train loss (all, class, reg): 7.237074759347098 0.009380952290126256 0.03231990234375\n",
      "Train accuracy: 0.9914285714285714\n",
      "Test loss (all, class, reg): 9.219928118387857 0.06058888753255209 0.09121078125\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  1220  --------------------------\n",
      "Train loss (all, class, reg): 7.183843697139195 0.008433333805629186 0.023553390066964285\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 9.218110669453939 0.038377777735392256 0.05113951822916667\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1230  --------------------------\n",
      "Train loss (all, class, reg): 7.1161670521327425 0.013904762268066407 0.025739151785714287\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 9.088086522420248 0.023044444719950357 0.06594653645833334\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  1240  --------------------------\n",
      "Train loss (all, class, reg): 7.082753105163574 0.00670952388218471 0.02045637416294643\n",
      "Train accuracy: 0.9885714285714285\n",
      "Test loss (all, class, reg): 9.051547037760416 0.055422223409016924 0.057190735677083326\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1250  --------------------------\n",
      "Train loss (all, class, reg): 7.071183316367013 0.01275238037109375 0.02017680245535714\n",
      "Train accuracy: 0.9914285714285714\n",
      "Test loss (all, class, reg): 9.068168290456136 0.021922224362691242 0.04428387369791666\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1260  --------------------------\n",
      "Train loss (all, class, reg): 7.101364885057722 0.011390476226806641 0.01840435546875\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 9.150383427937825 0.08553333282470703 0.05978174479166667\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  1270  --------------------------\n",
      "Train loss (all, class, reg): 7.029020235879081 0.02380476270403181 0.01811820033482143\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 9.130914675394694 0.051711111068725585 0.07255531250000001\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1280  --------------------------\n",
      "Train loss (all, class, reg): 7.033499919346401 0.023757144383021764 0.026532631138392857\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 9.007772191365559 0.026455554962158203 0.056798046875\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  1290  --------------------------\n",
      "Train loss (all, class, reg): 7.003211419241769 0.007638094765799386 0.019867081473214285\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 9.01890458424886 0.0994444465637207 0.062469140625\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1300  --------------------------\n",
      "Train loss (all, class, reg): 6.965375497000558 0.012776190893990652 0.022687984095982144\n",
      "Train accuracy: 0.9914285714285714\n",
      "Test loss (all, class, reg): 8.863507715861003 0.02651111125946045 0.043122942708333334\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1310  --------------------------\n",
      "Train loss (all, class, reg): 6.921960375649588 0.005366666998182024 0.024787296316964285\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 9.015681584676107 0.12286665598551433 0.060629042968750005\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  1320  --------------------------\n",
      "Train loss (all, class, reg): 6.972352063315255 0.005271428653172084 0.035354182477678575\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 9.03293561299642 0.24663330078125 0.05608343098958334\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1330  --------------------------\n",
      "Train loss (all, class, reg): 6.94701647077288 0.008723809378487723 0.027079051339285714\n",
      "Train accuracy: 0.9957142857142857\n",
      "Test loss (all, class, reg): 8.961227518717449 0.026266667048136395 0.059041575520833334\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1340  --------------------------\n",
      "Train loss (all, class, reg): 6.933988516671317 0.008309523718697684 0.02109140345982143\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 8.89721206665039 0.2979222361246745 0.04766392578125\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1350  --------------------------\n",
      "Train loss (all, class, reg): 6.86189489364624 0.012733334132603236 0.027783253348214285\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 8.892092119852702 0.11077779134114583 0.07175671875\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1360  --------------------------\n",
      "Train loss (all, class, reg): 6.865055700029646 0.05178095136369978 0.02904364676339286\n",
      "Train accuracy: 0.9942857142857143\n",
      "Test loss (all, class, reg): 9.283648338317871 0.06122222900390625 0.058023528645833336\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  1370  --------------------------\n",
      "Train loss (all, class, reg): 6.85763884135655 0.006604762077331543 0.02044916015625\n",
      "Train accuracy: 0.9942857142857143\n",
      "Test loss (all, class, reg): 9.095338503519693 0.10514443715413412 0.05684412760416666\n",
      "Test accuracy: 0.9466666666666667\n",
      "Epoch:  1380  --------------------------\n",
      "Train loss (all, class, reg): 6.832348809923444 0.015180952889578683 0.02348451450892857\n",
      "Train accuracy: 0.9914285714285714\n",
      "Test loss (all, class, reg): 8.902143828074138 0.02407777786254883 0.040801858723958334\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  1390  --------------------------\n",
      "Train loss (all, class, reg): 6.820310489109584 0.03685714449201311 0.015562539062500002\n",
      "Train accuracy: 0.9942857142857143\n",
      "Test loss (all, class, reg): 8.78807154337565 0.026266667048136395 0.06395787109375001\n",
      "Test accuracy: 0.95\n",
      "Epoch:  1400  --------------------------\n",
      "Train loss (all, class, reg): 6.7640765735081265 0.02094761712210519 0.02395817801339286\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 8.817338536580404 0.04179999669392904 0.06714998697916666\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1410  --------------------------\n",
      "Train loss (all, class, reg): 6.731200675964356 0.017009523936680385 0.024711328125\n",
      "Train accuracy: 0.9957142857142857\n",
      "Test loss (all, class, reg): 8.816958554585774 0.054744447072347005 0.06606878906250001\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1420  --------------------------\n",
      "Train loss (all, class, reg): 6.753654618944441 0.024914283752441407 0.017959400111607144\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 8.884034868876139 0.026022221247355145 0.06385502604166667\n",
      "Test accuracy: 0.9566666666666667\n",
      "Epoch:  1430  --------------------------\n",
      "Train loss (all, class, reg): 6.709453476497105 0.011809523446219309 0.03279619698660714\n",
      "Train accuracy: 0.9942857142857143\n",
      "Test loss (all, class, reg): 8.659284451802572 0.16405555725097656 0.06239074218750001\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  1440  --------------------------\n",
      "Train loss (all, class, reg): 6.68075929914202 0.009771428108215331 0.026878448660714288\n",
      "Train accuracy: 0.9957142857142857\n",
      "Test loss (all, class, reg): 8.88269765218099 0.07554444630940756 0.08282020182291668\n",
      "Test accuracy: 0.9633333333333334\n",
      "Epoch:  1450  --------------------------\n",
      "Train loss (all, class, reg): 6.663149735586984 0.009852380752563476 0.017916739676339288\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 8.756765823364258 0.09979999542236329 0.06546940755208333\n",
      "Test accuracy: 0.96\n",
      "Epoch:  1460  --------------------------\n",
      "Train loss (all, class, reg): 6.652012465340751 0.007238095147269113 0.019014568917410716\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 8.726686770121256 0.023344443639119465 0.060734479166666674\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  1470  --------------------------\n",
      "Train loss (all, class, reg): 6.6712737573896135 0.006747619083949497 0.030238705357142855\n",
      "Train accuracy: 0.99\n",
      "Test loss (all, class, reg): 8.63916540145874 0.019133334159851075 0.06661729166666668\n",
      "Test accuracy: 0.9633333333333334\n",
      "Epoch:  1480  --------------------------\n",
      "Train loss (all, class, reg): 6.645788955688476 0.008019048145839145 0.033111958705357145\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 8.62433203379313 0.08949999491373697 0.06440377604166667\n",
      "Test accuracy: 0.9533333333333334\n",
      "Epoch:  1490  --------------------------\n",
      "Train loss (all, class, reg): 6.630052882603237 0.01525238037109375 0.0220891796875\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 9.071030578613282 0.05648888905843099 0.03900167643229167\n",
      "Test accuracy: 0.9533333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1500  --------------------------\n",
      "Train loss (all, class, reg): 6.599302782331194 0.00804285730634417 0.02204318359375\n",
      "Train accuracy: 0.9928571428571429\n",
      "Test loss (all, class, reg): 8.702076047261556 0.02981111208597819 0.04169028645833333\n",
      "Test accuracy: 0.9566666666666667\n"
     ]
    }
   ],
   "source": [
    "train_total_losses=[]\n",
    "train_class_losses=[]\n",
    "train_regres_losses=[]\n",
    "\n",
    "test_total_losses=[]\n",
    "test_class_losses=[]\n",
    "test_regres_losses=[]\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "alpha = 1\n",
    "beta = 0.001\n",
    "for epoch in range(1501):\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    loss_train = 0\n",
    "    loss_class = 0\n",
    "    loss_reg = 0\n",
    "    for i, (_, tact, target, label) in enumerate(train_loader):\n",
    "        \n",
    "        tact = tact.to(device)\n",
    "        target = target.to(device)\n",
    "        tact = net.get_spike(tact)\n",
    "        output, out_input, _, _ = net.forward(tact)\n",
    "        \n",
    "        correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "        loss_class = error.numSpikes(output, target)\n",
    "        \n",
    "        loss_reg = error2.spikeTime(out_input, tact)\n",
    "        \n",
    "        loss = alpha*loss_class + beta*loss_reg\n",
    "        \n",
    "        loss_train += loss.item()\n",
    "        loss_class = alpha*loss_class.item()\n",
    "        loss_reg = beta*loss_reg.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: ', epoch, ' --------------------------')\n",
    "        print('Train loss (all, class, reg):', \n",
    "              loss_train/len(train_dataset),\n",
    "              loss_class/len(train_dataset),\n",
    "              loss_reg/len(train_dataset))\n",
    "        print('Train accuracy:', correct/len(train_dataset))\n",
    "    train_accs.append(correct/len(train_dataset))\n",
    "    train_total_losses.append(loss_train/len(train_dataset))\n",
    "    train_class_losses.append(loss_class/len(train_dataset))\n",
    "    train_regres_losses.append(loss_reg/len(train_dataset))\n",
    "        \n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    loss_test = 0\n",
    "    loss_class = 0\n",
    "    loss_reg = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (_, tact, target, label) in enumerate(test_loader):\n",
    "\n",
    "            tact = tact.to(device)\n",
    "            target = target.to(device)\n",
    "            tact = net.get_spike(tact)\n",
    "            output, out_input, _, _ = net.forward(tact)\n",
    "        \n",
    "            correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "            loss_class = error.numSpikes(output, target)\n",
    "\n",
    "            loss_reg = error2.spikeTime(out_input, tact)\n",
    "\n",
    "            loss = alpha*loss_class + beta*loss_reg\n",
    "\n",
    "            loss_test += loss.item()\n",
    "            loss_class = alpha*loss_class.item()\n",
    "            loss_reg = beta*loss_reg.item()\n",
    "            \n",
    "#     if epoch%10 == 0:\n",
    "#         print('Test loss:', loss_test/len(test_dataset))\n",
    "#         print('Test accuracy:', correct/len(test_dataset))\n",
    "#     test_accs.append(correct/len(test_dataset))\n",
    "#     test_losses.append(loss_test/len(test_dataset))\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Test loss (all, class, reg):', \n",
    "              loss_test/len(test_dataset),\n",
    "              loss_class/len(test_dataset),\n",
    "              loss_reg/len(test_dataset))\n",
    "        print('Test accuracy:', correct/len(test_dataset))\n",
    "    test_accs.append(correct/len(test_dataset))\n",
    "    test_total_losses.append(loss_test/len(test_dataset))\n",
    "    test_class_losses.append(loss_class/len(test_dataset))\n",
    "    test_regres_losses.append(loss_reg/len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(15,7))\n",
    "\n",
    "ax[0].plot(train_total_losses, 'b')\n",
    "ax[0].plot(500*np.array(train_class_losses), 'r')\n",
    "ax[0].plot(500*np.array(train_regres_losses_i), 'g')\n",
    "ax[0].plot(500*np.array(train_regres_losses_b), 'c')\n",
    "\n",
    "# ax[0].plot(test_losses)\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "ax[1].plot(train_accs)\n",
    "ax[1].plot(test_accs)\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend(['Train', 'Test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9971428571428571"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "big_list = []\n",
    "label_list=[]\n",
    "with torch.no_grad():\n",
    "    for i, (_, tact, target, label) in enumerate(test_loader):\n",
    "\n",
    "        tact = tact.to(device)\n",
    "        target = target.to(device)\n",
    "        tact = net.get_spike(tact)\n",
    "        _, _, rep, _ = net.forward(tact)\n",
    "        big_list.append(rep)\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 50, 1, 1, 150])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_representation = torch.cat(big_list,0)\n",
    "test_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all = torch.cat(label_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all = label_all.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.9 s, sys: 140 ms, total: 11.1 s\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dist_mat = torch.zeros([300,300])\n",
    "for i in range(300):\n",
    "    for j in range(300):\n",
    "        if i == j:\n",
    "            dist_mat[i, j] = 0.0\n",
    "        else:\n",
    "            dist_mat[i,j] = error2.spikeTime(test_representation[i], test_representation[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = dist_mat.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2,perplexity=10, metric='precomputed').fit_transform(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_embedded[:, 0], X_embedded[:, 1], c=label_all, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trasnfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierMLP(torch.nn.Module):\n",
    "    def __init__(self, params, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(ClassifierMLP, self).__init__()\n",
    "        self.slayer = snn.layer(params[\"neuron\"], params[\"simulation\"])\n",
    "        self.fc1 = self.slayer.dense(input_size, hidden_size1)\n",
    "        self.fc2 = self.slayer.dense(hidden_size1, hidden_size2) # rep\n",
    "        self.fc3 = self.slayer.dense(hidden_size2, output_size) # classifier\n",
    "    def get_spike(self, inp):\n",
    "        return self.slayer.spike(inp)\n",
    "    \n",
    "    def forward(self, spike_input):\n",
    "        spike_1 = self.slayer.spike(self.slayer.psp(self.fc1(spike_input)))\n",
    "        spike_2 = self.slayer.spike(self.slayer.psp(self.fc2(spike_1)))\n",
    "        spike_3 = self.slayer.spike(self.slayer.psp(self.fc3(spike_2)))  \n",
    "        return spike_3, spike_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = ClassifierMLP(params, 60, 50, 50, 20).to(device)\n",
    "error = snn.loss(params).to(device)\n",
    "error2 = snn.loss(params2).to(device)\n",
    "optimizer2 = torch.optim.RMSprop(net2.parameters(), lr=0.001, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_total_losses=[]\n",
    "# train_class_losses=[]\n",
    "# train_regres_losses=[]\n",
    "\n",
    "# test_total_losses=[]\n",
    "# test_class_losses=[]\n",
    "# test_regres_losses=[]\n",
    "\n",
    "# train_accs = []\n",
    "# test_accs = []\n",
    "\n",
    "# alpha = 1\n",
    "# beta = 0.001\n",
    "\n",
    "# for epoch in range(1501):\n",
    "#     correct = 0\n",
    "#     loss_train = 0\n",
    "#     loss_class = 0\n",
    "#     loss_reg = 0\n",
    "#     net2.train()\n",
    "#     for i, (tact, _, target, label) in enumerate(train_loader):\n",
    "        \n",
    "#         tact = tact.to(device)\n",
    "#         target = target.to(device)\n",
    "#         tact = net2.get_spike(tact)\n",
    "        \n",
    "#         # impute icub\n",
    "#         tact_new = torch.zeros((tact.shape[0],tact.shape[1],1,1,tact.shape[-1]*2)).to(device)\n",
    "#         tact_new[...,::2]  = tact\n",
    "#         tact = tact_new\n",
    "# #         print(tact.shape)\n",
    "        \n",
    "#         output, out_input = net2.forward(tact)\n",
    "        \n",
    "#         correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "#         loss_class = error.numSpikes(output, target)\n",
    "        \n",
    "#         #loss_reg = error2.spikeTime(out_input, tact)\n",
    "        \n",
    "#         loss = alpha*loss_class# + beta*loss_reg\n",
    "        \n",
    "#         loss_train += loss.item()\n",
    "#         loss_class += alpha*loss_class.item()\n",
    "#         #loss_reg = beta*loss_reg.item()\n",
    "        \n",
    "#         optimizer2.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer2.step()\n",
    "                \n",
    "#     if epoch%10 == 0:\n",
    "#         print('Epoch: ', epoch, ' --------------------------')\n",
    "#         print('Train loss (all, class, reg):', \n",
    "#               loss_train/len(train_dataset),\n",
    "#               loss_class/len(train_dataset),\n",
    "#               loss_reg/len(train_dataset))\n",
    "#         print('Train accuracy:', correct/len(train_dataset))\n",
    "#     train_accs.append(correct/len(train_dataset))\n",
    "#     train_total_losses.append(loss_train/len(train_dataset))\n",
    "#     train_class_losses.append(loss_class/len(train_dataset))\n",
    "#     train_regres_losses.append(loss_reg/len(train_dataset))\n",
    "        \n",
    "#     net2.eval()\n",
    "#     correct = 0\n",
    "#     loss_test = 0\n",
    "#     loss_class = 0\n",
    "#     loss_reg = 0\n",
    "#     with torch.no_grad():\n",
    "#         for i, (tact,_, target, label) in enumerate(test_loader):\n",
    "\n",
    "#             tact = tact.to(device)\n",
    "#             target = target.to(device)\n",
    "#             tact = net2.get_spike(tact)\n",
    "            \n",
    "#             # impute icub\n",
    "#             tact_new = torch.zeros((tact.shape[0],tact.shape[1],1,1,tact.shape[-1]*2)).to(device)\n",
    "#             tact_new[...,::2]  = tact\n",
    "#             tact = tact_new\n",
    "            \n",
    "#             output, out_input = net2.forward(tact)\n",
    "        \n",
    "#             correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "#             loss_class = error.numSpikes(output, target)\n",
    "\n",
    "#             #loss_reg = error2.spikeTime(out_input, tact)\n",
    "\n",
    "#             loss = alpha*loss_class# + beta*loss_reg\n",
    "\n",
    "#             loss_test += loss.item()\n",
    "#             loss_class += alpha*loss_class.item()\n",
    "#             #loss_reg = beta*loss_reg.item()\n",
    "            \n",
    "# #     if epoch%10 == 0:\n",
    "# #         print('Test loss:', loss_test/len(test_dataset))\n",
    "# #         print('Test accuracy:', correct/len(test_dataset))\n",
    "# #     test_accs.append(correct/len(test_dataset))\n",
    "# #     test_losses.append(loss_test/len(test_dataset))\n",
    "    \n",
    "#     if epoch%10 == 0:\n",
    "#         print('Test loss (all, class, reg):', \n",
    "#               loss_test/len(test_dataset),\n",
    "#               loss_class/len(test_dataset),\n",
    "#               loss_reg/len(test_dataset))\n",
    "#         print('Test accuracy:', correct/len(test_dataset))\n",
    "#     test_accs.append(correct/len(test_dataset))\n",
    "#     test_total_losses.append(loss_test/len(test_dataset))\n",
    "#     test_class_losses.append(loss_class/len(test_dataset))\n",
    "#     test_regres_losses.append(loss_reg/len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  --------------------------\n",
      "Train loss (all, class, reg): 97.24812844412668 0.4863714599609375 368.67377232142854\n",
      "Train accuracy: 0.11142857142857143\n",
      "Test loss (all, class, reg): 84.79127970377604 1.2585111490885417 750.7554166666666\n",
      "Test accuracy: 0.11333333333333333\n",
      "Epoch:  10  --------------------------\n",
      "Train loss (all, class, reg): 66.82751338413783 0.3417904663085938 179.26969866071428\n",
      "Train accuracy: 0.5542857142857143\n",
      "Test loss (all, class, reg): 65.43249165852865 0.4912444051106771 716.3011979166666\n",
      "Test accuracy: 0.5166666666666667\n",
      "Epoch:  20  --------------------------\n",
      "Train loss (all, class, reg): 66.58191890171597 0.2551619175502232 328.12698660714284\n",
      "Train accuracy: 0.6985714285714286\n",
      "Test loss (all, class, reg): 66.2225259399414 0.7868666585286458 561.0609375\n",
      "Test accuracy: 0.6633333333333333\n",
      "Epoch:  30  --------------------------\n",
      "Train loss (all, class, reg): 66.39846821376256 0.22680001395089286 209.2031919642857\n",
      "Train accuracy: 0.75\n",
      "Test loss (all, class, reg): 66.58025227864583 0.5721333312988282 520.6082291666667\n",
      "Test accuracy: 0.7033333333333334\n",
      "Epoch:  40  --------------------------\n",
      "Train loss (all, class, reg): 65.68229182652065 0.09185714721679687 296.8803125\n",
      "Train accuracy: 0.7842857142857143\n",
      "Test loss (all, class, reg): 65.8331403096517 0.8150889078776041 386.09822916666667\n",
      "Test accuracy: 0.7133333333333334\n",
      "Epoch:  50  --------------------------\n",
      "Train loss (all, class, reg): 65.16064004080636 0.18427618844168528 311.2551785714286\n",
      "Train accuracy: 0.8114285714285714\n",
      "Test loss (all, class, reg): 65.55120758056641 0.3925111134847005 353.9024479166667\n",
      "Test accuracy: 0.7333333333333333\n",
      "Epoch:  60  --------------------------\n",
      "Train loss (all, class, reg): 64.89313581194196 0.23023808070591517 355.7562276785714\n",
      "Train accuracy: 0.8171428571428572\n",
      "Test loss (all, class, reg): 65.92751190185547 0.668888905843099 397.756171875\n",
      "Test accuracy: 0.75\n",
      "Epoch:  70  --------------------------\n",
      "Train loss (all, class, reg): 65.03527426583426 0.07791428702218192 367.13779017857144\n",
      "Train accuracy: 0.8285714285714286\n",
      "Test loss (all, class, reg): 66.2619556681315 0.4338222249348958 873.3872916666667\n",
      "Test accuracy: 0.7566666666666667\n",
      "Epoch:  80  --------------------------\n",
      "Train loss (all, class, reg): 65.37958714076451 0.11501905168805804 286.04189732142856\n",
      "Train accuracy: 0.8442857142857143\n",
      "Test loss (all, class, reg): 66.51905680338541 0.4479332987467448 734.8884895833334\n",
      "Test accuracy: 0.75\n",
      "Epoch:  90  --------------------------\n",
      "Train loss (all, class, reg): 64.6853078351702 0.21568572998046875 374.01037946428573\n",
      "Train accuracy: 0.8528571428571429\n",
      "Test loss (all, class, reg): 65.36115427652994 0.5114222208658854 523.2447916666666\n",
      "Test accuracy: 0.7733333333333333\n",
      "Epoch:  100  --------------------------\n",
      "Train loss (all, class, reg): 63.698984200613836 0.07773332868303572 449.50669642857144\n",
      "Train accuracy: 0.8514285714285714\n",
      "Test loss (all, class, reg): 65.29141489664714 0.393955561319987 497.33197916666666\n",
      "Test accuracy: 0.79\n",
      "Epoch:  110  --------------------------\n",
      "Train loss (all, class, reg): 62.97168688092913 0.08135238102504186 349.14482142857145\n",
      "Train accuracy: 0.8514285714285714\n",
      "Test loss (all, class, reg): 64.15134216308594 0.5763778177897135 528.32921875\n",
      "Test accuracy: 0.7833333333333333\n",
      "Epoch:  120  --------------------------\n",
      "Train loss (all, class, reg): 62.22429650442941 0.09296190534319196 290.5944642857143\n",
      "Train accuracy: 0.86\n",
      "Test loss (all, class, reg): 63.905831502278645 0.30666666666666664 699.8380729166666\n",
      "Test accuracy: 0.8\n",
      "Epoch:  130  --------------------------\n",
      "Train loss (all, class, reg): 61.76639927455357 0.0984285627092634 461.9248214285714\n",
      "Train accuracy: 0.8657142857142858\n",
      "Test loss (all, class, reg): 63.529538014729816 0.32133331298828127 594.8898958333333\n",
      "Test accuracy: 0.8\n",
      "Epoch:  140  --------------------------\n",
      "Train loss (all, class, reg): 60.98612779889788 0.03889523914882115 328.2097991071429\n",
      "Train accuracy: 0.8671428571428571\n",
      "Test loss (all, class, reg): 62.614776611328125 0.5633777872721354 530.08265625\n",
      "Test accuracy: 0.7933333333333333\n",
      "Epoch:  150  --------------------------\n",
      "Train loss (all, class, reg): 60.0242989894322 0.038114286150251114 263.0063616071429\n",
      "Train accuracy: 0.8728571428571429\n",
      "Test loss (all, class, reg): 62.28564249674479 0.10353333791097005 906.619375\n",
      "Test accuracy: 0.8033333333333333\n",
      "Epoch:  160  --------------------------\n",
      "Train loss (all, class, reg): 59.21337833949498 0.02978095463344029 363.73578125\n",
      "Train accuracy: 0.88\n",
      "Test loss (all, class, reg): 60.97969568888346 0.3030444590250651 646.0544791666666\n",
      "Test accuracy: 0.81\n",
      "Epoch:  170  --------------------------\n",
      "Train loss (all, class, reg): 58.355997946602955 0.10888571602957589 255.7854017857143\n",
      "Train accuracy: 0.8842857142857142\n",
      "Test loss (all, class, reg): 59.87402567545573 0.1521333312988281 607.7328125\n",
      "Test accuracy: 0.8133333333333334\n",
      "Epoch:  180  --------------------------\n",
      "Train loss (all, class, reg): 57.36938158307757 0.16504761832101003 265.8581026785714\n",
      "Train accuracy: 0.8871428571428571\n",
      "Test loss (all, class, reg): 59.4735373433431 0.2480888875325521 715.8998958333333\n",
      "Test accuracy: 0.81\n",
      "Epoch:  190  --------------------------\n",
      "Train loss (all, class, reg): 56.52965122767857 0.10059047154017857 254.1927232142857\n",
      "Train accuracy: 0.8928571428571429\n",
      "Test loss (all, class, reg): 58.72292714436849 0.24577779134114583 639.738125\n",
      "Test accuracy: 0.82\n",
      "Epoch:  200  --------------------------\n",
      "Train loss (all, class, reg): 55.83773206438337 0.21301906040736607 217.8740625\n",
      "Train accuracy: 0.8914285714285715\n",
      "Test loss (all, class, reg): 58.59412643432617 0.7442889404296875 446.60572916666666\n",
      "Test accuracy: 0.8166666666666667\n",
      "Epoch:  210  --------------------------\n",
      "Train loss (all, class, reg): 55.018213304792134 0.07144762311662946 288.6678348214286\n",
      "Train accuracy: 0.9014285714285715\n",
      "Test loss (all, class, reg): 57.32151458740234 0.45471110026041667 574.36546875\n",
      "Test accuracy: 0.8266666666666667\n",
      "Epoch:  220  --------------------------\n",
      "Train loss (all, class, reg): 54.22254283360073 0.1755047607421875 247.27\n",
      "Train accuracy: 0.8985714285714286\n",
      "Test loss (all, class, reg): 57.22935246785482 0.2651999918619792 471.3545833333333\n",
      "Test accuracy: 0.8266666666666667\n",
      "Epoch:  230  --------------------------\n",
      "Train loss (all, class, reg): 53.69854777744838 0.15476190839494977 152.74339285714285\n",
      "Train accuracy: 0.8957142857142857\n",
      "Test loss (all, class, reg): 56.73593627929687 0.35128890991210937 631.9249479166666\n",
      "Test accuracy: 0.8266666666666667\n",
      "Epoch:  240  --------------------------\n",
      "Train loss (all, class, reg): 53.24034419468471 0.04252380916050502 343.61984375\n",
      "Train accuracy: 0.9014285714285715\n",
      "Test loss (all, class, reg): 56.58382425944011 0.48013331095377604 471.938125\n",
      "Test accuracy: 0.8266666666666667\n",
      "Epoch:  250  --------------------------\n",
      "Train loss (all, class, reg): 52.94529689243861 0.04860000610351563 240.0377455357143\n",
      "Train accuracy: 0.9014285714285715\n",
      "Test loss (all, class, reg): 56.24106557210286 0.5622444661458333 494.68541666666664\n",
      "Test accuracy: 0.8266666666666667\n",
      "Epoch:  260  --------------------------\n",
      "Train loss (all, class, reg): 52.50626985822405 0.06575237819126674 319.1166294642857\n",
      "Train accuracy: 0.9028571428571428\n",
      "Test loss (all, class, reg): 55.68225087483724 0.11837778727213542 675.8963541666667\n",
      "Test accuracy: 0.8266666666666667\n",
      "Epoch:  270  --------------------------\n",
      "Train loss (all, class, reg): 52.09268715994698 0.09509523664202009 222.19352678571428\n",
      "Train accuracy: 0.9042857142857142\n",
      "Test loss (all, class, reg): 55.18121856689453 0.7536222330729166 664.2720833333333\n",
      "Test accuracy: 0.8166666666666667\n",
      "Epoch:  280  --------------------------\n",
      "Train loss (all, class, reg): 51.82751972743443 0.10956189836774553 248.1474107142857\n",
      "Train accuracy: 0.91\n",
      "Test loss (all, class, reg): 54.83678914388021 0.4312889099121094 539.1588541666666\n",
      "Test accuracy: 0.84\n",
      "Epoch:  290  --------------------------\n",
      "Train loss (all, class, reg): 51.65518583025251 0.04575237819126674 261.45776785714287\n",
      "Train accuracy: 0.8985714285714286\n",
      "Test loss (all, class, reg): 55.229756418863936 0.29015556335449216 425.4819010416667\n",
      "Test accuracy: 0.83\n",
      "Epoch:  300  --------------------------\n",
      "Train loss (all, class, reg): 51.47117364065988 0.22947618756975446 211.85667410714285\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss (all, class, reg): 54.66632446289063 0.08908889134724934 820.1583854166666\n",
      "Test accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  310  --------------------------\n",
      "Train loss (all, class, reg): 51.20531138828822 0.0674000004359654 257.7728794642857\n",
      "Train accuracy: 0.91\n",
      "Test loss (all, class, reg): 54.62038009643555 0.16528889973958333 623.2875520833334\n",
      "Test accuracy: 0.84\n",
      "Epoch:  320  --------------------------\n",
      "Train loss (all, class, reg): 50.9512413242885 0.11864761352539062 169.84033482142857\n",
      "Train accuracy: 0.9014285714285715\n",
      "Test loss (all, class, reg): 54.55412602742513 0.3700889078776042 653.7652083333334\n",
      "Test accuracy: 0.8366666666666667\n",
      "Epoch:  330  --------------------------\n",
      "Train loss (all, class, reg): 50.74726039341518 0.04143809727260045 228.7563392857143\n",
      "Train accuracy: 0.9085714285714286\n",
      "Test loss (all, class, reg): 54.29369608561198 0.30275553385416665 412.12921875\n",
      "Test accuracy: 0.8333333333333334\n",
      "Epoch:  340  --------------------------\n",
      "Train loss (all, class, reg): 50.79137845720564 0.042923812866210935 251.13723214285713\n",
      "Train accuracy: 0.91\n",
      "Test loss (all, class, reg): 54.06190460205078 0.0670666758219401 560.5347395833334\n",
      "Test accuracy: 0.8366666666666667\n",
      "Epoch:  350  --------------------------\n",
      "Train loss (all, class, reg): 50.59794318062919 0.18895237513950894 218.87689732142857\n",
      "Train accuracy: 0.9128571428571428\n",
      "Test loss (all, class, reg): 54.305860697428386 0.3341333516438802 528.6368229166667\n",
      "Test accuracy: 0.8366666666666667\n",
      "Epoch:  360  --------------------------\n",
      "Train loss (all, class, reg): 50.64123103550502 0.0983333260672433 215.87060267857143\n",
      "Train accuracy: 0.9128571428571428\n",
      "Test loss (all, class, reg): 54.432509104410805 0.12544445037841798 599.5715104166667\n",
      "Test accuracy: 0.85\n",
      "Epoch:  370  --------------------------\n",
      "Train loss (all, class, reg): 50.42126852852957 0.05574285234723772 254.21620535714285\n",
      "Train accuracy: 0.9128571428571428\n",
      "Test loss (all, class, reg): 54.23980728149414 0.3050444539388021 517.0957291666666\n",
      "Test accuracy: 0.85\n",
      "Epoch:  380  --------------------------\n",
      "Train loss (all, class, reg): 50.390770438058034 0.05866666521344866 282.9047098214286\n",
      "Train accuracy: 0.9085714285714286\n",
      "Test loss (all, class, reg): 54.02682840983073 0.20186667124430338 642.7888020833333\n",
      "Test accuracy: 0.8333333333333334\n",
      "Epoch:  390  --------------------------\n",
      "Train loss (all, class, reg): 50.36883747645787 0.014514285496303013 278.96104910714286\n",
      "Train accuracy: 0.9114285714285715\n",
      "Test loss (all, class, reg): 53.99246917724609 0.40599998474121096 621.7096354166666\n",
      "Test accuracy: 0.8366666666666667\n",
      "Epoch:  400  --------------------------\n",
      "Train loss (all, class, reg): 50.14621804373605 0.10454286847795759 230.3347544642857\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss (all, class, reg): 53.96120808919271 0.3136444600423177 414.90458333333333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  410  --------------------------\n",
      "Train loss (all, class, reg): 50.08229620797294 0.055752378191266744 314.89676339285717\n",
      "Train accuracy: 0.9057142857142857\n",
      "Test loss (all, class, reg): 53.85504374186198 0.23219998677571616 655.7933333333333\n",
      "Test accuracy: 0.85\n",
      "Epoch:  420  --------------------------\n",
      "Train loss (all, class, reg): 49.92495760236468 0.10670476640973772 264.0040625\n",
      "Train accuracy: 0.91\n",
      "Test loss (all, class, reg): 53.29954477945964 0.15335556030273437 767.6259895833333\n",
      "Test accuracy: 0.85\n",
      "Epoch:  430  --------------------------\n",
      "Train loss (all, class, reg): 49.79784421648298 0.14994285583496095 227.98955357142856\n",
      "Train accuracy: 0.9128571428571428\n",
      "Test loss (all, class, reg): 53.16711669921875 0.33735555013020835 793.1178645833334\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  440  --------------------------\n",
      "Train loss (all, class, reg): 49.5446044921875 0.05808571406773159 267.5522321428571\n",
      "Train accuracy: 0.9171428571428571\n",
      "Test loss (all, class, reg): 53.46322616577149 0.3095111338297526 628.5580208333333\n",
      "Test accuracy: 0.84\n",
      "Epoch:  450  --------------------------\n",
      "Train loss (all, class, reg): 49.421002807617185 0.025114288330078127 286.8067857142857\n",
      "Train accuracy: 0.9114285714285715\n",
      "Test loss (all, class, reg): 53.24546340942383 0.45922220865885416 375.9048177083333\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  460  --------------------------\n",
      "Train loss (all, class, reg): 49.21674691336496 0.11084762573242188 189.63408482142856\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss (all, class, reg): 53.078894500732424 0.5244889322916667 553.0457291666667\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  470  --------------------------\n",
      "Train loss (all, class, reg): 49.072537667410714 0.020552381787981307 280.2977455357143\n",
      "Train accuracy: 0.9185714285714286\n",
      "Test loss (all, class, reg): 53.093644561767576 0.3105333201090495 540.9726041666667\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  480  --------------------------\n",
      "Train loss (all, class, reg): 48.989059622628346 0.027104761941092355 221.43886160714285\n",
      "Train accuracy: 0.9114285714285715\n",
      "Test loss (all, class, reg): 52.73595504760742 0.07533333460489909 690.2775520833334\n",
      "Test accuracy: 0.86\n",
      "Epoch:  490  --------------------------\n",
      "Train loss (all, class, reg): 48.94135029384068 0.02208571570260184 265.06546875\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss (all, class, reg): 53.07688069661458 0.07708889007568359 621.0248958333333\n",
      "Test accuracy: 0.85\n",
      "Epoch:  500  --------------------------\n",
      "Train loss (all, class, reg): 48.903528921944755 0.04464761734008789 350.85\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss (all, class, reg): 52.655008443196614 0.4208666737874349 540.7134895833333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  510  --------------------------\n",
      "Train loss (all, class, reg): 48.956274959019254 0.07221904754638672 200.96841517857143\n",
      "Train accuracy: 0.9214285714285714\n",
      "Test loss (all, class, reg): 53.005182037353514 0.22922220865885418 690.4985416666667\n",
      "Test accuracy: 0.86\n",
      "Epoch:  520  --------------------------\n",
      "Train loss (all, class, reg): 48.81035500662667 0.03727619171142578 241.5021875\n",
      "Train accuracy: 0.9171428571428571\n",
      "Test loss (all, class, reg): 52.667108103434245 0.4398221842447917 579.1121875\n",
      "Test accuracy: 0.85\n",
      "Epoch:  530  --------------------------\n",
      "Train loss (all, class, reg): 48.87402600969587 0.04021904536655971 304.1904910714286\n",
      "Train accuracy: 0.9057142857142857\n",
      "Test loss (all, class, reg): 52.70453536987305 0.2200444539388021 541.2860416666666\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  540  --------------------------\n",
      "Train loss (all, class, reg): 48.82345428466797 0.019038095474243164 273.56897321428573\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss (all, class, reg): 52.79886586507161 0.2812000020345052 678.3180729166667\n",
      "Test accuracy: 0.84\n",
      "Epoch:  550  --------------------------\n",
      "Train loss (all, class, reg): 48.844053867885044 0.08306666782924108 186.19495535714285\n",
      "Train accuracy: 0.9171428571428571\n",
      "Test loss (all, class, reg): 53.158150838216145 0.36791112263997394 537.7530729166666\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  560  --------------------------\n",
      "Train loss (all, class, reg): 48.97162316458566 0.08724761962890625 249.92386160714287\n",
      "Train accuracy: 0.9128571428571428\n",
      "Test loss (all, class, reg): 53.03126281738281 0.23720001220703124 691.8019270833333\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  570  --------------------------\n",
      "Train loss (all, class, reg): 48.8427585710798 0.052200001307896204 230.29953125\n",
      "Train accuracy: 0.9071428571428571\n",
      "Test loss (all, class, reg): 53.07778091430664 0.2964666748046875 614.2420833333333\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  580  --------------------------\n",
      "Train loss (all, class, reg): 48.6654799761091 0.05098095485142299 291.96982142857144\n",
      "Train accuracy: 0.9185714285714286\n",
      "Test loss (all, class, reg): 53.0676557413737 0.42964441935221354 499.88614583333333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  590  --------------------------\n",
      "Train loss (all, class, reg): 48.68164297921317 0.026276190621512277 270.41595982142854\n",
      "Train accuracy: 0.9171428571428571\n",
      "Test loss (all, class, reg): 52.42191640218099 0.706000010172526 445.4344791666667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  600  --------------------------\n",
      "Train loss (all, class, reg): 48.53816519601004 0.06306666782924107 221.21613839285715\n",
      "Train accuracy: 0.9171428571428571\n",
      "Test loss (all, class, reg): 52.46393320719401 0.16968889872233073 572.2963541666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  610  --------------------------\n",
      "Train loss (all, class, reg): 48.487332240513396 0.021942858014787948 289.035625\n",
      "Train accuracy: 0.9242857142857143\n",
      "Test loss (all, class, reg): 52.63836908976237 0.046044445037841795 630.8819791666666\n",
      "Test accuracy: 0.86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  620  --------------------------\n",
      "Train loss (all, class, reg): 48.5766885811942 0.11907618931361608 220.63439732142857\n",
      "Train accuracy: 0.9257142857142857\n",
      "Test loss (all, class, reg): 52.604309488932294 0.49713333129882814 424.90763020833333\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  630  --------------------------\n",
      "Train loss (all, class, reg): 48.36035897391183 0.034180951799665175 216.28214285714284\n",
      "Train accuracy: 0.9228571428571428\n",
      "Test loss (all, class, reg): 52.321312459309894 0.04388888676961263 642.5258333333334\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  640  --------------------------\n",
      "Train loss (all, class, reg): 48.35624572753906 0.03362857001168387 260.4893303571429\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss (all, class, reg): 53.008807271321615 0.46795557657877607 635.6964583333333\n",
      "Test accuracy: 0.8333333333333334\n",
      "Epoch:  650  --------------------------\n",
      "Train loss (all, class, reg): 48.47301725115095 0.03208571297781808 257.438125\n",
      "Train accuracy: 0.9242857142857143\n",
      "Test loss (all, class, reg): 52.60984761555989 0.45446670532226563 770.0795833333333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  660  --------------------------\n",
      "Train loss (all, class, reg): 48.34630453927176 0.10377142769949776 231.69919642857144\n",
      "Train accuracy: 0.92\n",
      "Test loss (all, class, reg): 52.57902094523112 0.2220000203450521 684.8617708333334\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  670  --------------------------\n",
      "Train loss (all, class, reg): 48.47187502179827 0.10367618015834264 221.3999330357143\n",
      "Train accuracy: 0.9242857142857143\n",
      "Test loss (all, class, reg): 52.86800354003906 0.2617333221435547 478.3843229166667\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  680  --------------------------\n",
      "Train loss (all, class, reg): 48.45865711757115 0.06543809073311942 305.86598214285715\n",
      "Train accuracy: 0.9271428571428572\n",
      "Test loss (all, class, reg): 52.62417510986328 0.12137776692708334 642.9198958333334\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  690  --------------------------\n",
      "Train loss (all, class, reg): 48.281415797642296 0.1476571546282087 187.37462053571429\n",
      "Train accuracy: 0.9271428571428572\n",
      "Test loss (all, class, reg): 52.744422353108725 0.06535555521647135 775.6486979166667\n",
      "Test accuracy: 0.86\n",
      "Epoch:  700  --------------------------\n",
      "Train loss (all, class, reg): 48.27101771763393 0.057685715811593194 269.9658482142857\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss (all, class, reg): 52.569320373535156 0.26040000915527345 518.3245833333333\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  710  --------------------------\n",
      "Train loss (all, class, reg): 48.2327197265625 0.24417144775390626 254.85908482142858\n",
      "Train accuracy: 0.9257142857142857\n",
      "Test loss (all, class, reg): 53.03311462402344 0.6488888549804688 345.189921875\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  720  --------------------------\n",
      "Train loss (all, class, reg): 48.14927278791155 0.015057142802647182 257.6348660714286\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 52.616690673828124 0.2454888916015625 628.0650520833333\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  730  --------------------------\n",
      "Train loss (all, class, reg): 48.1701407296317 0.021828572409493582 235.02529017857142\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss (all, class, reg): 52.512296447753904 0.18573333740234374 551.1757291666667\n",
      "Test accuracy: 0.85\n",
      "Epoch:  740  --------------------------\n",
      "Train loss (all, class, reg): 48.01037602015904 0.11643809727260045 211.91709821428572\n",
      "Train accuracy: 0.9228571428571428\n",
      "Test loss (all, class, reg): 53.11025177001953 0.47948893229166667 636.238125\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  750  --------------------------\n",
      "Train loss (all, class, reg): 47.893709869384764 0.014676189422607422 274.6882142857143\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss (all, class, reg): 52.41525197347005 0.17786666870117188 643.9933333333333\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  760  --------------------------\n",
      "Train loss (all, class, reg): 47.696303383963446 0.038847618103027344 216.23308035714285\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss (all, class, reg): 52.35632995605469 0.17468888600667318 581.6426041666666\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  770  --------------------------\n",
      "Train loss (all, class, reg): 47.84430415562221 0.032419046674455915 301.9831473214286\n",
      "Train accuracy: 0.9242857142857143\n",
      "Test loss (all, class, reg): 52.20640914916992 0.13671112060546875 553.2196875\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  780  --------------------------\n",
      "Train loss (all, class, reg): 47.64507526942662 0.14384762355259487 200.42875\n",
      "Train accuracy: 0.93\n",
      "Test loss (all, class, reg): 52.54763661702474 0.24188888549804688 797.2394791666667\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  790  --------------------------\n",
      "Train loss (all, class, reg): 47.62350980486189 0.05502857208251953 252.12995535714285\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss (all, class, reg): 52.008956095377606 0.19237777709960938 510.24427083333336\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  800  --------------------------\n",
      "Train loss (all, class, reg): 47.46597294398717 0.03040952410016741 235.56136160714286\n",
      "Train accuracy: 0.93\n",
      "Test loss (all, class, reg): 51.90669825236002 0.46975555419921877 570.8640625\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  810  --------------------------\n",
      "Train loss (all, class, reg): 47.30632766723633 0.11721905299595424 195.14801339285714\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss (all, class, reg): 51.59992889404297 0.7867111206054688 534.8929166666667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  820  --------------------------\n",
      "Train loss (all, class, reg): 47.31138660975865 0.01560000010899135 256.8514732142857\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss (all, class, reg): 51.96353429158528 0.2844666544596354 358.1065625\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  830  --------------------------\n",
      "Train loss (all, class, reg): 47.26708687918527 0.019066668919154577 333.1890625\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss (all, class, reg): 51.71491053263346 0.0628444480895996 605.41734375\n",
      "Test accuracy: 0.86\n",
      "Epoch:  840  --------------------------\n",
      "Train loss (all, class, reg): 47.23988717215402 0.05203809465680804 176.38370535714284\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss (all, class, reg): 52.035513458251955 0.13868888854980468 684.17078125\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  850  --------------------------\n",
      "Train loss (all, class, reg): 47.179618486676894 0.03917142868041992 272.8458705357143\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 51.67260787963867 0.33828890482584634 481.09989583333333\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  860  --------------------------\n",
      "Train loss (all, class, reg): 47.17004549298968 0.014990476880754743 288.7767857142857\n",
      "Train accuracy: 0.93\n",
      "Test loss (all, class, reg): 52.04825342814127 0.15259999593098958 586.4650520833334\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  870  --------------------------\n",
      "Train loss (all, class, reg): 47.074447326660156 0.08040000915527344 236.77642857142857\n",
      "Train accuracy: 0.9257142857142857\n",
      "Test loss (all, class, reg): 51.19765116373698 0.07551111221313477 638.9458854166667\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  880  --------------------------\n",
      "Train loss (all, class, reg): 46.960330592564176 0.017800000054495675 340.57736607142857\n",
      "Train accuracy: 0.9271428571428572\n",
      "Test loss (all, class, reg): 51.699992167154946 0.40688888549804686 665.0808854166667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  890  --------------------------\n",
      "Train loss (all, class, reg): 46.92971817016601 0.09363809858049665 209.62573660714287\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss (all, class, reg): 51.771121164957684 0.10366666793823243 520.7631770833333\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  900  --------------------------\n",
      "Train loss (all, class, reg): 47.09954467773437 0.05474285670689174 233.93714285714285\n",
      "Train accuracy: 0.9257142857142857\n",
      "Test loss (all, class, reg): 51.65198257446289 0.33104443868001304 499.03765625\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  910  --------------------------\n",
      "Train loss (all, class, reg): 46.8641259765625 0.017933333260672434 217.25848214285713\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss (all, class, reg): 51.3879970296224 0.41671114603678383 659.8627083333333\n",
      "Test accuracy: 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  920  --------------------------\n",
      "Train loss (all, class, reg): 46.814152047293526 0.01606666564941406 276.99729910714285\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss (all, class, reg): 51.17583958943685 0.2809333292643229 464.80005208333336\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  930  --------------------------\n",
      "Train loss (all, class, reg): 46.662496468680246 0.08266666957310267 227.3386830357143\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss (all, class, reg): 51.47710510253906 0.37828887939453126 523.8149479166667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  940  --------------------------\n",
      "Train loss (all, class, reg): 46.66426293509347 0.14134286063058035 235.39285714285714\n",
      "Train accuracy: 0.93\n",
      "Test loss (all, class, reg): 51.20631088256836 0.25388888041178387 487.5964583333333\n",
      "Test accuracy: 0.85\n",
      "Epoch:  950  --------------------------\n",
      "Train loss (all, class, reg): 46.50758313860212 0.08555238451276506 282.4454017857143\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 51.2191449991862 0.13042222340901694 492.6773958333333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  960  --------------------------\n",
      "Train loss (all, class, reg): 46.48872538975307 0.026847615923200334 257.40877232142856\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.991573384602866 0.3043555196126302 537.3183333333334\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  970  --------------------------\n",
      "Train loss (all, class, reg): 46.424217136928014 0.017542858123779297 214.4752232142857\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 50.90880503336589 0.16420000712076824 777.6194791666667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  980  --------------------------\n",
      "Train loss (all, class, reg): 46.34990430559431 0.19021905081612722 163.97324776785715\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss (all, class, reg): 51.07257949829101 0.5114666748046875 518.26109375\n",
      "Test accuracy: 0.86\n",
      "Epoch:  990  --------------------------\n",
      "Train loss (all, class, reg): 46.24272746494838 0.029857142312186107 251.39383928571428\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss (all, class, reg): 50.63850468953451 0.0910888926188151 660.91203125\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1000  --------------------------\n",
      "Train loss (all, class, reg): 46.164563555036274 0.10795237949916295 209.855625\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss (all, class, reg): 51.07399266560872 0.05697778065999349 502.3184375\n",
      "Test accuracy: 0.85\n",
      "Epoch:  1010  --------------------------\n",
      "Train loss (all, class, reg): 46.19770625523159 0.09518094744001115 339.3120535714286\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.07936950683594 0.3758000183105469 474.4886979166667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1020  --------------------------\n",
      "Train loss (all, class, reg): 46.123949715750555 0.17841905866350447 195.11325892857144\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 50.30740661621094 0.3465555318196615 334.72669270833336\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1030  --------------------------\n",
      "Train loss (all, class, reg): 46.14361225673131 0.024723810468401226 203.78223214285714\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss (all, class, reg): 50.523287811279296 0.09206666310628255 494.21359375\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1040  --------------------------\n",
      "Train loss (all, class, reg): 46.10352643694196 0.017952382223946708 277.5467410714286\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss (all, class, reg): 50.55745264689128 0.0855555534362793 574.3860416666666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1050  --------------------------\n",
      "Train loss (all, class, reg): 45.99378962925502 0.20979997907366071 255.22466517857143\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss (all, class, reg): 51.252045186360675 0.22422220865885417 639.0741666666667\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1060  --------------------------\n",
      "Train loss (all, class, reg): 45.9533502633231 0.15951428004673548 173.09325892857143\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.01101155598958 0.10062222798665364 639.63703125\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1070  --------------------------\n",
      "Train loss (all, class, reg): 46.06149270193917 0.049971422467912946 199.38955357142856\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss (all, class, reg): 50.896409301757814 0.22577776590983073 482.01609375\n",
      "Test accuracy: 0.85\n",
      "Epoch:  1080  --------------------------\n",
      "Train loss (all, class, reg): 46.033926936558316 0.028638095855712892 257.06915178571427\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 50.252981669108074 0.1347777811686198 837.2318229166667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1090  --------------------------\n",
      "Train loss (all, class, reg): 46.0330876159668 0.14668571472167968 166.6973325892857\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss (all, class, reg): 50.70018798828125 0.4754888916015625 542.2456770833334\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1100  --------------------------\n",
      "Train loss (all, class, reg): 45.93791222708566 0.03240952355521066 281.5564955357143\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 50.03665568033854 0.37997777303059893 478.13489583333336\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1110  --------------------------\n",
      "Train loss (all, class, reg): 45.79587472098214 0.06690475463867188 189.18933035714286\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss (all, class, reg): 50.52871505737305 0.1688444391886393 548.3221354166667\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1120  --------------------------\n",
      "Train loss (all, class, reg): 45.877454746791294 0.06042857578822545 218.59060267857143\n",
      "Train accuracy: 0.93\n",
      "Test loss (all, class, reg): 50.44173355102539 0.38904446919759117 496.43473958333334\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1130  --------------------------\n",
      "Train loss (all, class, reg): 45.986197531563896 0.023847618103027345 271.1245535714286\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.525986175537106 0.29215555826822914 580.435625\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1140  --------------------------\n",
      "Train loss (all, class, reg): 46.00197326660156 0.015085714885166713 226.49770089285715\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 50.28731399536133 0.5057333374023437 511.451875\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1150  --------------------------\n",
      "Train loss (all, class, reg): 45.92671279907226 0.10522857666015625 205.32542410714285\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.232412618001305 0.0808222262064616 559.4136458333334\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1160  --------------------------\n",
      "Train loss (all, class, reg): 45.86976104736328 0.015800000599452427 274.54082589285713\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.579920094807946 0.4624444580078125 391.9553125\n",
      "Test accuracy: 0.85\n",
      "Epoch:  1170  --------------------------\n",
      "Train loss (all, class, reg): 45.759644383021765 0.032914287022181916 268.0525669642857\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 50.76516418457031 0.2190888977050781 432.9482552083333\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1180  --------------------------\n",
      "Train loss (all, class, reg): 45.72777648925781 0.075 240.78037946428572\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 50.320873158772784 0.39113332112630206 506.89817708333334\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1190  --------------------------\n",
      "Train loss (all, class, reg): 45.88619663783482 0.025600000108991352 279.39004464285716\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 50.42215998331706 0.06175556182861328 569.8135416666667\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  1200  --------------------------\n",
      "Train loss (all, class, reg): 45.91290529523577 0.02091428620474679 260.8766517857143\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 50.38416290283203 0.22524444580078126 537.3928645833333\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1210  --------------------------\n",
      "Train loss (all, class, reg): 45.74750490461077 0.030057144165039063 234.51379464285714\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss (all, class, reg): 50.07280919392904 0.15173333485921223 434.124375\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1220  --------------------------\n",
      "Train loss (all, class, reg): 45.9012756565639 0.11996190752301897 185.89393973214285\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.74722412109375 0.38899998982747397 626.6798958333334\n",
      "Test accuracy: 0.8533333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1230  --------------------------\n",
      "Train loss (all, class, reg): 45.8011468069894 0.06618095397949218 244.26457589285715\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 50.4925114440918 0.27 467.7305729166667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1240  --------------------------\n",
      "Train loss (all, class, reg): 45.931324419294086 0.02898095267159598 330.2282142857143\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 50.818217519124346 0.11353333791097005 652.9709895833333\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1250  --------------------------\n",
      "Train loss (all, class, reg): 45.84316759381976 0.06975238255092076 266.71991071428573\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss (all, class, reg): 50.50320373535156 0.1499555460611979 403.9574479166667\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1260  --------------------------\n",
      "Train loss (all, class, reg): 45.92999574933733 0.09365713936941965 174.57989955357144\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss (all, class, reg): 50.79828898111979 0.23591110229492188 622.501875\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1270  --------------------------\n",
      "Train loss (all, class, reg): 45.8525051007952 0.12911429268973215 162.46770089285715\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 50.49330546061198 0.0926444435119629 632.1063541666666\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1280  --------------------------\n",
      "Train loss (all, class, reg): 45.86916152954102 0.06151428767613002 225.18790178571427\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 50.77527770996094 0.07406666437784831 671.4596875\n",
      "Test accuracy: 0.85\n",
      "Epoch:  1290  --------------------------\n",
      "Train loss (all, class, reg): 45.92364079066685 0.09325714111328125 206.01915178571429\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 50.33467198689779 0.12448889414469401 708.7420833333333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1300  --------------------------\n",
      "Train loss (all, class, reg): 45.7800766645159 0.05124761853899275 254.92736607142857\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss (all, class, reg): 50.113465067545576 0.3565778096516927 626.2455208333333\n",
      "Test accuracy: 0.88\n",
      "Epoch:  1310  --------------------------\n",
      "Train loss (all, class, reg): 45.75391732352121 0.09598094395228794 220.48526785714284\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 50.53442352294922 0.027422224680582682 617.2403645833333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1320  --------------------------\n",
      "Train loss (all, class, reg): 45.625886949811665 0.021695237840924943 280.3614732142857\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss (all, class, reg): 51.03589813232422 0.06857777913411459 611.8974479166667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1330  --------------------------\n",
      "Train loss (all, class, reg): 45.77198972429548 0.10176191057477678 227.04707589285715\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.23195215861003 0.03740000089009603 634.0741666666667\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1340  --------------------------\n",
      "Train loss (all, class, reg): 45.69475622994559 0.025114285605294363 193.86633928571428\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.04505859375 0.24502222696940104 492.54552083333334\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1350  --------------------------\n",
      "Train loss (all, class, reg): 45.75993715558733 0.1187142835344587 218.94069196428572\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 50.54367950439453 0.33942222595214844 532.26296875\n",
      "Test accuracy: 0.85\n",
      "Epoch:  1360  --------------------------\n",
      "Train loss (all, class, reg): 45.80314531598772 0.07866666521344866 215.22299107142857\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 50.31506571451823 0.20093332926432292 721.0633854166666\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1370  --------------------------\n",
      "Train loss (all, class, reg): 45.891256888253345 0.09539047241210938 243.0084375\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.49034352620443 0.0632444445292155 559.5511979166666\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  1380  --------------------------\n",
      "Train loss (all, class, reg): 45.993535439627514 0.025399998256138392 274.60053571428574\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 50.918660430908204 0.26682223002115885 648.1553125\n",
      "Test accuracy: 0.85\n",
      "Epoch:  1390  --------------------------\n",
      "Train loss (all, class, reg): 45.905982012067525 0.08574285234723772 189.37058035714287\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 50.5870437113444 0.15562222798665365 500.81307291666667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1400  --------------------------\n",
      "Train loss (all, class, reg): 45.97741971697126 0.01798095294407436 225.81419642857142\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.49898157755534 0.053155555725097656 696.760625\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1410  --------------------------\n",
      "Train loss (all, class, reg): 46.041088256835934 0.093990478515625 252.1378125\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 50.67346740722656 0.314022216796875 624.36203125\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1420  --------------------------\n",
      "Train loss (all, class, reg): 45.9323596409389 0.015809523718697684 206.61290178571429\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 50.754497375488285 0.13286666870117186 672.52625\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1430  --------------------------\n",
      "Train loss (all, class, reg): 46.167605678013395 0.02399047579084124 208.53473214285714\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.50750605265299 0.2823778025309245 564.1086458333333\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1440  --------------------------\n",
      "Train loss (all, class, reg): 46.03326793125697 0.03792380741664342 222.84870535714285\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.1904753112793 0.46264444986979164 439.6254166666667\n",
      "Test accuracy: 0.85\n",
      "Epoch:  1450  --------------------------\n",
      "Train loss (all, class, reg): 46.014233006068636 0.10281905038016183 178.28306919642858\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 50.71233103434245 0.1512000020345052 507.3990625\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1460  --------------------------\n",
      "Train loss (all, class, reg): 45.9734950038365 0.11658094133649553 240.99386160714286\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 50.72424916585287 0.1806000010172526 610.8\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1470  --------------------------\n",
      "Train loss (all, class, reg): 46.06520289829799 0.0938380868094308 256.93707589285714\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 50.64323740641276 0.15673333485921223 792.67625\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1480  --------------------------\n",
      "Train loss (all, class, reg): 45.92475193568638 0.11864761352539062 157.43667410714286\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.646236928304035 0.05308888753255208 717.0353645833334\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1490  --------------------------\n",
      "Train loss (all, class, reg): 45.99276951381138 0.015619049072265625 252.9465625\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 50.749007314046224 0.14255555470784506 553.9974479166667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1500  --------------------------\n",
      "Train loss (all, class, reg): 45.92822023664202 0.01322857175554548 257.85162946428574\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 50.6818276977539 0.09284444173177084 687.0819270833333\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1510  --------------------------\n",
      "Train loss (all, class, reg): 45.818206678118024 0.016476192474365235 239.1199107142857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.7521836344401 0.37708892822265627 491.8034895833333\n",
      "Test accuracy: 0.85\n",
      "Epoch:  1520  --------------------------\n",
      "Train loss (all, class, reg): 45.945284293038505 0.09152380807059152 227.52466517857144\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.903446146647134 0.5364666239420572 549.0404166666667\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1530  --------------------------\n",
      "Train loss (all, class, reg): 46.10545680454799 0.013276190076555524 253.61\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 50.69490173339844 0.7435333251953125 531.6038020833333\n",
      "Test accuracy: 0.8633333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1540  --------------------------\n",
      "Train loss (all, class, reg): 46.024837493896484 0.022780952453613282 260.84828125\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 50.83337168375651 0.05239999771118164 484.76765625\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1550  --------------------------\n",
      "Train loss (all, class, reg): 46.10338121686663 0.040514286586216516 247.3584375\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 50.93919637044271 0.13835554758707683 578.3205729166667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1560  --------------------------\n",
      "Train loss (all, class, reg): 46.19819351196289 0.05491428920200893 257.69279017857144\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.259464772542316 0.20871111551920574 458.13989583333336\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1570  --------------------------\n",
      "Train loss (all, class, reg): 46.0348667035784 0.05747619083949498 186.768203125\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.249382985432945 0.14371111551920573 715.6742708333334\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1580  --------------------------\n",
      "Train loss (all, class, reg): 46.15333932059152 0.04521905081612723 249.46828125\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.5340939839681 0.10155555089314779 628.5673958333333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1590  --------------------------\n",
      "Train loss (all, class, reg): 46.05820765904018 0.1728761945452009 195.89609375\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.08368103027344 0.8269332885742188 485.9192708333333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1600  --------------------------\n",
      "Train loss (all, class, reg): 46.169288526262555 0.034733330862862725 203.45564732142856\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.77401936848958 0.6470444742838541 477.50614583333333\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1610  --------------------------\n",
      "Train loss (all, class, reg): 46.06589385986328 0.0167047609601702 243.4935267857143\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 51.19577804565429 0.27362223307291667 487.1634375\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1620  --------------------------\n",
      "Train loss (all, class, reg): 46.23536889212472 0.014685713904244559 260.3868080357143\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.453367411295574 0.3482666524251302 601.3186979166667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1630  --------------------------\n",
      "Train loss (all, class, reg): 46.17412009102958 0.2488857160295759 222.44888392857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.50639953613281 0.3132666778564453 747.1733854166666\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1640  --------------------------\n",
      "Train loss (all, class, reg): 46.128465750558036 0.02208571434020996 320.9511607142857\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.66030370076498 0.09542222340901693 619.1453125\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1650  --------------------------\n",
      "Train loss (all, class, reg): 46.1551176234654 0.19837142944335937 251.20457589285715\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.36220494588216 0.07935555775960286 663.92671875\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1660  --------------------------\n",
      "Train loss (all, class, reg): 46.0644654410226 0.018047618865966796 302.7131919642857\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.32799926757812 0.11851112365722656 673.7988020833334\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  1670  --------------------------\n",
      "Train loss (all, class, reg): 46.00085244315011 0.0651999991280692 222.19267857142856\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 51.32930531819662 0.9425999959309895 648.90890625\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1680  --------------------------\n",
      "Train loss (all, class, reg): 46.119950234549385 0.011914285932268415 235.27535714285713\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.992173970540364 0.17786666870117188 576.3089583333333\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  1690  --------------------------\n",
      "Train loss (all, class, reg): 46.06708435058594 0.020990476608276368 285.66272321428573\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.96359608968099 0.26273330688476565 610.7555208333333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1700  --------------------------\n",
      "Train loss (all, class, reg): 46.08960200718471 0.018714286259242468 259.8934375\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.132404479980465 0.3181111145019531 503.7964583333333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1710  --------------------------\n",
      "Train loss (all, class, reg): 45.96678636823382 0.01677142824445452 329.3754464285714\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.250486297607424 0.1087777837117513 529.6305729166667\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1720  --------------------------\n",
      "Train loss (all, class, reg): 46.184063938685824 0.07173333304268974 218.09549107142857\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 51.395101877848305 0.3977333577473958 613.4391666666667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1730  --------------------------\n",
      "Train loss (all, class, reg): 46.02670582362584 0.03876190458025251 187.2965625\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.43819920857747 0.6066444905598959 522.8436458333333\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1740  --------------------------\n",
      "Train loss (all, class, reg): 45.958866402762276 0.04960000174386161 244.96055803571429\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.11566380818685 0.06420000076293945 557.86953125\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1750  --------------------------\n",
      "Train loss (all, class, reg): 45.943292694091795 0.03196190425327846 252.9489955357143\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 51.06672297159831 0.22942222595214845 594.14734375\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1760  --------------------------\n",
      "Train loss (all, class, reg): 45.82828844342913 0.02016190528869629 254.42546875\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.83690862019857 0.3212888844807943 605.2095833333333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1770  --------------------------\n",
      "Train loss (all, class, reg): 46.1249777003697 0.0608952386038644 260.5159375\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 51.23464904785156 0.39997777303059895 506.6709375\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1780  --------------------------\n",
      "Train loss (all, class, reg): 46.124249703543526 0.09435237339564732 236.5897767857143\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.3543532816569 0.09751111348470053 516.5190625\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1790  --------------------------\n",
      "Train loss (all, class, reg): 46.051842215401784 0.07390475681849888 209.6521875\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.48508860270182 0.09180000305175781 509.1994270833333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1800  --------------------------\n",
      "Train loss (all, class, reg): 46.18022332327706 0.030399998256138393 200.68082589285714\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.363242085774736 0.19424444834391277 489.19546875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1810  --------------------------\n",
      "Train loss (all, class, reg): 46.26650161743164 0.011752382005964008 253.31819196428572\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.455287272135415 0.3044666798909505 566.1446354166667\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1820  --------------------------\n",
      "Train loss (all, class, reg): 46.293108128138954 0.08291427612304687 188.68779017857142\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.40850494384765 0.2258666483561198 675.8728125\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1830  --------------------------\n",
      "Train loss (all, class, reg): 46.22135175432478 0.02013333320617676 289.851875\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 51.31029103597005 0.14546666463216146 530.8146354166666\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1840  --------------------------\n",
      "Train loss (all, class, reg): 46.31599389212472 0.014666666303362165 282.76564732142856\n",
      "Train accuracy: 0.9514285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (all, class, reg): 51.27140370686849 0.21442222595214844 479.89348958333335\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1850  --------------------------\n",
      "Train loss (all, class, reg): 46.378209904262 0.028333334241594586 256.9518973214286\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 51.342358907063804 0.378888905843099 474.3553645833333\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1860  --------------------------\n",
      "Train loss (all, class, reg): 46.30521041870117 0.029733330862862725 239.3440625\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.58048344930013 0.0878000005086263 732.45859375\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1870  --------------------------\n",
      "Train loss (all, class, reg): 46.30979091099331 0.07012381417410714 220.78944196428571\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.446367543538415 0.18813334147135416 486.63677083333334\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1880  --------------------------\n",
      "Train loss (all, class, reg): 46.33395335606166 0.014542857578822545 217.87417410714286\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.534622497558594 0.1223111089070638 515.66359375\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1890  --------------------------\n",
      "Train loss (all, class, reg): 46.34355292184012 0.019876191275460378 258.75613839285717\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.561211853027345 0.27611114501953127 643.6735416666667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1900  --------------------------\n",
      "Train loss (all, class, reg): 46.274840196881975 0.027095238821847098 230.09683035714286\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.64300760904948 0.06582221984863282 632.9941145833334\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1910  --------------------------\n",
      "Train loss (all, class, reg): 46.33220846993583 0.07067618778773717 187.16795758928572\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.2479438273112 0.4833556111653646 678.9611458333334\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1920  --------------------------\n",
      "Train loss (all, class, reg): 46.27185038975307 0.02167619160243443 289.8488392857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.705393676757815 0.2892444356282552 483.9046875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1930  --------------------------\n",
      "Train loss (all, class, reg): 46.40835623604911 0.027742857251848493 223.96970982142858\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.53076934814453 0.18068888346354167 597.0361458333333\n",
      "Test accuracy: 0.88\n",
      "Epoch:  1940  --------------------------\n",
      "Train loss (all, class, reg): 46.324322814941404 0.09990476335797992 253.37446428571428\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.341342264811196 0.29335556030273435 481.8407291666667\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1950  --------------------------\n",
      "Train loss (all, class, reg): 46.344403119768415 0.0868857192993164 283.42390625\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 51.342185770670575 0.10640000661214193 631.6785416666667\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  1960  --------------------------\n",
      "Train loss (all, class, reg): 46.26475402832031 0.09733334132603237 179.03808035714286\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 51.4335476175944 0.05648888905843099 576.4197916666667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1970  --------------------------\n",
      "Train loss (all, class, reg): 46.26713461739676 0.03362857273646763 240.64794642857143\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.67582163492838 0.2444000244140625 632.8746354166667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1980  --------------------------\n",
      "Train loss (all, class, reg): 46.26313836233957 0.0548857171194894 234.86645089285713\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.63973612467448 0.27186665852864583 496.31104166666665\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1990  --------------------------\n",
      "Train loss (all, class, reg): 46.37761710030692 0.019495237895420618 245.1638169642857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.67076268513998 0.24468889872233074 537.2780729166667\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2000  --------------------------\n",
      "Train loss (all, class, reg): 46.21052520751953 0.023333334241594585 207.24283482142857\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 51.81720184326172 0.22246668497721353 592.4414583333333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2010  --------------------------\n",
      "Train loss (all, class, reg): 46.24147718157087 0.030276189531598774 283.66185267857145\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.92443394978841 0.11815555572509766 610.0888541666667\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2020  --------------------------\n",
      "Train loss (all, class, reg): 46.42743390764509 0.012800001416887556 272.55834821428573\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.61466720581055 0.41775555928548175 478.27630208333335\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2030  --------------------------\n",
      "Train loss (all, class, reg): 46.28355601719448 0.054190472194126676 217.81209821428573\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.0334353129069 0.4014666748046875 592.3156770833333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2040  --------------------------\n",
      "Train loss (all, class, reg): 46.36795447213309 0.0651904787336077 318.9121205357143\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 52.13246536254883 0.05966666539510091 522.9803125\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  2050  --------------------------\n",
      "Train loss (all, class, reg): 46.373086831229074 0.04748571123395647 289.3594196428571\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.746414489746094 0.3783555603027344 431.51458333333335\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2060  --------------------------\n",
      "Train loss (all, class, reg): 46.388792441231864 0.01855238233293806 279.1937723214286\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.619944661458334 0.2263555399576823 633.2578125\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2070  --------------------------\n",
      "Train loss (all, class, reg): 46.48678658621652 0.08487618582589286 204.98705357142856\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.65107350667318 0.5698666381835937 481.28739583333333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2080  --------------------------\n",
      "Train loss (all, class, reg): 46.36386383056641 0.024638094220842635 216.93979910714285\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.87439259847005 0.29002222696940105 505.13057291666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2090  --------------------------\n",
      "Train loss (all, class, reg): 46.43133677891323 0.08186666761125837 225.5534375\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.75080729166667 0.2155555470784505 516.7182291666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2100  --------------------------\n",
      "Train loss (all, class, reg): 46.51433909824916 0.10245714460100447 182.79172991071428\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.94392883300781 0.31197776794433596 542.9027604166666\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2110  --------------------------\n",
      "Train loss (all, class, reg): 46.50185320172991 0.1850952366420201 184.42964285714285\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.83708770751953 0.2556000264485677 568.10359375\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2120  --------------------------\n",
      "Train loss (all, class, reg): 46.445766993931365 0.19054286411830357 259.70819196428573\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.70587865193685 0.3119555409749349 678.96421875\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2130  --------------------------\n",
      "Train loss (all, class, reg): 46.41464815412249 0.023209525517054966 270.52645089285716\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.90552459716797 0.38813334147135414 490.74994791666666\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2140  --------------------------\n",
      "Train loss (all, class, reg): 46.39271946498326 0.015219048091343472 236.64408482142858\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.92713399251302 0.11333334604899088 686.9344791666666\n",
      "Test accuracy: 0.8733333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2150  --------------------------\n",
      "Train loss (all, class, reg): 46.47184428623744 0.012666666848318917 230.31361607142858\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss (all, class, reg): 51.86261423746745 0.15300000508626302 445.9553125\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2160  --------------------------\n",
      "Train loss (all, class, reg): 46.49158238002232 0.022228572028023856 288.6356696428571\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.993324534098306 0.20935555775960288 485.9856770833333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2170  --------------------------\n",
      "Train loss (all, class, reg): 46.43492736816406 0.025085716247558593 266.08542410714284\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.584572855631514 0.14446667989095052 436.4342447916667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2180  --------------------------\n",
      "Train loss (all, class, reg): 46.48315294538225 0.017952380861554828 223.55859375\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.73780131022136 0.07200000127156575 520.4318229166666\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2190  --------------------------\n",
      "Train loss (all, class, reg): 46.44434923444476 0.025304761614118303 263.0328348214286\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.522601216634115 0.23426668802897135 598.97609375\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2200  --------------------------\n",
      "Train loss (all, class, reg): 46.52609366280692 0.08592381613595144 225.93205357142858\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.8436924235026 0.25195556640625 532.6963541666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2210  --------------------------\n",
      "Train loss (all, class, reg): 46.35082621983119 0.05916191101074219 274.79488839285716\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 51.34549570719401 0.135977783203125 571.8292708333333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2220  --------------------------\n",
      "Train loss (all, class, reg): 46.40816369192941 0.014742856706891742 262.0403125\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 51.37963358561198 0.1638888931274414 606.4584375\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2230  --------------------------\n",
      "Train loss (all, class, reg): 46.37116258893694 0.06451429094587054 224.0525\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.81604415893555 0.28513333638509114 527.13984375\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  2240  --------------------------\n",
      "Train loss (all, class, reg): 46.3863332257952 0.09102857862200056 208.0746875\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 51.819799194335936 0.29959999084472655 515.6044791666667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2250  --------------------------\n",
      "Train loss (all, class, reg): 46.35056368146624 0.009257143565586635 250.17484375\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.67937739054362 0.37220001220703125 424.85963541666666\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2260  --------------------------\n",
      "Train loss (all, class, reg): 46.337803213936944 0.012742857251848493 255.20714285714286\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.80477162679036 0.03319999694824219 595.3306770833333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2270  --------------------------\n",
      "Train loss (all, class, reg): 46.38747041974749 0.026009524209158762 223.86787946428572\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.14425267537435 0.3341111246744792 500.2900520833333\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  2280  --------------------------\n",
      "Train loss (all, class, reg): 46.25564627511161 0.0687142835344587 212.59939732142857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.855058949788415 0.5737777709960937 451.5884375\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2290  --------------------------\n",
      "Train loss (all, class, reg): 46.15899629865374 0.01832380975995745 253.33348214285715\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.77150512695312 0.28759999593098956 641.53984375\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2300  --------------------------\n",
      "Train loss (all, class, reg): 46.373626883370534 0.03577142987932478 244.25404017857142\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.32820510864258 0.37 547.1741666666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2310  --------------------------\n",
      "Train loss (all, class, reg): 46.28541739327567 0.017866667338779993 261.81529017857144\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.7408154296875 0.4013111114501953 493.5521875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2320  --------------------------\n",
      "Train loss (all, class, reg): 46.30925286429269 0.02632380894252232 269.81352678571426\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.63903869628906 0.07920000076293945 615.4965625\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2330  --------------------------\n",
      "Train loss (all, class, reg): 46.28733849661691 0.020971429007393974 241.84165178571428\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.437999674479165 0.24 622.6293229166666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2340  --------------------------\n",
      "Train loss (all, class, reg): 46.40395817347935 0.01991428647722517 316.0233928571429\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.38705637613932 0.22313334147135416 448.02369791666666\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2350  --------------------------\n",
      "Train loss (all, class, reg): 46.50320874895368 0.0789999989100865 272.3430357142857\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.49977584838867 0.04195555369059245 616.7149479166667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2360  --------------------------\n",
      "Train loss (all, class, reg): 46.24952165876116 0.014428571973528181 194.14066964285715\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.66919504801432 0.24735555013020832 543.0088541666667\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2370  --------------------------\n",
      "Train loss (all, class, reg): 46.448643537248884 0.02009523800441197 273.22426339285715\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.91236348470052 0.07239999771118164 660.3141145833333\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2380  --------------------------\n",
      "Train loss (all, class, reg): 46.57350123814174 0.024000001634870257 278.8709375\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.89477854410807 0.18800000508626302 621.0111458333333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2390  --------------------------\n",
      "Train loss (all, class, reg): 46.42228910173689 0.07048570905412946 189.67417410714285\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.00223505655924 0.10319999694824218 475.14661458333336\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  2400  --------------------------\n",
      "Train loss (all, class, reg): 46.413923012869695 0.01617142813546317 220.47745535714284\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.094201202392576 0.05739999771118164 625.3381770833333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2410  --------------------------\n",
      "Train loss (all, class, reg): 46.414359152657646 0.08166666848318918 263.10662946428573\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 52.25628606160482 0.5819111124674479 439.2288541666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2420  --------------------------\n",
      "Train loss (all, class, reg): 46.55768120901925 0.028942854745047434 262.485625\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.35480646769206 0.24742220560709635 477.3880208333333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2430  --------------------------\n",
      "Train loss (all, class, reg): 46.4985920715332 0.021800000326974052 289.57301339285715\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 52.04357462565104 0.05228889147440592 648.8438020833333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2440  --------------------------\n",
      "Train loss (all, class, reg): 46.62766381399972 0.0873809541974749 229.61859375\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 52.15917673746745 0.685133310953776 568.7170833333333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2450  --------------------------\n",
      "Train loss (all, class, reg): 46.52953473772322 0.03501904896327428 242.41716517857142\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.32515828450521 0.4631999715169271 507.69916666666666\n",
      "Test accuracy: 0.8666666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2460  --------------------------\n",
      "Train loss (all, class, reg): 46.61640908377511 0.022809524536132813 299.30066964285714\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.39674784342448 0.2835110982259115 740.2090625\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2470  --------------------------\n",
      "Train loss (all, class, reg): 46.44813901628767 0.019980951036725727 220.36698660714285\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.19423136393229 0.12122222900390625 563.2208854166666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2480  --------------------------\n",
      "Train loss (all, class, reg): 46.57357940673828 0.04730475834437779 237.19549107142856\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.975974019368486 0.10782222747802735 630.9285416666667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2490  --------------------------\n",
      "Train loss (all, class, reg): 46.579398280552454 0.09209522792271205 225.9821875\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.13577657063802 0.1343777847290039 554.61375\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2500  --------------------------\n",
      "Train loss (all, class, reg): 46.64702634538923 0.021904762813023157 268.94125\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 51.980119120279944 0.1862000020345052 471.68635416666666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2510  --------------------------\n",
      "Train loss (all, class, reg): 46.4283205304827 0.02554285866873605 229.76151785714285\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.45293009440104 0.13584443410237632 503.68182291666665\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2520  --------------------------\n",
      "Train loss (all, class, reg): 46.57607025146484 0.015304761614118303 215.84558035714286\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.31134536743164 0.10122222900390625 578.57171875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2530  --------------------------\n",
      "Train loss (all, class, reg): 46.65820151192801 0.07204762050083706 292.1505580357143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.94381205240885 0.8239554850260417 467.1221875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2540  --------------------------\n",
      "Train loss (all, class, reg): 46.64712378365653 0.09796190534319196 187.31607142857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.290628051757814 0.29893333435058594 611.3066666666666\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2550  --------------------------\n",
      "Train loss (all, class, reg): 46.59100322178432 0.008752381461007255 338.93212053571426\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.30668757120768 0.23186665852864582 648.6469791666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2560  --------------------------\n",
      "Train loss (all, class, reg): 46.48025033133371 0.08641904558454241 207.54348214285713\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.214717915852866 0.2045111083984375 662.83296875\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2570  --------------------------\n",
      "Train loss (all, class, reg): 46.55041351318359 0.07866666521344866 257.3800446428571\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.604915873209634 0.3283777872721354 641.9507291666666\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2580  --------------------------\n",
      "Train loss (all, class, reg): 46.7161839730399 0.020619046347481865 204.2997544642857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.24367874145508 0.10151111602783203 475.8140104166667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2590  --------------------------\n",
      "Train loss (all, class, reg): 46.589820382254466 0.07129523141043527 264.2562723214286\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.473756815592445 1.0351778157552083 788.46109375\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2600  --------------------------\n",
      "Train loss (all, class, reg): 46.60114770071847 0.024733330862862724 209.99017857142857\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.45973353068034 0.11986666361490886 512.6444791666667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2610  --------------------------\n",
      "Train loss (all, class, reg): 46.64796502249582 0.0565904780796596 193.73386160714287\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.27940063476562 0.25286666870117186 679.8320833333333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2620  --------------------------\n",
      "Train loss (all, class, reg): 46.49210649762835 0.009609524181910923 282.3295758928571\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.09089548746745 0.14855557759602864 510.18671875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2630  --------------------------\n",
      "Train loss (all, class, reg): 46.66021475655692 0.02556190490722656 246.44441964285716\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.32573959350586 0.22871111551920573 527.5658333333333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2640  --------------------------\n",
      "Train loss (all, class, reg): 46.51299255371094 0.056276190621512276 240.3722767857143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.34579956054687 0.1878222147623698 509.66760416666665\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2650  --------------------------\n",
      "Train loss (all, class, reg): 46.58679944719587 0.02623809814453125 281.7554017857143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.19308904012044 0.19704443613688152 709.133125\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2660  --------------------------\n",
      "Train loss (all, class, reg): 46.61222475324358 0.02654285703386579 213.25091517857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 52.34622985839844 0.07782222112019857 547.9969791666666\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2670  --------------------------\n",
      "Train loss (all, class, reg): 46.76941735403879 0.010247619492667061 305.03683035714283\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.42201802571615 0.21399998982747395 633.7897395833334\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2680  --------------------------\n",
      "Train loss (all, class, reg): 46.701847163609095 0.06809523446219308 235.85232142857143\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss (all, class, reg): 52.508058369954426 0.340133310953776 473.8015625\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2690  --------------------------\n",
      "Train loss (all, class, reg): 46.749137638636995 0.07004761832101004 238.60390625\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 52.40088312784831 0.21779998779296875 544.3930208333334\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2700  --------------------------\n",
      "Train loss (all, class, reg): 46.69178697858538 0.06476189749581474 228.4828794642857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.09074991861979 0.21233334859212238 657.68609375\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2710  --------------------------\n",
      "Train loss (all, class, reg): 46.663331843784874 0.03 227.64415178571429\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.46371622721354 0.33851109822591147 560.8286979166667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2720  --------------------------\n",
      "Train loss (all, class, reg): 46.73606057303292 0.029476190294538226 229.89035714285714\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 52.22377395629883 0.025444444020589194 535.7858854166667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2730  --------------------------\n",
      "Train loss (all, class, reg): 46.585166015625 0.1876857212611607 214.31160714285716\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.631339365641274 0.13706666310628254 380.42635416666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2740  --------------------------\n",
      "Train loss (all, class, reg): 46.677469177246095 0.015619047709873744 249.07216517857142\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.40267827351888 0.06684444427490234 581.78109375\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2750  --------------------------\n",
      "Train loss (all, class, reg): 46.685736280168804 0.07382857186453683 177.54602678571428\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.2458322652181 0.44175557454427083 600.1580208333334\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2760  --------------------------\n",
      "Train loss (all, class, reg): 46.736693398611884 0.03293333326067243 271.4395982142857\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.69049026489258 0.3016444142659505 543.5891666666666\n",
      "Test accuracy: 0.8666666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  2770  --------------------------\n",
      "Train loss (all, class, reg): 46.66765047345843 0.014028570992606028 281.2036830357143\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.32000696818034 0.14660001118977864 648.1172916666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2780  --------------------------\n",
      "Train loss (all, class, reg): 46.7620509992327 0.0122761903490339 241.10203125\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.75090337117513 0.13466667175292968 538.1313541666667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2790  --------------------------\n",
      "Train loss (all, class, reg): 46.72267881120954 0.06037143162318638 211.15816964285713\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.6228076171875 0.26062222798665363 748.8134895833333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2800  --------------------------\n",
      "Train loss (all, class, reg): 46.70021198817662 0.019628571101597377 227.20098214285716\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.11578353881836 0.06295555750528971 649.3211979166666\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2810  --------------------------\n",
      "Train loss (all, class, reg): 46.64355769566127 0.009180953162057059 305.41707589285716\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.26094670613607 0.09504444122314454 494.8353125\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2820  --------------------------\n",
      "Train loss (all, class, reg): 46.855535321916854 0.01779047693525042 220.2825\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss (all, class, reg): 52.47612711588542 0.2973555501302083 589.7108854166667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2830  --------------------------\n",
      "Train loss (all, class, reg): 46.62867013113839 0.022485715321132114 293.2887053571429\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.603212381998695 0.09715555826822916 538.1325\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2840  --------------------------\n",
      "Train loss (all, class, reg): 46.60675074986049 0.04711428506033761 224.49964285714285\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.58556767781575 0.29028889973958333 538.0511458333333\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2850  --------------------------\n",
      "Train loss (all, class, reg): 46.690498700823106 0.017047620500837055 239.28660714285715\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.4536137898763 0.1329111099243164 601.8808333333334\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2860  --------------------------\n",
      "Train loss (all, class, reg): 46.625831211635045 0.07015237535749162 211.70953125\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.33771016438802 0.14322222391764322 464.7828645833333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2870  --------------------------\n",
      "Train loss (all, class, reg): 46.71401657104492 0.061790477207728796 231.79261160714285\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 52.772830912272134 0.22897776285807292 735.0969791666666\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2880  --------------------------\n",
      "Train loss (all, class, reg): 46.59106571742466 0.02231428691319057 243.8239732142857\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.67960530598958 0.1212444559733073 660.3715104166666\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2890  --------------------------\n",
      "Train loss (all, class, reg): 46.74722497122628 0.013799999782017298 303.8067857142857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.16709925333659 0.21466664632161458 422.90221354166664\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  2900  --------------------------\n",
      "Train loss (all, class, reg): 46.67848262241908 0.04448571341378348 247.66745535714287\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.54931584676107 0.08795555114746094 612.6342708333333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2910  --------------------------\n",
      "Train loss (all, class, reg): 46.75509573800223 0.013199999673025948 236.3986607142857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.739185434977216 0.29008890787760416 686.64125\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  2920  --------------------------\n",
      "Train loss (all, class, reg): 46.794023960658485 0.024800000871930804 268.7177901785714\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.463568420410155 0.06997777938842774 648.17375\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2930  --------------------------\n",
      "Train loss (all, class, reg): 46.83947256905692 0.017552381243024554 237.36158482142858\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 52.713304850260414 0.38753334045410154 636.7859375\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2940  --------------------------\n",
      "Train loss (all, class, reg): 46.75981196812221 0.01762857300894601 254.85464285714286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.53482228597005 0.8168000284830729 584.3034375\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  2950  --------------------------\n",
      "Train loss (all, class, reg): 46.66912078857422 0.032209524427141464 186.64140625\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 52.97799290974935 0.342933349609375 640.073125\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2960  --------------------------\n",
      "Train loss (all, class, reg): 46.71961140223912 0.035961908612932476 225.11765625\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 52.52970733642578 0.2986000061035156 600.9208854166667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2970  --------------------------\n",
      "Train loss (all, class, reg): 46.77564714704241 0.011371428625924246 304.5102232142857\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 52.475000915527346 0.1394666544596354 643.7999479166666\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2980  --------------------------\n",
      "Train loss (all, class, reg): 46.93823717389788 0.03541904721941267 285.03292410714283\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 52.860991923014325 0.09620000203450521 658.0659895833334\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2990  --------------------------\n",
      "Train loss (all, class, reg): 46.77703377859933 0.14714283534458705 253.24263392857142\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.856489715576174 0.18077779134114583 673.8691145833334\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3000  --------------------------\n",
      "Train loss (all, class, reg): 46.66955017089844 0.02601904732840402 251.14066964285715\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.22057434082031 0.49708892822265627 450.07807291666666\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3010  --------------------------\n",
      "Train loss (all, class, reg): 46.680242745535715 0.027647617885044645 255.01020089285714\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.0050287882487 0.3187555440266927 658.75625\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  3020  --------------------------\n",
      "Train loss (all, class, reg): 46.80640638078962 0.0358380971636091 235.21194196428573\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.372941385904944 0.25220001220703125 477.94473958333333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  3030  --------------------------\n",
      "Train loss (all, class, reg): 46.61223384312221 0.08261905125209264 240.88064732142857\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.70710800170898 0.2530888875325521 479.6056770833333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  3040  --------------------------\n",
      "Train loss (all, class, reg): 46.579943259102954 0.011952381134033203 273.6647544642857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 52.65529052734375 0.31528887430826824 609.1994791666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3050  --------------------------\n",
      "Train loss (all, class, reg): 46.81218985421317 0.018742858341762 244.59301339285713\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 52.284869486490884 0.5099110921223958 711.9671354166667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3060  --------------------------\n",
      "Train loss (all, class, reg): 46.78224321637835 0.01986666815621512 210.50725446428572\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss (all, class, reg): 52.57777262369792 0.1581777826944987 540.1684895833333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3070  --------------------------\n",
      "Train loss (all, class, reg): 46.94234379359654 0.011619047437395369 257.90350446428573\n",
      "Train accuracy: 0.9442857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (all, class, reg): 52.52254364013672 0.4275111389160156 617.20828125\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  3080  --------------------------\n",
      "Train loss (all, class, reg): 46.902866799490795 0.017333333151681084 263.8136830357143\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.55150553385417 0.2901777648925781 468.8097916666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3090  --------------------------\n",
      "Train loss (all, class, reg): 46.830340728759765 0.08394286019461496 253.68279017857142\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.41046742757162 0.5233556111653646 510.8876041666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3100  --------------------------\n",
      "Train loss (all, class, reg): 46.869356580461776 0.02857142857142857 226.24488839285715\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 52.80927098592122 0.5218443806966145 477.0290625\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3110  --------------------------\n",
      "Train loss (all, class, reg): 46.79469955444336 0.012800000054495676 245.10089285714287\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 52.38562149047851 0.1818222173055013 640.7825520833334\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3120  --------------------------\n",
      "Train loss (all, class, reg): 46.96704086303711 0.07783810206821987 202.47276785714286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.61675323486328 0.3284222157796224 569.3097916666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3130  --------------------------\n",
      "Train loss (all, class, reg): 47.01393051147461 0.04033333369663784 296.56058035714284\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 52.52073028564453 0.11653333028157552 580.84953125\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3140  --------------------------\n",
      "Train loss (all, class, reg): 46.94340765816825 0.024190474918910434 219.34866071428573\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.81389389038086 0.0820888900756836 534.93109375\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3150  --------------------------\n",
      "Train loss (all, class, reg): 46.86619657244001 0.014571429661342075 202.35604910714287\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.777875315348304 0.3736444346110026 541.4358854166667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3160  --------------------------\n",
      "Train loss (all, class, reg): 46.81281531197684 0.024571426936558314 251.96859375\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 52.55408635457357 0.4311333211263021 431.320859375\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  3170  --------------------------\n",
      "Train loss (all, class, reg): 46.963769160679405 0.013676191057477678 232.75667410714286\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 52.744273783365884 0.2222222391764323 567.9836458333333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3180  --------------------------\n",
      "Train loss (all, class, reg): 46.88210220336914 0.030895238603864398 254.0258705357143\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.633028208414714 0.08177778244018555 549.5181770833333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  3190  --------------------------\n",
      "Train loss (all, class, reg): 46.9097524370466 0.18716190883091519 225.98868303571427\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 53.13041275024414 0.08888888676961262 713.1028125\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3200  --------------------------\n",
      "Train loss (all, class, reg): 46.9088155909947 0.0230952399117606 263.94060267857145\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.76841054280599 0.20306666056315104 499.98192708333335\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  3210  --------------------------\n",
      "Train loss (all, class, reg): 46.95299113682338 0.1381999969482422 203.04258928571429\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.48801035563151 0.1128222147623698 550.815\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3220  --------------------------\n",
      "Train loss (all, class, reg): 46.84973828996931 0.07355238233293805 246.11279017857143\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.93313873291016 0.5666222635904948 538.2241145833333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3230  --------------------------\n",
      "Train loss (all, class, reg): 46.94408748081752 0.02528571537562779 240.1359375\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.66312052408854 0.12266666412353516 410.05651041666664\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3240  --------------------------\n",
      "Train loss (all, class, reg): 46.959557451520645 0.050704759870256695 214.23424107142858\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.46600992838542 0.28879999796549477 763.2147395833333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3250  --------------------------\n",
      "Train loss (all, class, reg): 46.9146437726702 0.13865713936941965 214.59611607142858\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.29639948527018 0.15908888498942056 659.5456770833333\n",
      "Test accuracy: 0.86\n",
      "Epoch:  3260  --------------------------\n",
      "Train loss (all, class, reg): 46.83105826241629 0.10841905866350446 214.38227678571428\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.633658447265624 0.13433333079020182 608.2809895833333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3270  --------------------------\n",
      "Train loss (all, class, reg): 46.84209893362863 0.013619046892438615 279.27296875\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.65134979248047 0.15 516.3146875\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3280  --------------------------\n",
      "Train loss (all, class, reg): 47.07164544241769 0.013095238549368723 248.93904017857142\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.89263361612956 0.6318222045898437 392.1498697916667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  3290  --------------------------\n",
      "Train loss (all, class, reg): 47.003750871930805 0.06744761875697544 223.83169642857143\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.81224792480469 0.10806666056315105 543.1570833333334\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3300  --------------------------\n",
      "Train loss (all, class, reg): 47.026733834402904 0.02876190458025251 231.28125\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.64640391031901 0.1291333516438802 568.45703125\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3310  --------------------------\n",
      "Train loss (all, class, reg): 46.91316864013672 0.04569523402622768 229.1146875\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.852638448079425 0.5173555501302083 613.02390625\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3320  --------------------------\n",
      "Train loss (all, class, reg): 46.98225248064313 0.016342857905796596 270.61879464285715\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.700346069335936 0.17744444529215495 547.8664583333333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3330  --------------------------\n",
      "Train loss (all, class, reg): 47.01615271432059 0.13365713936941964 177.18621651785713\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.781182352701826 0.08095555623372395 677.51390625\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3340  --------------------------\n",
      "Train loss (all, class, reg): 46.981172005789624 0.016057143892560688 240.06642857142856\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.74088663736979 0.3325999959309896 602.61296875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3350  --------------------------\n",
      "Train loss (all, class, reg): 46.93590018136161 0.12347619192940848 219.00727678571428\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.623719482421876 0.18877777099609375 637.4997916666666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3360  --------------------------\n",
      "Train loss (all, class, reg): 47.01904933384487 0.11216190883091517 195.39328125\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 52.78049865722656 0.08437778472900391 551.42046875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3370  --------------------------\n",
      "Train loss (all, class, reg): 47.097478899274556 0.030199999128069196 246.40332589285714\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.07879475911459 0.3385777791341146 480.92411458333333\n",
      "Test accuracy: 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3380  --------------------------\n",
      "Train loss (all, class, reg): 47.0970679800851 0.05706666128976005 333.5793973214286\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 53.30366170247396 0.5034665934244792 466.58411458333336\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3390  --------------------------\n",
      "Train loss (all, class, reg): 46.91467143467494 0.07881904602050781 224.7602455357143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 52.76544667561849 0.2008222198486328 530.5966145833333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3400  --------------------------\n",
      "Train loss (all, class, reg): 47.00166996547154 0.07333333696637835 244.97392857142856\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.48223693847656 0.09748889287312826 603.4111458333333\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3410  --------------------------\n",
      "Train loss (all, class, reg): 46.99587162562779 0.01452380861554827 306.16546875\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 53.15969314575195 0.29771110534667966 521.20484375\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3420  --------------------------\n",
      "Train loss (all, class, reg): 46.88302302769252 0.020628570829119 219.10450892857142\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 52.901624857584636 0.19564445495605468 613.4606770833333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3430  --------------------------\n",
      "Train loss (all, class, reg): 47.05177191598075 0.10316189357212611 198.2825\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.79358703613281 0.10875555674235025 725.3475520833333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3440  --------------------------\n",
      "Train loss (all, class, reg): 46.94234453473772 0.018523808888026645 260.0821875\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.210041198730465 0.9537333170572917 892.4821875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  3450  --------------------------\n",
      "Train loss (all, class, reg): 47.02704330444336 0.019219048363821847 292.6482142857143\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss (all, class, reg): 52.823319600423176 0.10502221425374349 572.8205208333334\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3460  --------------------------\n",
      "Train loss (all, class, reg): 47.07663360595703 0.01471428462437221 250.17301339285714\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 53.21992797851563 0.1751111094156901 549.0222916666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3470  --------------------------\n",
      "Train loss (all, class, reg): 46.96882021222796 0.06234286172049386 253.32109375\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 53.10752899169922 0.030399999618530273 600.4025\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  3480  --------------------------\n",
      "Train loss (all, class, reg): 47.02521299089704 0.020685713631766182 243.24473214285715\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.976666819254554 0.0554888916015625 726.73890625\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3490  --------------------------\n",
      "Train loss (all, class, reg): 47.12267353602818 0.09017142159598214 270.36357142857145\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.18144231160482 0.11339998881022136 541.0346354166667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3500  --------------------------\n",
      "Train loss (all, class, reg): 46.98554203578404 0.026847621372767857 261.35421875\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.95438730875651 0.09937778472900391 508.92114583333336\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3510  --------------------------\n",
      "Train loss (all, class, reg): 47.1544698878697 0.0760857173374721 240.05140625\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.11690633138021 0.39431111653645834 553.73734375\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3520  --------------------------\n",
      "Train loss (all, class, reg): 46.951298239571706 0.03382857186453683 229.80734375\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.88663289388021 0.4287110900878906 422.08630208333335\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3530  --------------------------\n",
      "Train loss (all, class, reg): 46.904144461495534 0.0846190425327846 242.02466517857144\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.8859223429362 0.16811111450195312 666.74390625\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3540  --------------------------\n",
      "Train loss (all, class, reg): 46.97942164829799 0.01930476324898856 245.34578125\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.97931905110677 0.12466667175292968 562.5694791666666\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3550  --------------------------\n",
      "Train loss (all, class, reg): 46.91000723702567 0.09448571341378348 261.53140625\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 53.30592290242513 0.05133333206176758 669.2005208333334\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3560  --------------------------\n",
      "Train loss (all, class, reg): 46.92219696044922 0.009571428980146136 260.62883928571426\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.255179951985674 0.3735777791341146 831.0386458333334\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3570  --------------------------\n",
      "Train loss (all, class, reg): 46.98843032836914 0.026095237731933594 264.90058035714287\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 52.677347310384114 0.3767777506510417 536.4635416666666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3580  --------------------------\n",
      "Train loss (all, class, reg): 47.018524562290736 0.08768571036202567 223.16379464285714\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.68176991780599 0.1338666788736979 600.02765625\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3590  --------------------------\n",
      "Train loss (all, class, reg): 47.06677784511021 0.016533333914620536 223.25455357142857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.06516459147135 0.32779998779296876 648.9063541666667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3600  --------------------------\n",
      "Train loss (all, class, reg): 47.04918380737305 0.05150476728166853 258.19879464285714\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 52.937015482584634 0.21213333129882814 674.4055208333333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3610  --------------------------\n",
      "Train loss (all, class, reg): 46.94767183576312 0.01174285616193499 276.03734375\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 52.757654673258465 0.11386667887369792 517.1005208333333\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3620  --------------------------\n",
      "Train loss (all, class, reg): 46.850848541259765 0.07500000544956752 205.43816964285713\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 52.96590469360351 0.13817776997884115 500.15130208333335\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3630  --------------------------\n",
      "Train loss (all, class, reg): 46.881711992536275 0.12520001002720424 204.5885267857143\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 53.194337412516276 0.0784000015258789 565.73421875\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3640  --------------------------\n",
      "Train loss (all, class, reg): 47.01572963169643 0.08346666608537946 207.02232142857142\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.90277109781901 0.1997777811686198 470.52057291666665\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3650  --------------------------\n",
      "Train loss (all, class, reg): 46.901710314069476 0.0652857208251953 218.77020089285713\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 52.82432291666667 0.16537776947021485 593.5339583333333\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3660  --------------------------\n",
      "Train loss (all, class, reg): 47.03081351143973 0.087038083757673 268.98004464285714\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.854331970214844 0.9447332763671875 816.5408854166667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3670  --------------------------\n",
      "Train loss (all, class, reg): 47.09272866385324 0.022009522574288506 241.51785714285714\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.83347900390625 0.5079999796549479 493.26458333333335\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3680  --------------------------\n",
      "Train loss (all, class, reg): 46.97940329415458 0.014380950927734375 293.6850446428571\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 52.99130925496419 0.20124444325764973 579.81453125\n",
      "Test accuracy: 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  3690  --------------------------\n",
      "Train loss (all, class, reg): 46.84079594203404 0.07258094787597656 243.29883928571428\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.869001108805335 0.07099999745686848 646.7274479166666\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3700  --------------------------\n",
      "Train loss (all, class, reg): 47.09129612513951 0.07531428745814732 209.72459821428572\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.04837946573893 0.1029111099243164 688.9355729166666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3710  --------------------------\n",
      "Train loss (all, class, reg): 46.96070805140904 0.013333332879202707 309.8997991071429\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.91604553222656 0.1556666692097982 499.5442708333333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3720  --------------------------\n",
      "Train loss (all, class, reg): 46.94253149850028 0.019285714285714285 242.74185267857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.93807184855143 0.07433333079020182 532.2306770833334\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3730  --------------------------\n",
      "Train loss (all, class, reg): 46.86252493722098 0.01540952410016741 254.64486607142857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 53.01161346435547 0.05964444478352864 618.6477083333333\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3740  --------------------------\n",
      "Train loss (all, class, reg): 47.125160042899 0.07567619323730469 285.54162946428573\n",
      "Train accuracy: 0.94\n",
      "Test loss (all, class, reg): 53.161098887125654 0.187533327738444 535.5169270833334\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3750  --------------------------\n",
      "Train loss (all, class, reg): 47.010698569161555 0.020447619301932198 271.78183035714284\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.18422948201498 0.06482222239176433 596.0897916666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3760  --------------------------\n",
      "Train loss (all, class, reg): 47.02759116036551 0.031733335767473496 216.43662946428572\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 53.20941218058268 0.4704888916015625 433.88421875\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3770  --------------------------\n",
      "Train loss (all, class, reg): 47.11231615339007 0.022390475954328266 252.43361607142856\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.89940684000651 0.20495554606119792 588.1765104166667\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3780  --------------------------\n",
      "Train loss (all, class, reg): 47.08447291782924 0.08003808702741351 244.36542410714284\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.962903849283855 0.04917778015136719 582.0404166666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3790  --------------------------\n",
      "Train loss (all, class, reg): 47.109859183175224 0.08960000174386161 218.34850446428572\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 53.088345489501954 0.20120001475016275 501.84390625\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3800  --------------------------\n",
      "Train loss (all, class, reg): 47.00789221627372 0.021952381134033205 304.67111607142857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.12832651774089 0.21926666259765626 590.9455208333334\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3810  --------------------------\n",
      "Train loss (all, class, reg): 47.085144391741075 0.034971427917480466 221.19776785714285\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 53.18111333211263 0.06888888676961263 553.70671875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3820  --------------------------\n",
      "Train loss (all, class, reg): 47.02075051443917 0.054190477643694196 258.00316964285713\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 52.96835225423177 0.21648890177408855 515.7325\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  3830  --------------------------\n",
      "Train loss (all, class, reg): 47.033888244628905 0.13846666608537947 196.54169642857144\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 53.113582153320316 0.13995557149251303 552.3113541666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3840  --------------------------\n",
      "Train loss (all, class, reg): 46.90292419433594 0.01663809503827776 236.9113392857143\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 53.00250559488932 0.23277778625488282 651.8147916666667\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3850  --------------------------\n",
      "Train loss (all, class, reg): 47.03253886631557 0.01351428576878139 280.63178571428574\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 53.22629287719727 0.1131555430094401 565.1175520833333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3860  --------------------------\n",
      "Train loss (all, class, reg): 47.01041244506836 0.01452380861554827 274.0601785714286\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.569324798583985 0.07617777506510416 636.6056770833334\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3870  --------------------------\n",
      "Train loss (all, class, reg): 47.14981632777623 0.03331428800310408 252.31625\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 53.60012588500977 0.10955556233723958 632.6684375\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3880  --------------------------\n",
      "Train loss (all, class, reg): 46.96482149396624 0.02468571526663644 275.5413169642857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.88466532389323 0.06291110992431641 583.4394270833334\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3890  --------------------------\n",
      "Train loss (all, class, reg): 46.85282655988421 0.014095238276890345 323.1870089285714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 53.50801752726237 0.33235555013020834 579.48234375\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3900  --------------------------\n",
      "Train loss (all, class, reg): 47.02859002249581 0.018819046020507813 221.32707589285715\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.04084238688151 0.36268890380859375 768.1855729166666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3910  --------------------------\n",
      "Train loss (all, class, reg): 47.08527060372489 0.053904762268066404 246.78814732142857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 53.35669204711914 0.10506666819254558 605.5336979166667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3920  --------------------------\n",
      "Train loss (all, class, reg): 47.14150390625 0.022828573499407086 246.00491071428573\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 53.35285166422526 0.20511109670003255 552.89453125\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3930  --------------------------\n",
      "Train loss (all, class, reg): 47.21833075387137 0.008885714667184012 242.35877232142857\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 53.47266337076823 0.4222222391764323 445.09791666666666\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3940  --------------------------\n",
      "Train loss (all, class, reg): 47.041030426025394 0.015552381787981306 262.1069196428571\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.374554290771485 0.12460000356038411 597.2043229166667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3950  --------------------------\n",
      "Train loss (all, class, reg): 47.05978561401367 0.139952392578125 210.13243303571429\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 53.61425359090169 0.19942222595214842 520.3724479166667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  3960  --------------------------\n",
      "Train loss (all, class, reg): 46.93449336460659 0.0848000008719308 263.27917410714286\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 53.436574910481774 0.3467778015136719 528.4731770833333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3970  --------------------------\n",
      "Train loss (all, class, reg): 47.00217819213867 0.01953333309718541 241.97502232142858\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.1925200398763 0.11275555928548177 621.4354166666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3980  --------------------------\n",
      "Train loss (all, class, reg): 47.1625505065918 0.05284762246268136 240.88964285714286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 53.49462916056315 0.12 727.7668229166667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  3990  --------------------------\n",
      "Train loss (all, class, reg): 47.30278431483678 0.018180953434535435 251.24183035714285\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 53.45319254557292 0.2839111073811849 539.23515625\n",
      "Test accuracy: 0.8733333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4000  --------------------------\n",
      "Train loss (all, class, reg): 47.14481530325753 0.01816190583365304 280.25511160714285\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.53190170288086 0.14604443868001302 613.1456770833333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4010  --------------------------\n",
      "Train loss (all, class, reg): 47.08175000871931 0.027066666739327568 236.94816964285715\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.47233856201172 0.11966667175292969 543.8078645833333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4020  --------------------------\n",
      "Train loss (all, class, reg): 47.11081981113979 0.08636190141950335 245.65839285714284\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 53.187166900634764 0.11339998881022136 698.766875\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4030  --------------------------\n",
      "Train loss (all, class, reg): 47.05916996547154 0.08991428920200893 255.01042410714285\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.26329299926758 0.14420000712076822 697.92421875\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4040  --------------------------\n",
      "Train loss (all, class, reg): 47.13833980015346 0.011047619410923549 225.5284375\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 53.178167724609374 0.13497778574625652 503.06567708333336\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4050  --------------------------\n",
      "Train loss (all, class, reg): 47.1382003566197 0.014142856597900391 333.24633928571427\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 53.23337387084961 0.08206666310628255 635.48015625\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4060  --------------------------\n",
      "Train loss (all, class, reg): 47.056709899902344 0.1164666748046875 182.83313616071428\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.97421569824219 0.3526666768391927 544.8217708333333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4070  --------------------------\n",
      "Train loss (all, class, reg): 47.06175988333566 0.009952380997794014 227.18890625\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.913087361653645 0.4494444274902344 653.08328125\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4080  --------------------------\n",
      "Train loss (all, class, reg): 47.07464091709682 0.0091142851965768 237.2878125\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 53.51470977783203 0.0782888921101888 622.7299479166667\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  4090  --------------------------\n",
      "Train loss (all, class, reg): 47.053742130824496 0.012209524427141462 242.14198660714285\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 53.522290852864586 0.597111104329427 479.20479166666667\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4100  --------------------------\n",
      "Train loss (all, class, reg): 46.991227351597374 0.06973333086286272 259.6121875\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 53.389337870279945 0.06522221883138021 513.4831770833333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4110  --------------------------\n",
      "Train loss (all, class, reg): 46.93132795061384 0.04484761919294085 268.6113392857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 53.28939331054688 0.22068888346354168 630.5210416666666\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4120  --------------------------\n",
      "Train loss (all, class, reg): 46.932185668945316 0.03495238167898995 235.63988839285713\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.31545979817708 0.513977762858073 557.9627083333334\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  4130  --------------------------\n",
      "Train loss (all, class, reg): 46.97192129952567 0.010971428326198032 244.74176339285714\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 53.323550872802734 0.07253333409627279 633.7005208333334\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4140  --------------------------\n",
      "Train loss (all, class, reg): 47.07445569719587 0.03246666772024972 257.60939732142856\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.93054590861003 0.053400001525878905 627.9775520833333\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4150  --------------------------\n",
      "Train loss (all, class, reg): 46.89871606009347 0.024161905561174667 269.47973214285713\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 53.209719848632815 0.11760000864664713 640.0265104166666\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4160  --------------------------\n",
      "Train loss (all, class, reg): 46.986973048618864 0.06610476357596261 229.54140625\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 53.30819864908854 0.0491777769724528 733.52734375\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  4170  --------------------------\n",
      "Train loss (all, class, reg): 46.873016357421875 0.08547618321010045 239.57852678571427\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 53.201460927327474 0.11266666412353515 530.4788020833333\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4180  --------------------------\n",
      "Train loss (all, class, reg): 46.80179175240653 0.010247619492667061 273.51247767857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 53.10082478841146 0.18268887837727865 579.52\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4190  --------------------------\n",
      "Train loss (all, class, reg): 46.8491671534947 0.12292380196707589 236.05546875\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 52.98817637125651 0.18019999186197916 574.4536458333333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4200  --------------------------\n",
      "Train loss (all, class, reg): 46.90821537562779 0.05318095070975167 218.27654017857142\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.15961908976237 0.08255555470784505 587.854375\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4210  --------------------------\n",
      "Train loss (all, class, reg): 46.874415806361604 0.09285713195800781 232.17863839285715\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 53.112277018229165 0.20997777303059895 697.7660416666666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4220  --------------------------\n",
      "Train loss (all, class, reg): 46.845086735316684 0.015104762486049108 279.3577901785714\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.768824157714846 0.2513111114501953 543.3994270833333\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4230  --------------------------\n",
      "Train loss (all, class, reg): 46.70464473179408 0.014476190294538225 283.27267857142857\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.82502426147461 0.21200000762939453 482.2390625\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4240  --------------------------\n",
      "Train loss (all, class, reg): 46.76488762991769 0.011638095038277762 247.44866071428572\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.93111434936523 0.07351111094156901 565.0974479166666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4250  --------------------------\n",
      "Train loss (all, class, reg): 46.68186296735491 0.08301904950823102 246.32285714285715\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 53.06097249348959 0.46246668497721355 616.2532291666666\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4260  --------------------------\n",
      "Train loss (all, class, reg): 46.56414103916713 0.011790477207728795 243.810625\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.95827163696289 0.3923333485921224 649.7839583333333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4270  --------------------------\n",
      "Train loss (all, class, reg): 46.66760951450893 0.060361905779157364 241.02316964285714\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.90515268961588 0.21491109212239584 671.48328125\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4280  --------------------------\n",
      "Train loss (all, class, reg): 46.59486077444894 0.07362857273646764 202.4728125\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.87024058024088 0.03515555699666341 566.8592708333333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4290  --------------------------\n",
      "Train loss (all, class, reg): 46.52967409406389 0.015038095201764788 281.68339285714285\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 52.670116882324216 0.41251113891601565 598.8769270833334\n",
      "Test accuracy: 0.87\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4300  --------------------------\n",
      "Train loss (all, class, reg): 46.55039352416992 0.021419048309326172 223.3177232142857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.85111974080404 0.4241777801513672 513.2198958333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4310  --------------------------\n",
      "Train loss (all, class, reg): 46.570402134486606 0.012552381243024553 255.0849107142857\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.63587717692057 0.44464447021484377 450.20838541666666\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4320  --------------------------\n",
      "Train loss (all, class, reg): 46.48633922031947 0.04686666761125837 190.28428571428572\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.752381795247395 0.16111111958821614 495.4795833333333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4330  --------------------------\n",
      "Train loss (all, class, reg): 46.437482495989116 0.015276189531598773 245.62216517857144\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.83442372639974 0.3824888610839844 443.12854166666665\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4340  --------------------------\n",
      "Train loss (all, class, reg): 46.5062100655692 0.028552382332938057 273.5764955357143\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 53.1503944905599 0.24575553894042967 545.6559895833333\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4350  --------------------------\n",
      "Train loss (all, class, reg): 46.611591491699215 0.010342856815883091 286.8321651785714\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.970107421875 0.3017333475748698 541.2714583333334\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4360  --------------------------\n",
      "Train loss (all, class, reg): 46.4737835257394 0.010647619792393277 296.83676339285716\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.599115193684895 0.17211110432942708 662.0188020833333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4370  --------------------------\n",
      "Train loss (all, class, reg): 46.429622737339564 0.008180952753339495 201.738125\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 52.68857711791992 0.30637776692708335 541.7696875\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  4380  --------------------------\n",
      "Train loss (all, class, reg): 46.50579345703125 0.025238094329833986 237.188125\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 52.6991015625 0.42715550740559893 527.93\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4390  --------------------------\n",
      "Train loss (all, class, reg): 46.36586181640625 0.015390475136893136 232.1783705357143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.71538299560547 0.21084444681803385 547.3323958333333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4400  --------------------------\n",
      "Train loss (all, class, reg): 46.39927474975586 0.008247619356427874 264.48984375\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.46201497395833 0.21766667683919272 486.34942708333335\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4410  --------------------------\n",
      "Train loss (all, class, reg): 46.34501438685826 0.012238095147269113 274.26779017857143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 52.95776357014974 0.040622224807739256 606.8647916666666\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4420  --------------------------\n",
      "Train loss (all, class, reg): 46.43138209751674 0.016942858014787947 228.0636830357143\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.60705047607422 0.3434222412109375 451.5128125\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4430  --------------------------\n",
      "Train loss (all, class, reg): 46.24074068341936 0.013914285387311662 235.13765625\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.69768900553385 0.09353333791097006 692.7040104166666\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4440  --------------------------\n",
      "Train loss (all, class, reg): 46.38377190726144 0.007714285169328962 264.8253571428571\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 52.629249267578125 0.24199999491373697 649.7038541666667\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4450  --------------------------\n",
      "Train loss (all, class, reg): 46.40257524762835 0.013199999673025948 327.09658482142856\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.58883021036784 0.4822889200846354 454.39447916666666\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4460  --------------------------\n",
      "Train loss (all, class, reg): 46.241309988839284 0.07496190207345145 221.04758928571428\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.78152369181315 0.07117777506510417 733.4021354166666\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4470  --------------------------\n",
      "Train loss (all, class, reg): 46.32238274710519 0.011685714721679688 255.15310267857143\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.71095876057943 0.22331110636393228 591.1328645833333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4480  --------------------------\n",
      "Train loss (all, class, reg): 46.26200716291155 0.00949523789542062 262.9122544642857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.20590265909831 0.12895554860432942 657.114375\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4490  --------------------------\n",
      "Train loss (all, class, reg): 46.387766636439736 0.08514285496303013 254.62375\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.64999989827474 0.5655777486165364 708.3047395833333\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4500  --------------------------\n",
      "Train loss (all, class, reg): 46.23315089634487 0.01724761962890625 284.1369419642857\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.11105753580729 0.0828222147623698 546.4791666666666\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4510  --------------------------\n",
      "Train loss (all, class, reg): 46.184764469691686 0.015333332334245954 304.78395089285715\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 52.62594665527344 0.55 573.2842708333334\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4520  --------------------------\n",
      "Train loss (all, class, reg): 46.36883403233119 0.04718094961983817 231.75504464285714\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.404378967285155 0.2187999979654948 530.34546875\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4530  --------------------------\n",
      "Train loss (all, class, reg): 46.16242194039481 0.055495240347726 187.92274553571428\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 52.36550760904948 0.18813334147135416 663.35625\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4540  --------------------------\n",
      "Train loss (all, class, reg): 46.07496098109654 0.021419046946934292 228.11964285714285\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 52.41530883789063 0.24826667785644532 694.3959895833333\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4550  --------------------------\n",
      "Train loss (all, class, reg): 46.09003679547991 0.021952381134033205 221.49002232142857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 53.13032964070638 0.21348889668782553 512.24296875\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4560  --------------------------\n",
      "Train loss (all, class, reg): 46.1620979309082 0.011980953216552735 191.4311830357143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 52.53907043457031 0.1271777852376302 734.45578125\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4570  --------------------------\n",
      "Train loss (all, class, reg): 46.10694702148437 0.010666666712079729 228.6350892857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.19085779825846 0.30468889872233074 428.34869791666665\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4580  --------------------------\n",
      "Train loss (all, class, reg): 46.169097987583704 0.025685713631766183 211.19196428571428\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.36750818888346 0.17784444173177083 511.06328125\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4590  --------------------------\n",
      "Train loss (all, class, reg): 46.09332951136998 0.07518094744001116 224.61078125\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.400159200032554 0.3308221944173177 654.22890625\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4600  --------------------------\n",
      "Train loss (all, class, reg): 46.00074611118862 0.011876190730503628 237.17578125\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.23745142618815 0.18568888346354168 563.0213541666667\n",
      "Test accuracy: 0.8833333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4610  --------------------------\n",
      "Train loss (all, class, reg): 46.009271327427456 0.01322857175554548 268.38473214285716\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.499933268229164 0.18388890584309897 686.1449479166666\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4620  --------------------------\n",
      "Train loss (all, class, reg): 45.987823290143695 0.016866667611258372 256.78486607142855\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.31358052571615 0.2793999735514323 558.73\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4630  --------------------------\n",
      "Train loss (all, class, reg): 45.967074040004185 0.0108857148034232 249.30267857142857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 52.20712661743164 0.26486666361490885 506.56333333333333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4640  --------------------------\n",
      "Train loss (all, class, reg): 45.90990851266044 0.01050476210457938 220.90060267857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.08472895304362 0.12155555725097657 614.9988541666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  4650  --------------------------\n",
      "Train loss (all, class, reg): 45.95712581089565 0.013057141985212054 317.49158482142855\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.32355672200521 0.07917777379353841 527.83515625\n",
      "Test accuracy: 0.87\n",
      "Epoch:  4660  --------------------------\n",
      "Train loss (all, class, reg): 45.96205732073103 0.020828571319580078 305.12080357142855\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.91549179077148 0.3288666788736979 563.1447916666667\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4670  --------------------------\n",
      "Train loss (all, class, reg): 46.018394884381976 0.07791428702218192 195.48475446428571\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.588753916422526 0.47555552164713544 581.650625\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4680  --------------------------\n",
      "Train loss (all, class, reg): 46.04414114815848 0.010952381406511578 252.33256696428572\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.22900889078776 0.10884443918863933 525.67671875\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4690  --------------------------\n",
      "Train loss (all, class, reg): 46.10133043561663 0.07812381199428013 203.74430803571428\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 52.2696608988444 0.1897111129760742 584.1730729166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  4700  --------------------------\n",
      "Train loss (all, class, reg): 46.024551805768695 0.01699047633579799 238.83917410714287\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.979794362386066 0.071488889058431 669.1215104166666\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4710  --------------------------\n",
      "Train loss (all, class, reg): 46.02369293212891 0.00860952377319336 255.2097767857143\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.90598729451497 0.22411112467447916 528.94828125\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4720  --------------------------\n",
      "Train loss (all, class, reg): 45.864564666748045 0.019228571483067104 284.38910714285714\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.982032775878906 0.34937779744466146 634.4115104166667\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4730  --------------------------\n",
      "Train loss (all, class, reg): 45.768138493129186 0.01107619081224714 294.79571428571427\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.84924865722656 0.2462444559733073 563.9958333333333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4740  --------------------------\n",
      "Train loss (all, class, reg): 45.98036771501813 0.012161903381347657 212.95247767857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 52.11246063232422 0.26104446411132814 577.5761458333334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4750  --------------------------\n",
      "Train loss (all, class, reg): 45.78442546299526 0.0077238096509660995 294.53127232142856\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.93959381103516 0.19333333333333333 525.3296354166666\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4760  --------------------------\n",
      "Train loss (all, class, reg): 45.82760848999023 0.016476191111973355 307.3274776785714\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.95217544555664 0.20911112467447918 573.69375\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4770  --------------------------\n",
      "Train loss (all, class, reg): 45.80649697440011 0.05009523664202009 222.8283482142857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.91413925170898 0.18982222239176433 650.11125\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4780  --------------------------\n",
      "Train loss (all, class, reg): 45.87297801426479 0.009571428298950196 252.55263392857142\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.957857615152996 0.0715333366394043 797.8083854166666\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4790  --------------------------\n",
      "Train loss (all, class, reg): 45.76611624581473 0.07958095550537109 214.03962053571428\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.19292322794596 0.07204444249471029 652.2309895833333\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  4800  --------------------------\n",
      "Train loss (all, class, reg): 45.714239153180806 0.01148571286882673 238.30051339285714\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.73181065877279 0.1651555633544922 478.67651041666664\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4810  --------------------------\n",
      "Train loss (all, class, reg): 45.744623740059986 0.07088571275983538 227.24160714285713\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.91543436686198 0.29579996744791665 615.6013541666666\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4820  --------------------------\n",
      "Train loss (all, class, reg): 45.826310860770086 0.014599999019077846 244.49089285714285\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.86281046549479 0.07466667175292968 623.1941666666667\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4830  --------------------------\n",
      "Train loss (all, class, reg): 45.73359636579241 0.08268571036202567 230.66714285714286\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 52.00627410888672 0.3813555653889974 476.2647395833333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4840  --------------------------\n",
      "Train loss (all, class, reg): 45.6475802394322 0.015161905288696289 321.0589732142857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 51.825233154296875 0.18537776947021484 487.73546875\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4850  --------------------------\n",
      "Train loss (all, class, reg): 45.70416961669922 0.06746667044503349 254.76763392857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.61651011149088 0.14884445190429688 545.6430208333334\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  4860  --------------------------\n",
      "Train loss (all, class, reg): 45.76093279157366 0.012695237568446567 261.9466294642857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.857024383544925 0.22240000406901042 518.559375\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4870  --------------------------\n",
      "Train loss (all, class, reg): 45.64479274204799 0.09164762224469866 284.3441517857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 52.01229771931966 0.19439998626708985 530.531875\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4880  --------------------------\n",
      "Train loss (all, class, reg): 45.788917715890065 0.012980952944074359 218.5961830357143\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.673324737548825 0.3395111083984375 531.4725520833333\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4890  --------------------------\n",
      "Train loss (all, class, reg): 45.676373508998324 0.020838097163609095 290.0567410714286\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss (all, class, reg): 51.94981541951498 0.40937774658203124 456.9799479166667\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4900  --------------------------\n",
      "Train loss (all, class, reg): 45.76689169747489 0.08132380894252232 204.32488839285713\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 51.75267974853516 0.23591110229492188 666.2996354166667\n",
      "Test accuracy: 0.8733333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4910  --------------------------\n",
      "Train loss (all, class, reg): 45.793816746303015 0.0813142830984933 232.00089285714284\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.68884302775065 0.34115557352701825 625.4650520833334\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4920  --------------------------\n",
      "Train loss (all, class, reg): 45.65414031982422 0.04288571493966239 266.81580357142855\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.91078816731771 0.2801111094156901 658.8519270833333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4930  --------------------------\n",
      "Train loss (all, class, reg): 45.819806714739116 0.019733333587646486 226.99877232142856\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss (all, class, reg): 51.97261703491211 0.45335550944010417 576.4675520833333\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  4940  --------------------------\n",
      "Train loss (all, class, reg): 45.65573039463588 0.05171429225376674 239.62359375\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.41500111897786 0.02111111005147298 514.3343229166667\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4950  --------------------------\n",
      "Train loss (all, class, reg): 45.738753945486884 0.15834286281040735 182.61008928571428\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.7396560160319 0.29851112365722654 574.9984895833334\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4960  --------------------------\n",
      "Train loss (all, class, reg): 45.619515271868025 0.012019048418317522 230.70323660714286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 52.02954208374023 0.1534666697184245 650.3528125\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4970  --------------------------\n",
      "Train loss (all, class, reg): 45.589236929757256 0.008571428571428572 231.89618303571427\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.68352793375651 0.18617777506510416 437.74114583333335\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4980  --------------------------\n",
      "Train loss (all, class, reg): 45.62623866489955 0.022047619138445173 269.56316964285713\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.88435516357422 0.07164443969726562 605.7796354166667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4990  --------------------------\n",
      "Train loss (all, class, reg): 45.605975298200335 0.04959047589983259 228.4646875\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.76509145100911 0.6028667195638021 551.7534895833334\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  5000  --------------------------\n",
      "Train loss (all, class, reg): 45.424671848842074 0.12572381155831472 187.93669642857142\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 52.02339874267578 0.1254888916015625 595.4328645833333\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5010  --------------------------\n",
      "Train loss (all, class, reg): 45.50840068272182 0.012199998583112444 235.5900892857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.47931513468424 0.594022216796875 516.39734375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5020  --------------------------\n",
      "Train loss (all, class, reg): 45.553480333600724 0.008276190757751465 236.93575892857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.482067311604816 0.27817776997884114 467.0420833333333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5030  --------------------------\n",
      "Train loss (all, class, reg): 45.402829284667966 0.026123809814453124 297.55138392857145\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.336151072184244 0.3145111083984375 588.74921875\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5040  --------------------------\n",
      "Train loss (all, class, reg): 45.51845977783203 0.07357142312186105 218.5328125\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.534155985514325 0.18991111755371093 642.9799479166667\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5050  --------------------------\n",
      "Train loss (all, class, reg): 45.46404471261161 0.020704762595040456 217.13772321428573\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.363726959228515 0.05082221984863281 537.3222395833334\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5060  --------------------------\n",
      "Train loss (all, class, reg): 45.52146728515625 0.022209524427141462 216.7019642857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.66025858561198 0.2992222086588542 562.1176041666666\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  5070  --------------------------\n",
      "Train loss (all, class, reg): 45.44565035138812 0.021714285441807337 268.5813839285714\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 51.61311131795247 0.535 486.465625\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5080  --------------------------\n",
      "Train loss (all, class, reg): 45.35218817574637 0.015866666521344865 189.90845982142858\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.3300210571289 0.20993333180745444 533.8991145833334\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5090  --------------------------\n",
      "Train loss (all, class, reg): 45.266973811558316 0.08175237383161273 238.9752455357143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.328267415364586 0.0725777816772461 511.92369791666664\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5100  --------------------------\n",
      "Train loss (all, class, reg): 45.2087423488072 0.020228571210588728 213.79017857142858\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.18825693766276 0.372066650390625 488.29125\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5110  --------------------------\n",
      "Train loss (all, class, reg): 45.31920935494559 0.08905713762555803 235.33872767857142\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.46977818806966 0.24235555013020835 494.04604166666667\n",
      "Test accuracy: 0.87\n",
      "Epoch:  5120  --------------------------\n",
      "Train loss (all, class, reg): 45.27290723528181 0.008457142966134208 231.38473214285713\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.5353151957194 0.06799999872843425 599.4778125\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5130  --------------------------\n",
      "Train loss (all, class, reg): 45.17873574393136 0.03380952562604632 265.50011160714286\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 51.412245483398436 0.7614443969726562 733.371875\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5140  --------------------------\n",
      "Train loss (all, class, reg): 45.15872809273856 0.010419047219412668 279.28995535714284\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.10400029500325 0.12444445292154947 498.9965104166667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5150  --------------------------\n",
      "Train loss (all, class, reg): 45.19885947091239 0.019609523500714984 233.05290178571428\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.41354624430338 0.1562444559733073 593.5302604166667\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5160  --------------------------\n",
      "Train loss (all, class, reg): 44.99289629255022 0.008209523473467146 221.52\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 51.389994608561196 0.08537776947021485 508.1494270833333\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5170  --------------------------\n",
      "Train loss (all, class, reg): 45.108494328090124 0.010561904907226562 241.22495535714285\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.3372661336263 0.6313333129882812 465.51494791666664\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5180  --------------------------\n",
      "Train loss (all, class, reg): 44.978337097167966 0.018457142966134207 286.45515625\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.581284027099606 0.4177111053466797 566.891875\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  5190  --------------------------\n",
      "Train loss (all, class, reg): 45.15954539707729 0.024171428680419924 254.32\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.527987213134764 0.12686665852864584 508.9605208333333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5200  --------------------------\n",
      "Train loss (all, class, reg): 45.17167846679688 0.13241905212402344 255.53872767857143\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 51.51822453816732 0.16911112467447917 669.8028645833333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5210  --------------------------\n",
      "Train loss (all, class, reg): 45.04976464407785 0.015904761723109655 228.03424107142857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.38468724568685 0.06122222900390625 461.3316145833333\n",
      "Test accuracy: 0.8866666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5220  --------------------------\n",
      "Train loss (all, class, reg): 45.045396118164064 0.02908571515764509 219.47341517857143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.64871063232422 0.22042221069335938 593.7122916666667\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5230  --------------------------\n",
      "Train loss (all, class, reg): 45.14395137241908 0.012428571156093053 236.35732142857142\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.39816558837891 0.5387555440266927 526.8575\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5240  --------------------------\n",
      "Train loss (all, class, reg): 45.08002779279436 0.17817141941615514 228.708125\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.583251241048174 0.09733333587646484 571.36328125\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5250  --------------------------\n",
      "Train loss (all, class, reg): 45.066958988734655 0.009533333097185407 200.46638392857142\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 50.9756042989095 0.08282222747802734 632.9022916666667\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5260  --------------------------\n",
      "Train loss (all, class, reg): 45.069180668422156 0.009800000190734863 244.56736607142858\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.19810699462891 0.07313333511352539 676.59203125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5270  --------------------------\n",
      "Train loss (all, class, reg): 45.061966814313614 0.012923808779035297 248.22087053571428\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.44219924926758 0.06764444986979166 668.3047916666667\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  5280  --------------------------\n",
      "Train loss (all, class, reg): 45.02767011369978 0.08145714351109096 178.23183035714285\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.0590273030599 0.10624444325764974 655.0991145833333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5290  --------------------------\n",
      "Train loss (all, class, reg): 45.1222670854841 0.007371428353445871 253.61013392857143\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.40867828369141 0.386199951171875 683.6982291666667\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5300  --------------------------\n",
      "Train loss (all, class, reg): 45.06501157488142 0.014228571483067104 267.83125\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.53641632080078 0.06157777786254883 594.3172395833334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5310  --------------------------\n",
      "Train loss (all, class, reg): 44.95736448015486 0.010419047219412668 232.99754464285715\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.074448903401695 0.06208889007568359 530.8509375\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  5320  --------------------------\n",
      "Train loss (all, class, reg): 45.00969600132534 0.03088571548461914 237.63417410714285\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.16489212036133 0.11224444071451822 609.4069270833334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5330  --------------------------\n",
      "Train loss (all, class, reg): 44.979277409144814 0.016028571810041154 271.63901785714285\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.43796330769857 0.1414444351196289 477.4155729166667\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5340  --------------------------\n",
      "Train loss (all, class, reg): 45.00651515415736 0.10690475463867187 185.3058705357143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.36884089152018 0.06257778167724609 495.90067708333333\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5350  --------------------------\n",
      "Train loss (all, class, reg): 45.03999152047294 0.01411428587777274 249.04419642857144\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.09019012451172 0.060222225189208986 700.4098958333333\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5360  --------------------------\n",
      "Train loss (all, class, reg): 44.99915457589286 0.01915237971714565 292.2862946428571\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.95545196533203 0.41626668294270835 492.9086458333333\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5370  --------------------------\n",
      "Train loss (all, class, reg): 45.12562940325056 0.011104761532374791 224.32712053571427\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.869758961995444 0.023533334732055666 520.0302604166667\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5380  --------------------------\n",
      "Train loss (all, class, reg): 45.10817707606724 0.017380952835083008 228.03734375\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.07213490804036 0.10324443817138672 451.76921875\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5390  --------------------------\n",
      "Train loss (all, class, reg): 45.0652560206822 0.07933333260672433 224.3778125\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.24743810017904 0.45304443359375 499.4100520833333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5400  --------------------------\n",
      "Train loss (all, class, reg): 45.04722030639648 0.024161905561174667 286.53098214285717\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 51.203229115804035 0.21893330891927085 565.5930729166666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5410  --------------------------\n",
      "Train loss (all, class, reg): 45.13128302437919 0.01303809574672154 302.90640625\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 50.848115234375 0.1568888854980469 558.7769791666667\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5420  --------------------------\n",
      "Train loss (all, class, reg): 45.072544926234656 0.01668571472167969 227.0036607142857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.999496663411456 0.3164222208658854 531.0194791666667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5430  --------------------------\n",
      "Train loss (all, class, reg): 45.116761561802456 0.0972190420968192 207.3622544642857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.20297231038411 0.21415555318196614 509.95484375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5440  --------------------------\n",
      "Train loss (all, class, reg): 45.16023677280971 0.03154285703386579 230.9585044642857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.5084255472819 0.03508888880411784 514.0224479166667\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5450  --------------------------\n",
      "Train loss (all, class, reg): 45.073971666608536 0.08285714285714285 223.84571428571428\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.85729395548503 0.21251111348470053 450.9661458333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5460  --------------------------\n",
      "Train loss (all, class, reg): 45.072552708217074 0.013476189204624721 275.8714508928571\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.92950724283854 0.39226666768391927 430.29578125\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  5470  --------------------------\n",
      "Train loss (all, class, reg): 44.98714760916574 0.06169524056570871 229.32785714285714\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.809889221191405 0.25655553181966145 496.7239583333333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  5480  --------------------------\n",
      "Train loss (all, class, reg): 45.06560614449637 0.013180953434535436 242.36042410714285\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.95879948933919 0.07708889007568359 661.6872916666666\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5490  --------------------------\n",
      "Train loss (all, class, reg): 45.06519522530692 0.014523809977940151 246.03314732142857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.22018463134766 0.055977783203125 623.6554166666666\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5500  --------------------------\n",
      "Train loss (all, class, reg): 45.182925589425224 0.016152379172188897 229.24526785714286\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.53281667073568 0.21044443766276041 489.14640625\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5510  --------------------------\n",
      "Train loss (all, class, reg): 44.96613878522601 0.01050476210457938 299.74580357142855\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.933190205891925 0.5196000162760417 726.4305208333334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5520  --------------------------\n",
      "Train loss (all, class, reg): 45.082884150913785 0.014466667175292968 242.39008928571428\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.20005040486654 0.11186665852864583 568.4784895833334\n",
      "Test accuracy: 0.8833333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5530  --------------------------\n",
      "Train loss (all, class, reg): 45.18947514125279 0.019695238385881695 219.3060044642857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.31080200195313 0.2584222157796224 556.9723958333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5540  --------------------------\n",
      "Train loss (all, class, reg): 45.19281053815569 0.013028572627476283 216.66689732142856\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.12470723470052 0.1297777811686198 709.3308333333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5550  --------------------------\n",
      "Train loss (all, class, reg): 45.148387233189176 0.012085715702601842 239.99484375\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 51.02332590738932 0.042866668701171874 545.7868229166667\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5560  --------------------------\n",
      "Train loss (all, class, reg): 45.29196256365095 0.19263809204101562 181.7163392857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.25646011352539 0.08706666310628255 609.0002083333334\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5570  --------------------------\n",
      "Train loss (all, class, reg): 45.21900608607701 0.010828571319580078 206.8683482142857\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 51.39412521362305 0.08815555572509766 510.80932291666664\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5580  --------------------------\n",
      "Train loss (all, class, reg): 45.28980967930385 0.009885714394705637 267.5439732142857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 51.16103332519531 0.13771110534667969 501.8646875\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  5590  --------------------------\n",
      "Train loss (all, class, reg): 45.18158671787807 0.016428571428571428 252.54352678571428\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 51.34036641438802 0.13004444122314454 794.9518229166666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5600  --------------------------\n",
      "Train loss (all, class, reg): 45.27141207013811 0.018457142966134207 237.07520089285714\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.372983856201174 0.08246666590372721 726.10765625\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5610  --------------------------\n",
      "Train loss (all, class, reg): 45.1429613167899 0.0934857177734375 188.41504464285714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.99198079427083 0.3057111104329427 496.61864583333335\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5620  --------------------------\n",
      "Train loss (all, class, reg): 45.11092588152204 0.055333333696637836 215.58591517857144\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.19244222005209 0.04302222569783529 615.53921875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5630  --------------------------\n",
      "Train loss (all, class, reg): 45.130232587541855 0.01 243.6646875\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.396984049479165 0.06860000610351563 592.034375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  5640  --------------------------\n",
      "Train loss (all, class, reg): 45.15964976719447 0.0882190431867327 268.72546875\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.08827092488607 0.11506665547688802 595.6325520833333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5650  --------------------------\n",
      "Train loss (all, class, reg): 45.098995317731585 0.009438095092773437 332.4958705357143\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 51.30203684488932 0.18557777404785156 592.2228645833334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5660  --------------------------\n",
      "Train loss (all, class, reg): 45.130033852713446 0.06928571428571428 209.60497767857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.29609588623047 0.42515556335449217 787.639375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5670  --------------------------\n",
      "Train loss (all, class, reg): 45.077229570661274 0.023438094002859934 226.95716517857142\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.06590031941732 0.2994666798909505 660.4763541666666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5680  --------------------------\n",
      "Train loss (all, class, reg): 45.007781699044365 0.01196190425327846 316.39671875\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.833044637044274 0.09811111450195313 445.73614583333335\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5690  --------------------------\n",
      "Train loss (all, class, reg): 45.07104143415179 0.010676190512520927 254.2477232142857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 51.12266637166341 0.2898444620768229 547.6427083333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5700  --------------------------\n",
      "Train loss (all, class, reg): 45.02599666050502 0.007685714449201311 254.43254464285715\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.07813756306966 0.19697776794433594 652.2416145833333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  5710  --------------------------\n",
      "Train loss (all, class, reg): 45.01728267124721 0.02376190458025251 268.61198660714285\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 51.160082244873045 0.3006222534179688 568.0009895833333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5720  --------------------------\n",
      "Train loss (all, class, reg): 45.061555306570874 0.05543809618268694 247.89973214285715\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.72676864624023 0.20220001220703124 483.9050520833333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5730  --------------------------\n",
      "Train loss (all, class, reg): 44.97319649832589 0.011780951363699776 241.00357142857143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.2486181640625 0.3567999776204427 705.4224479166667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5740  --------------------------\n",
      "Train loss (all, class, reg): 44.915454777308874 0.10296190534319197 267.31973214285716\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.73173833211263 0.425 485.22161458333335\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5750  --------------------------\n",
      "Train loss (all, class, reg): 44.89603504725865 0.012828570774623326 264.83178571428573\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.72336273193359 0.17737777709960936 584.91609375\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5760  --------------------------\n",
      "Train loss (all, class, reg): 44.91051618303572 0.033266666957310266 184.92618303571427\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 51.10528274536133 0.031844444274902343 531.8004166666667\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5770  --------------------------\n",
      "Train loss (all, class, reg): 44.77693252563476 0.011371428625924246 284.3628794642857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 51.03704803466797 1.1409555053710938 756.25234375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5780  --------------------------\n",
      "Train loss (all, class, reg): 44.89226405552456 0.07965714045933314 188.87236607142856\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.939776255289715 0.08868888854980468 518.1725520833334\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5790  --------------------------\n",
      "Train loss (all, class, reg): 44.83472939627511 0.06807619367327009 206.60837053571427\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.891323496500654 0.2854888661702474 579.5388541666666\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5800  --------------------------\n",
      "Train loss (all, class, reg): 44.896424364362446 0.016438095910208565 250.26263392857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.78547932942708 1.0228888956705728 801.90984375\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5810  --------------------------\n",
      "Train loss (all, class, reg): 44.82398260934012 0.093990478515625 257.4379017857143\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 51.173126729329425 1.204222208658854 883.6371875\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5820  --------------------------\n",
      "Train loss (all, class, reg): 44.86417449951172 0.011647619519914899 319.59935267857145\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.979000345865884 0.08988889058430989 681.0010416666667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5830  --------------------------\n",
      "Train loss (all, class, reg): 44.69601534162249 0.026361906869070872 219.18205357142858\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 50.88945297241211 0.04397777557373047 578.54640625\n",
      "Test accuracy: 0.8833333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5840  --------------------------\n",
      "Train loss (all, class, reg): 44.78510266985212 0.01683809552873884 250.53109375\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 51.086826680501304 0.3510888671875 708.1410416666666\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5850  --------------------------\n",
      "Train loss (all, class, reg): 44.8692100742885 0.07658095223563058 225.62640625\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 51.22005065917969 0.34339996337890627 627.0852083333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5860  --------------------------\n",
      "Train loss (all, class, reg): 44.85599657331194 0.014047619955880301 250.31154017857142\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.943291422526045 1.0466443888346355 1010.2222916666667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5870  --------------------------\n",
      "Train loss (all, class, reg): 44.744954158238 0.09134285518101283 241.4727455357143\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 51.01573206583659 0.4790888468424479 494.52869791666666\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5880  --------------------------\n",
      "Train loss (all, class, reg): 44.631934814453125 0.13915237426757812 191.72238839285714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.59194391886393 0.23382222493489582 542.188125\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5890  --------------------------\n",
      "Train loss (all, class, reg): 44.576356571742465 0.009009524072919573 225.50361607142858\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.60498326619466 0.16937777201334636 538.3497916666666\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5900  --------------------------\n",
      "Train loss (all, class, reg): 44.70563276018415 0.06447618756975447 243.4333705357143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.66320271809896 0.27964441935221357 606.38578125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5910  --------------------------\n",
      "Train loss (all, class, reg): 44.59635646275112 0.016657142639160155 237.24642857142857\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 50.75931482950846 0.05322222709655762 596.17015625\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5920  --------------------------\n",
      "Train loss (all, class, reg): 44.67662909371512 0.0868952396937779 192.4078794642857\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 50.455912272135414 0.12124444325764974 637.7472395833333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5930  --------------------------\n",
      "Train loss (all, class, reg): 44.60976390293666 0.05660952976771763 275.21703125\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 50.71323486328125 0.23180000305175782 805.52984375\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5940  --------------------------\n",
      "Train loss (all, class, reg): 44.580030452183316 0.1151047624860491 198.84098214285714\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 50.98835225423177 0.16975557963053386 537.0403645833334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5950  --------------------------\n",
      "Train loss (all, class, reg): 44.614109933035714 0.01278095245361328 259.4461607142857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.45323079427083 0.18577777862548828 498.5002083333333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5960  --------------------------\n",
      "Train loss (all, class, reg): 44.70753082275391 0.01060000010899135 256.5036830357143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.72652577718099 0.07793333689371745 710.7684895833333\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5970  --------------------------\n",
      "Train loss (all, class, reg): 44.83294139317104 0.0785904802594866 222.91908482142858\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.72667282104492 0.165466677347819 449.8265625\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5980  --------------------------\n",
      "Train loss (all, class, reg): 44.6802439226423 0.1955523681640625 227.29502232142858\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.981377360026045 0.5379777526855469 482.05052083333334\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5990  --------------------------\n",
      "Train loss (all, class, reg): 44.78060492379325 0.031657142639160155 211.0117857142857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.575843556722006 0.08377777735392253 587.9941666666666\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6000  --------------------------\n",
      "Train loss (all, class, reg): 44.589078587123325 0.02005714280264718 225.9925\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.400014038085935 0.3008666483561198 500.71880208333334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6010  --------------------------\n",
      "Train loss (all, class, reg): 44.53702839442662 0.027428572518484934 287.8383482142857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.807574615478515 0.26917775472005206 559.0433854166666\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6020  --------------------------\n",
      "Train loss (all, class, reg): 44.581700177873884 0.08332381112234934 189.3425\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 50.98583536783854 0.17153334299723308 674.5763020833333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6030  --------------------------\n",
      "Train loss (all, class, reg): 44.57912867954799 0.015780952998570033 225.30325892857144\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.5215229288737 0.1931999969482422 621.9044791666666\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6040  --------------------------\n",
      "Train loss (all, class, reg): 44.57850479125977 0.05983809334891183 226.90433035714287\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.36563191731771 0.26600001017252606 557.48640625\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6050  --------------------------\n",
      "Train loss (all, class, reg): 44.49919400896345 0.021476192474365233 247.08285714285714\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.66424011230469 0.06022221883138021 649.0838020833334\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6060  --------------------------\n",
      "Train loss (all, class, reg): 44.44802174159459 0.015561904907226563 284.22125\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.73467905680339 1.0598444620768228 711.3403645833333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6070  --------------------------\n",
      "Train loss (all, class, reg): 44.61583953857422 0.013361906324114119 224.36107142857142\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.61461583455404 0.3206000010172526 600.9133333333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6080  --------------------------\n",
      "Train loss (all, class, reg): 44.53810716901507 0.028085714067731585 229.3738392857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.67498062133789 0.2728888956705729 493.8208333333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6090  --------------------------\n",
      "Train loss (all, class, reg): 44.474103502546036 0.008209524154663085 243.30828125\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.36995407104492 0.05413333257039388 542.1132291666667\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6100  --------------------------\n",
      "Train loss (all, class, reg): 44.34856881277902 0.014380953652518137 287.6460714285714\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.671229654947915 0.09900000254313152 562.6033333333334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6110  --------------------------\n",
      "Train loss (all, class, reg): 44.51297716413225 0.006123809814453125 197.46736607142856\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.486617685953775 0.6268222045898437 419.8868229166667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6120  --------------------------\n",
      "Train loss (all, class, reg): 44.39908089773996 0.07594285147530692 197.77808035714287\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.53856816609701 0.26553334554036456 477.1326041666667\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6130  --------------------------\n",
      "Train loss (all, class, reg): 44.56865029471261 0.09122857230050223 169.70675223214286\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.599407043457035 0.1585555648803711 679.8943229166666\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6140  --------------------------\n",
      "Train loss (all, class, reg): 44.521328408377514 0.008342857360839845 234.6125\n",
      "Train accuracy: 0.9471428571428572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (all, class, reg): 50.56140431722005 0.04473333358764649 665.7458854166666\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6150  --------------------------\n",
      "Train loss (all, class, reg): 44.34895050048828 0.012571428843906947 265.1414732142857\n",
      "Train accuracy: 0.9614285714285714\n",
      "Test loss (all, class, reg): 51.00801442464193 0.4216888936360677 774.6726041666667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6160  --------------------------\n",
      "Train loss (all, class, reg): 44.41332604544503 0.012361905234200613 205.4525\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 51.07869293212891 0.48415557861328123 687.1636458333334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6170  --------------------------\n",
      "Train loss (all, class, reg): 44.439095153808594 0.014342858450753348 250.43147321428572\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 50.217181294759115 0.22497777303059896 573.5199479166666\n",
      "Test accuracy: 0.88\n",
      "Epoch:  6180  --------------------------\n",
      "Train loss (all, class, reg): 44.49662329537528 0.013799999782017298 263.75841517857145\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.6032861328125 0.25904444376627606 550.5686458333333\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6190  --------------------------\n",
      "Train loss (all, class, reg): 44.3980952671596 0.013619048254830497 281.23444196428574\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.229319407145184 0.10624443689982097 648.8483333333334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6200  --------------------------\n",
      "Train loss (all, class, reg): 44.366850062779015 0.014752381188528878 254.3995982142857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.60553365071615 0.18660001118977865 488.01880208333336\n",
      "Test accuracy: 0.88\n",
      "Epoch:  6210  --------------------------\n",
      "Train loss (all, class, reg): 44.27570349557059 0.01682857240949358 251.74339285714285\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.45388854980469 0.2955555470784505 524.34421875\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6220  --------------------------\n",
      "Train loss (all, class, reg): 44.240685773577006 0.00952380929674421 303.10839285714286\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 50.06308110555013 0.08508888880411784 521.6967708333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6230  --------------------------\n",
      "Train loss (all, class, reg): 44.31819161551339 0.06998095376150949 239.33029017857143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.48159383138021 0.06293333689371745 436.77458333333334\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6240  --------------------------\n",
      "Train loss (all, class, reg): 44.2424828011649 0.011723809923444475 233.99747767857144\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.23896942138672 0.1360888926188151 516.6997395833333\n",
      "Test accuracy: 0.88\n",
      "Epoch:  6250  --------------------------\n",
      "Train loss (all, class, reg): 44.25163981846401 0.011523809432983399 249.81921875\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.49479949951172 0.046266670227050784 475.0578125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6260  --------------------------\n",
      "Train loss (all, class, reg): 44.26726455688477 0.02313333238874163 195.09430803571428\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.335889739990236 0.27182220458984374 440.78151041666666\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6270  --------------------------\n",
      "Train loss (all, class, reg): 44.42585702078683 0.016999999455043248 257.33350446428574\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 49.80386001586914 0.18420000712076823 506.214375\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6280  --------------------------\n",
      "Train loss (all, class, reg): 44.21237224033901 0.030142857687813895 240.94482142857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.4382969156901 0.9145333862304688 763.09265625\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6290  --------------------------\n",
      "Train loss (all, class, reg): 44.294093279157366 0.030047618321010043 273.4755580357143\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.00016825358073 0.17860000610351562 585.8967708333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6300  --------------------------\n",
      "Train loss (all, class, reg): 44.26701714651925 0.01721904754638672 242.4322767857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.14571116129557 0.03877777735392252 572.4480208333333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6310  --------------------------\n",
      "Train loss (all, class, reg): 44.302237352643694 0.09290475027901786 194.09533482142857\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 50.304615122477216 0.18235555013020832 513.4999479166667\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6320  --------------------------\n",
      "Train loss (all, class, reg): 44.196824340820314 0.013380952562604631 275.9572098214286\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.141524912516275 0.14915555318196613 447.1170833333333\n",
      "Test accuracy: 0.88\n",
      "Epoch:  6330  --------------------------\n",
      "Train loss (all, class, reg): 44.289181714739115 0.020200000490461077 259.8027232142857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.45191055297852 0.06413333257039389 532.0908333333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6340  --------------------------\n",
      "Train loss (all, class, reg): 44.22435852050781 0.007038096019199917 222.00285714285715\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 50.32673350016276 0.14117777506510418 438.48\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6350  --------------------------\n",
      "Train loss (all, class, reg): 44.24616577148438 0.014895238876342774 244.50609375\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 50.461806030273436 0.1388222122192383 624.3516666666667\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6360  --------------------------\n",
      "Train loss (all, class, reg): 44.24287867954799 0.010485714503696987 280.46241071428574\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.31723378499349 0.06786666870117188 546.5374479166667\n",
      "Test accuracy: 0.88\n",
      "Epoch:  6370  --------------------------\n",
      "Train loss (all, class, reg): 44.21172177995954 0.008390477044241769 323.75138392857144\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.252569376627605 0.042622222900390624 551.6866145833334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6380  --------------------------\n",
      "Train loss (all, class, reg): 44.105072479248044 0.008447619165693011 213.0510267857143\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 49.921056213378904 0.11835554758707682 518.5553125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6390  --------------------------\n",
      "Train loss (all, class, reg): 43.979319392613 0.06611428397042411 204.594375\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 50.24046330769857 0.5587111409505209 527.3444791666667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6400  --------------------------\n",
      "Train loss (all, class, reg): 44.14639528547014 0.017666666848318916 290.2444642857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.25164744059245 0.3403555806477865 561.3668229166667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6410  --------------------------\n",
      "Train loss (all, class, reg): 44.224920567103794 0.09190475463867187 204.87167410714287\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.01297826131185 0.13548887888590494 603.933125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6420  --------------------------\n",
      "Train loss (all, class, reg): 44.01806073869977 0.05590476989746094 181.46385044642858\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 50.37964279174805 0.16224444071451824 686.77109375\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6430  --------------------------\n",
      "Train loss (all, class, reg): 44.09503904070173 0.07237143380301339 221.33243303571427\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.35573445638021 0.24317776997884114 529.9394270833334\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6440  --------------------------\n",
      "Train loss (all, class, reg): 43.99628409249442 0.05546666826520647 219.21796875\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 50.092054239908855 0.056866671244303384 560.9586458333333\n",
      "Test accuracy: 0.8966666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6450  --------------------------\n",
      "Train loss (all, class, reg): 44.00075703212193 0.014552382060459682 221.23794642857143\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 50.14560577392578 0.53804443359375 568.9225\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6460  --------------------------\n",
      "Train loss (all, class, reg): 43.93899645124163 0.008638095855712891 195.41558035714286\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 50.04195770263672 0.173977788289388 516.8838541666667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6470  --------------------------\n",
      "Train loss (all, class, reg): 43.809100385393414 0.009314285687037877 206.54424107142856\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 50.2447011311849 0.03824444770812988 836.80359375\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6480  --------------------------\n",
      "Train loss (all, class, reg): 43.97677791050502 0.016780951363699777 241.41953125\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 49.77466298421224 0.1710888926188151 455.44197916666667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6490  --------------------------\n",
      "Train loss (all, class, reg): 43.85032052176339 0.008076190267290388 265.190625\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 49.968689931233726 0.2544666544596354 416.04578125\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6500  --------------------------\n",
      "Train loss (all, class, reg): 43.83298688616071 0.0841142817905971 209.160625\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.18425181070963 0.06464444478352864 579.16796875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6510  --------------------------\n",
      "Train loss (all, class, reg): 43.80451442173549 0.08667618887765068 220.27926339285713\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 49.78586776733398 0.21991111755371093 533.49390625\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6520  --------------------------\n",
      "Train loss (all, class, reg): 43.75503287179129 0.012409523555210659 243.2185267857143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 50.09576049804687 0.2901555379231771 472.88890625\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6530  --------------------------\n",
      "Train loss (all, class, reg): 43.661551513671874 0.03117142813546317 217.5475\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 50.21035733540853 0.15071111043294272 342.607734375\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6540  --------------------------\n",
      "Train loss (all, class, reg): 43.70286302839007 0.05281905038016183 232.96234375\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 49.98430348714193 0.4453111267089844 502.42723958333335\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6550  --------------------------\n",
      "Train loss (all, class, reg): 43.62828800746373 0.06245714460100447 249.93410714285713\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 50.2436708577474 0.3774889119466146 501.37635416666666\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6560  --------------------------\n",
      "Train loss (all, class, reg): 43.68622146606445 0.012295237949916295 233.2900892857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 50.05823506673177 0.06782222747802734 553.7345833333334\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6570  --------------------------\n",
      "Train loss (all, class, reg): 43.57591066632952 0.07552380153111049 249.24486607142856\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 49.53095057169596 0.3938221995035807 562.7163020833333\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  6580  --------------------------\n",
      "Train loss (all, class, reg): 43.56235297066825 0.052961905343191965 184.66025669642858\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 49.81873560587565 0.15337777455647786 550.570625\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6590  --------------------------\n",
      "Train loss (all, class, reg): 43.51254558018276 0.010942858287266323 236.39140625\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 49.42144088745117 0.205466677347819 547.7232291666667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6600  --------------------------\n",
      "Train loss (all, class, reg): 43.361725245884486 0.08054286411830357 254.68801339285713\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 49.44031941731771 0.4097111002604167 643.2068229166666\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6610  --------------------------\n",
      "Train loss (all, class, reg): 43.458029065813335 0.012599999564034597 281.55765625\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 49.747188822428384 0.10893333435058594 495.5810416666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6620  --------------------------\n",
      "Train loss (all, class, reg): 43.408409620012556 0.020295238494873045 237.03696428571428\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 49.594674784342445 0.2589555358886719 502.99302083333333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6630  --------------------------\n",
      "Train loss (all, class, reg): 43.2192839050293 0.011342857905796595 252.24801339285713\n",
      "Train accuracy: 0.9614285714285714\n",
      "Test loss (all, class, reg): 50.07071675618489 0.029311110178629557 528.5978125\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6640  --------------------------\n",
      "Train loss (all, class, reg): 43.34100544520787 0.014038095474243164 246.20910714285714\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 49.23339589436849 0.2662888844807943 491.5718229166667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6650  --------------------------\n",
      "Train loss (all, class, reg): 43.24817474365234 0.010447619301932198 204.61700892857144\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 49.22320948282878 0.07077777226765951 592.53265625\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6660  --------------------------\n",
      "Train loss (all, class, reg): 43.26959806169782 0.021466666630336216 212.37810267857142\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 49.31528696695963 0.23697779337565103 506.17942708333334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6670  --------------------------\n",
      "Train loss (all, class, reg): 43.24745930262974 0.015371428898402623 263.2992410714286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 49.34744990030924 0.1343999989827474 566.0205208333333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6680  --------------------------\n",
      "Train loss (all, class, reg): 43.09348161969866 0.015238095692225865 212.60332589285716\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 49.1090690612793 0.33226666768391927 457.66739583333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6690  --------------------------\n",
      "Train loss (all, class, reg): 43.095430319649836 0.05844761439732143 182.45877232142857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 49.41119598388672 0.35873331705729167 531.3016145833334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6700  --------------------------\n",
      "Train loss (all, class, reg): 42.997692565917966 0.00968571390424456 241.65975446428573\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 49.02042470296224 0.09422222137451172 516.9014583333334\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6710  --------------------------\n",
      "Train loss (all, class, reg): 42.907125854492186 0.018980952671595983 215.07285714285715\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 49.4904606628418 0.09766667048136393 613.6861979166666\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6720  --------------------------\n",
      "Train loss (all, class, reg): 42.911361476353235 0.012390475954328264 226.01395089285714\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 49.12708272298177 0.40991109212239585 489.4373958333333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6730  --------------------------\n",
      "Train loss (all, class, reg): 42.961922890799386 0.01885714258466448 223.64261160714287\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 48.939005584716796 0.04611111323038737 692.0047395833334\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6740  --------------------------\n",
      "Train loss (all, class, reg): 42.90837685721261 0.01313333375113351 229.97660714285715\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 49.24115931193034 0.24720001220703125 489.96619791666666\n",
      "Test accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  6750  --------------------------\n",
      "Train loss (all, class, reg): 42.88692463466099 0.013028571265084403 235.53388392857144\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 48.88748626708984 0.3245555623372396 483.10625\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6760  --------------------------\n",
      "Train loss (all, class, reg): 42.85615587506975 0.07374285561697824 187.94051339285716\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 48.97918568929037 0.03244444529215495 528.8721354166667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6770  --------------------------\n",
      "Train loss (all, class, reg): 42.982525089808874 0.013209522792271205 241.78314732142857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 49.068780466715495 0.11504444122314453 467.44135416666666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6780  --------------------------\n",
      "Train loss (all, class, reg): 43.057164808000834 0.08174285888671876 215.75176339285716\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 49.004976501464846 0.1057111104329427 584.86046875\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6790  --------------------------\n",
      "Train loss (all, class, reg): 42.90415274483817 0.01907619067600795 215.9990625\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 48.75439641316732 0.027311108907063803 572.3376041666667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6800  --------------------------\n",
      "Train loss (all, class, reg): 42.73174750191825 0.007990476063319615 228.0756919642857\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 49.10037434895833 0.23639999389648436 562.6355208333333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6810  --------------------------\n",
      "Train loss (all, class, reg): 42.83575557163783 0.011619047437395369 206.48986607142857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 49.398387552897134 0.09164443969726563 527.5121354166666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6820  --------------------------\n",
      "Train loss (all, class, reg): 42.887823617117746 0.036819046565464565 254.85573660714286\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 49.126961364746094 0.40055557250976564 424.821953125\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6830  --------------------------\n",
      "Train loss (all, class, reg): 42.70542227608817 0.01813333375113351 237.35600446428572\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 48.63546300252278 0.13686667124430338 493.74052083333333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6840  --------------------------\n",
      "Train loss (all, class, reg): 42.773716517857146 0.013371429443359374 250.04970982142856\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 49.22127192179362 0.11628889719645183 552.17609375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6850  --------------------------\n",
      "Train loss (all, class, reg): 42.735255192347935 0.09043809618268694 184.25293526785714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 49.327682189941406 0.26811111450195313 434.671640625\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6860  --------------------------\n",
      "Train loss (all, class, reg): 42.758359157017296 0.011257143020629882 225.93484375\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 49.00000111897786 0.1383111063639323 451.05109375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6870  --------------------------\n",
      "Train loss (all, class, reg): 42.73644077845982 0.08019048418317522 228.21004464285716\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 48.875473225911456 0.28297775268554687 433.329921875\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6880  --------------------------\n",
      "Train loss (all, class, reg): 42.63116108485631 0.13216189793178013 189.18417410714287\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 48.670579732259114 0.29262222290039064 613.2311458333334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6890  --------------------------\n",
      "Train loss (all, class, reg): 42.65231205531529 0.011085714612688338 206.11689732142858\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 49.09591547648112 0.0804888916015625 467.56041666666664\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6900  --------------------------\n",
      "Train loss (all, class, reg): 42.59304207938058 0.08463809422084263 203.75450892857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 48.68592295328776 0.0971999994913737 534.719375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6910  --------------------------\n",
      "Train loss (all, class, reg): 42.550305851527625 0.06687619345528739 211.09033482142857\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 48.79552978515625 0.04404444376627604 503.6761979166667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6920  --------------------------\n",
      "Train loss (all, class, reg): 42.51433813912528 0.007885714939662388 208.8724107142857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 48.64254013061523 0.0503333314259847 400.3059895833333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6930  --------------------------\n",
      "Train loss (all, class, reg): 42.56604917253767 0.015257143293108259 332.32379464285714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 48.70192443847656 0.2439555358886719 544.7170833333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6940  --------------------------\n",
      "Train loss (all, class, reg): 42.49573741367885 0.08879047393798828 195.13390625\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 48.62922810872396 0.21286668141682943 525.0169791666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6950  --------------------------\n",
      "Train loss (all, class, reg): 42.446175319126674 0.09917142595563616 244.24147321428572\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 48.61802551269531 0.6384000142415365 578.17140625\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6960  --------------------------\n",
      "Train loss (all, class, reg): 42.43343231201172 0.010457142421177455 211.85979910714286\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 48.36398829142252 0.11337778727213542 587.4438541666667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6970  --------------------------\n",
      "Train loss (all, class, reg): 42.47395111083984 0.08282857077462333 228.38620535714287\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 48.553273111979166 0.07700000127156575 598.3300520833334\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6980  --------------------------\n",
      "Train loss (all, class, reg): 42.38564529418945 0.07625713893345425 199.49354910714285\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 48.81109746297201 0.08362222671508789 486.4511979166667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6990  --------------------------\n",
      "Train loss (all, class, reg): 42.2884258379255 0.16166666303362165 214.3450669642857\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 48.337099100748695 0.0365333366394043 533.4603125\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7000  --------------------------\n",
      "Train loss (all, class, reg): 42.332789350237164 0.13098094395228796 177.3859263392857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 48.475294240315755 0.28386667887369793 442.7239583333333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7010  --------------------------\n",
      "Train loss (all, class, reg): 42.20653690883091 0.011142857415335519 246.7003794642857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 48.567975463867185 0.1512222162882487 510.44067708333336\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7020  --------------------------\n",
      "Train loss (all, class, reg): 42.304117518833706 0.02749523980276925 274.85104910714284\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 48.450379892985026 0.059800001780192055 465.4571875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7030  --------------------------\n",
      "Train loss (all, class, reg): 42.18394005911691 0.019361904689243863 245.87321428571428\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 48.41977183024088 0.15606666564941407 632.5046875\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7040  --------------------------\n",
      "Train loss (all, class, reg): 42.15780585152762 0.013142858232770647 227.26060267857142\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 48.47604807535807 0.12553333282470702 675.7929166666667\n",
      "Test accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7050  --------------------------\n",
      "Train loss (all, class, reg): 42.16589739118304 0.01002857140132359 276.99395089285713\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 48.459628092447915 0.14566666920979818 608.78359375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7060  --------------------------\n",
      "Train loss (all, class, reg): 42.08057368687221 0.0917142813546317 223.02526785714286\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 48.194297587076825 0.16480000813802084 423.7559375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7070  --------------------------\n",
      "Train loss (all, class, reg): 42.15179761614118 0.008161904471261161 293.5808035714286\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 48.25619913736979 0.16615557352701824 560.7989583333333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7080  --------------------------\n",
      "Train loss (all, class, reg): 42.12152685982841 0.013657142094203404 252.00845982142857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 48.26679718017578 0.09402222315470378 501.30223958333335\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7090  --------------------------\n",
      "Train loss (all, class, reg): 42.12823669433594 0.05654284885951451 186.86441964285714\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 48.910760192871095 0.9067777506510417 800.4080208333334\n",
      "Test accuracy: 0.9\n",
      "Epoch:  7100  --------------------------\n",
      "Train loss (all, class, reg): 42.02394343784877 0.019885714394705635 200.58783482142857\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 48.22443806966146 0.18006665547688802 601.8740625\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7110  --------------------------\n",
      "Train loss (all, class, reg): 41.91605248587472 0.040780950273786275 232.2397544642857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 47.92732838948568 0.284022216796875 530.6981770833333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7120  --------------------------\n",
      "Train loss (all, class, reg): 42.028446197509766 0.010152380807059151 217.86200892857144\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 47.9123176574707 0.1756000010172526 481.6336979166667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7130  --------------------------\n",
      "Train loss (all, class, reg): 41.916645115443636 0.09445714678083147 168.43925223214285\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 48.1605951944987 0.18284444173177083 466.1720833333333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7140  --------------------------\n",
      "Train loss (all, class, reg): 41.923375462123325 0.013209524154663086 197.0964955357143\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss (all, class, reg): 48.24506978352865 0.37542223612467446 581.87640625\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7150  --------------------------\n",
      "Train loss (all, class, reg): 41.93461689540318 0.007571428843906948 297.53412946428574\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 47.60565272013346 0.043111111323038735 582.9805208333333\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7160  --------------------------\n",
      "Train loss (all, class, reg): 41.89241053989955 0.0718190438406808 154.248046875\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 47.55705423990885 0.10777776082356771 457.4078125\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7170  --------------------------\n",
      "Train loss (all, class, reg): 41.79565065656389 0.022809524536132813 210.6891294642857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 47.96422617594401 0.24899998982747396 470.3719791666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7180  --------------------------\n",
      "Train loss (all, class, reg): 41.82639192853655 0.008666666575840542 265.4203125\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 47.782621459960936 0.35197779337565105 519.751875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7190  --------------------------\n",
      "Train loss (all, class, reg): 41.748946446010045 0.009076190676007952 270.0742633928571\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 47.37812169392904 0.2704888916015625 529.2197395833333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7200  --------------------------\n",
      "Train loss (all, class, reg): 41.80021628243583 0.011352381025041852 210.89232142857142\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 47.83619862874349 0.020955554644266763 504.40296875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7210  --------------------------\n",
      "Train loss (all, class, reg): 41.62360120500837 0.060152380807059154 197.50087053571428\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 47.836027475992836 0.336022211710612 543.2272916666667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7220  --------------------------\n",
      "Train loss (all, class, reg): 41.6979836164202 0.013047618865966797 205.79654017857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 47.212136840820314 0.2681555430094401 550.1624479166667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7230  --------------------------\n",
      "Train loss (all, class, reg): 41.57027093069894 0.0122761903490339 229.48395089285714\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 48.3411013285319 0.04446666717529297 627.7446354166667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7240  --------------------------\n",
      "Train loss (all, class, reg): 41.572355237688335 0.07178095136369977 241.65205357142858\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 47.67318603515625 0.07371111551920573 462.4628125\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7250  --------------------------\n",
      "Train loss (all, class, reg): 41.62688446044922 0.01762857164655413 233.8382142857143\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 47.5252685546875 0.12399998982747396 550.9441666666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7260  --------------------------\n",
      "Train loss (all, class, reg): 41.738389870779855 0.01844761984688895 236.45881696428572\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 47.798506368001306 0.07762222290039063 523.7186979166667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7270  --------------------------\n",
      "Train loss (all, class, reg): 41.64206324986049 0.06491428920200892 178.027421875\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 48.22859242757161 0.35840001424153645 516.7508333333334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7280  --------------------------\n",
      "Train loss (all, class, reg): 41.629255632672994 0.08299999782017299 210.67372767857142\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 47.6281157430013 0.2196666717529297 455.8222395833333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7290  --------------------------\n",
      "Train loss (all, class, reg): 41.52551766531808 0.022904763902936665 230.12290178571428\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 47.52679234822591 0.17428887685139974 480.5215104166667\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7300  --------------------------\n",
      "Train loss (all, class, reg): 41.45001911708287 0.013552382332938057 224.3990625\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 47.63504730224609 0.14671112060546876 412.2152864583333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7310  --------------------------\n",
      "Train loss (all, class, reg): 41.52516239711216 0.12801904950823104 186.7387611607143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 48.03026082356771 0.14006666819254557 505.20989583333335\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7320  --------------------------\n",
      "Train loss (all, class, reg): 41.46701751708984 0.01344761848449707 269.50332589285716\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 47.00617970784505 0.09831111907958984 629.0215104166666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7330  --------------------------\n",
      "Train loss (all, class, reg): 41.463844953264505 0.01205714362008231 196.35852678571428\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 47.816415303548176 0.11286666870117187 496.28703125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7340  --------------------------\n",
      "Train loss (all, class, reg): 41.480539071219305 0.07470475878034319 194.38970982142857\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 47.43688125610352 0.0795555559794108 449.56244791666666\n",
      "Test accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7350  --------------------------\n",
      "Train loss (all, class, reg): 41.35066898890904 0.006704762322562082 253.9010267857143\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 47.48595657348633 0.10802223205566407 537.6033333333334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7360  --------------------------\n",
      "Train loss (all, class, reg): 41.36290934971401 0.05585714067731585 198.89381696428572\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 47.20162241617839 0.4847333272298177 444.5458854166667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  7370  --------------------------\n",
      "Train loss (all, class, reg): 41.28992436000279 0.017666666848318916 236.29691964285715\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 47.52724787394206 0.054111111958821616 431.32536458333334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7380  --------------------------\n",
      "Train loss (all, class, reg): 41.24619402204241 0.053038101196289066 168.6371986607143\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 47.27148274739584 0.22062220255533854 418.2632552083333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7390  --------------------------\n",
      "Train loss (all, class, reg): 41.16436327253069 0.012047620500837054 217.56832589285713\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 47.45653956095378 0.029733333587646484 612.41546875\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7400  --------------------------\n",
      "Train loss (all, class, reg): 41.23007984706334 0.005009523800441197 205.63533482142856\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 47.22567677815755 0.09546666463216145 549.7531770833333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7410  --------------------------\n",
      "Train loss (all, class, reg): 41.11918433053153 0.08339047023228237 181.32291294642857\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 47.03622314453125 0.23042221069335939 643.095625\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7420  --------------------------\n",
      "Train loss (all, class, reg): 41.301700221470426 0.010104761804853167 221.29482142857142\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 46.98631083170573 0.2225555419921875 626.2676041666666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7430  --------------------------\n",
      "Train loss (all, class, reg): 41.20165416172573 0.008638095855712891 252.93158482142857\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 46.880865987141924 0.12597777048746744 581.0197395833334\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7440  --------------------------\n",
      "Train loss (all, class, reg): 41.15965131487165 0.010961904525756835 191.31459821428572\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 47.10974706013997 0.40044443766276044 539.0096354166667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7450  --------------------------\n",
      "Train loss (all, class, reg): 41.10332981654576 0.009514285496303013 266.63578125\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.82923492431641 0.06206666310628255 656.483125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7460  --------------------------\n",
      "Train loss (all, class, reg): 41.022657405308316 0.015142857687813895 218.22569196428572\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 47.22665186564127 0.05964444478352864 522.2965625\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7470  --------------------------\n",
      "Train loss (all, class, reg): 41.147601558140344 0.01509523800441197 201.90147321428572\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 46.80923192342122 0.14073333740234376 597.7654166666666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7480  --------------------------\n",
      "Train loss (all, class, reg): 41.17950411115374 0.017333333151681084 288.88984375\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 47.284860636393226 0.2906000264485677 765.5452083333333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7490  --------------------------\n",
      "Train loss (all, class, reg): 41.05153536115374 0.013904762268066407 216.52098214285715\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss (all, class, reg): 47.059172007242836 0.2575333404541016 560.631875\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  7500  --------------------------\n",
      "Train loss (all, class, reg): 41.01520603724888 0.023219048636300223 218.8761607142857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 46.90218236287435 0.1555555470784505 491.63114583333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7510  --------------------------\n",
      "Train loss (all, class, reg): 40.96046925136021 0.005542857306344169 179.04580357142856\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 46.877939809163415 0.0971333376566569 450.22828125\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7520  --------------------------\n",
      "Train loss (all, class, reg): 40.98028645106724 0.01566666739327567 190.78979910714287\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 46.89232111612956 0.1647555414835612 436.117734375\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7530  --------------------------\n",
      "Train loss (all, class, reg): 40.899371686662946 0.009095238276890346 212.46939732142857\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 46.76641342163086 0.16504444122314454 545.2522916666667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7540  --------------------------\n",
      "Train loss (all, class, reg): 40.95350808279855 0.010495238985334124 208.30854910714285\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 46.76136952718099 0.16971111297607422 502.91520833333334\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7550  --------------------------\n",
      "Train loss (all, class, reg): 40.940977783203124 0.013400001525878906 198.01497767857143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 47.02236399332682 0.025466667811075847 424.44307291666667\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7560  --------------------------\n",
      "Train loss (all, class, reg): 40.81989190237863 0.01896190507071359 227.46642857142857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.86542744954427 0.17671112060546876 553.1626041666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7570  --------------------------\n",
      "Train loss (all, class, reg): 40.769855281284876 0.06237142835344587 174.75129464285715\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 47.21939931233724 0.2947777811686198 438.71369791666666\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7580  --------------------------\n",
      "Train loss (all, class, reg): 40.912505929129466 0.07703809465680804 185.49018973214285\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 46.712525126139326 0.09493333180745443 510.04703125\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7590  --------------------------\n",
      "Train loss (all, class, reg): 40.773570687430244 0.012066666739327566 186.2303125\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 46.72074579874675 0.13813334147135417 609.4558333333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7600  --------------------------\n",
      "Train loss (all, class, reg): 40.70961018153599 0.022504762922014507 178.79758928571428\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 46.840777689615884 0.21555557250976562 489.2875520833333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7610  --------------------------\n",
      "Train loss (all, class, reg): 40.941185280936104 0.011276190621512278 206.31611607142858\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 46.475533905029295 0.7142889404296875 392.53541666666666\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7620  --------------------------\n",
      "Train loss (all, class, reg): 40.88246335710798 0.008019048145839145 219.95529017857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 46.533807373046876 0.34235555013020835 562.0282291666666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7630  --------------------------\n",
      "Train loss (all, class, reg): 40.68727763584682 0.0465142822265625 191.16799107142856\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 46.578749084472655 0.07031111399332682 509.3748958333333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7640  --------------------------\n",
      "Train loss (all, class, reg): 40.91136520385742 0.013219048636300223 229.30591517857144\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 46.58357406616211 0.07611111323038737 475.7881770833333\n",
      "Test accuracy: 0.8933333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7650  --------------------------\n",
      "Train loss (all, class, reg): 40.67934058053153 0.009723809106009347 201.17111607142857\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss (all, class, reg): 46.78652699788412 0.22046666463216147 432.16432291666666\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7660  --------------------------\n",
      "Train loss (all, class, reg): 40.65259427751813 0.01440000125340053 205.05930803571428\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 46.64306091308594 0.2546000162760417 736.2643229166666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7670  --------------------------\n",
      "Train loss (all, class, reg): 40.69066861833845 0.009580952780587333 224.84171875\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 46.49142471313476 0.3724889119466146 602.8789583333333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7680  --------------------------\n",
      "Train loss (all, class, reg): 40.65205596923828 0.02316190447126116 245.8530580357143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 47.010758005777994 0.1562666702270508 450.57395833333334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7690  --------------------------\n",
      "Train loss (all, class, reg): 40.69254405430385 0.013695237295968192 250.95479910714286\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.51184682210287 0.7342889404296875 431.3128385416667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7700  --------------------------\n",
      "Train loss (all, class, reg): 40.60028747558594 0.08505714416503907 175.88059151785714\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.54792439778646 0.08926666259765625 506.97989583333333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7710  --------------------------\n",
      "Train loss (all, class, reg): 40.542791486467635 0.01521904672895159 173.12782366071428\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 46.536932373046874 0.10444445292154948 567.4905729166667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7720  --------------------------\n",
      "Train loss (all, class, reg): 40.59641937255859 0.08053333282470704 233.79551339285715\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 46.4935878499349 0.21228888193766277 428.1309635416667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  7730  --------------------------\n",
      "Train loss (all, class, reg): 40.53074462890625 0.008123809269496372 245.90348214285714\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 46.87785883585612 0.15888888041178387 452.0596875\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7740  --------------------------\n",
      "Train loss (all, class, reg): 40.49130613054548 0.01581904820033482 202.17868303571427\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 46.43287633260091 0.1435777791341146 505.2315625\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7750  --------------------------\n",
      "Train loss (all, class, reg): 40.57484856741769 0.04345714569091797 185.38517857142858\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 46.83524597167969 0.07711111068725586 635.12140625\n",
      "Test accuracy: 0.9\n",
      "Epoch:  7760  --------------------------\n",
      "Train loss (all, class, reg): 40.634898943219866 0.07812380109514509 182.21104910714286\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 45.94552490234375 0.17579999287923176 478.15921875\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7770  --------------------------\n",
      "Train loss (all, class, reg): 40.46824199131557 0.01348571504865374 226.29433035714285\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss (all, class, reg): 46.33290781656901 0.10411111195882161 463.82239583333336\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7780  --------------------------\n",
      "Train loss (all, class, reg): 40.559238978794646 0.010180952208382743 180.72282366071428\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.45806798299154 0.4329555257161458 412.886875\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7790  --------------------------\n",
      "Train loss (all, class, reg): 40.47920887538365 0.007638095446995326 195.92149553571429\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.29927968343099 0.5632667032877604 418.0719270833333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7800  --------------------------\n",
      "Train loss (all, class, reg): 40.42227397373745 0.06549523489815848 187.24522321428572\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.786652908325195 0.2127333196004232 306.28822916666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7810  --------------------------\n",
      "Train loss (all, class, reg): 40.3214323425293 0.014371427808489119 262.6628348214286\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 46.05248041788737 0.06948889414469402 562.6358854166666\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  7820  --------------------------\n",
      "Train loss (all, class, reg): 40.398817443847655 0.11421905517578125 186.70175223214287\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.43139200846354 0.32026664733886717 377.7422135416667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7830  --------------------------\n",
      "Train loss (all, class, reg): 40.40032302856445 0.11637142726353236 200.20252232142857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 46.35080037434896 0.2640222422281901 478.14671875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7840  --------------------------\n",
      "Train loss (all, class, reg): 40.258675733293806 0.0706095232282366 217.17566964285714\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.31907348632812 0.09002222696940104 598.8061979166666\n",
      "Test accuracy: 0.9\n",
      "Epoch:  7850  --------------------------\n",
      "Train loss (all, class, reg): 40.35277478899275 0.014552380698067802 202.69810267857142\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 46.41647613525391 0.05802221934000651 497.01859375\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7860  --------------------------\n",
      "Train loss (all, class, reg): 40.09018112182617 0.009257142884390696 193.13352678571428\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 45.951702473958335 0.061466668446858726 551.4647916666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7870  --------------------------\n",
      "Train loss (all, class, reg): 40.19690763201032 0.013428570883614677 242.14649553571428\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 45.6660194905599 0.2536444600423177 516.06609375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  7880  --------------------------\n",
      "Train loss (all, class, reg): 40.21866860525949 0.01215238162449428 216.9881919642857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.229821014404294 0.22773335774739584 535.6079166666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7890  --------------------------\n",
      "Train loss (all, class, reg): 40.106095057896205 0.07849524361746651 177.127734375\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 46.02387334187826 0.33382222493489583 536.90265625\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7900  --------------------------\n",
      "Train loss (all, class, reg): 40.00956407819476 0.0868952396937779 165.00229910714285\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 45.641827952067054 0.2828444417317708 460.49578125\n",
      "Test accuracy: 0.9\n",
      "Epoch:  7910  --------------------------\n",
      "Train loss (all, class, reg): 39.868144836425785 0.11920950753348214 202.74890625\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 45.832779998779294 0.21882222493489584 435.90588541666665\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7920  --------------------------\n",
      "Train loss (all, class, reg): 39.92518960135324 0.08048570905412947 213.57982142857142\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 46.158606669108075 0.16055554707845052 448.2341666666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7930  --------------------------\n",
      "Train loss (all, class, reg): 39.880293906075615 0.08877142769949777 208.19267857142856\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 45.89884267171224 0.1413999938964844 449.7654166666667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7940  --------------------------\n",
      "Train loss (all, class, reg): 39.84285430908203 0.06961904798235212 157.55202008928572\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 45.68513392130534 0.3950000254313151 447.4394791666667\n",
      "Test accuracy: 0.8966666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7950  --------------------------\n",
      "Train loss (all, class, reg): 39.83848005022321 0.015133334568568638 223.801875\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 45.57223968505859 0.37991114298502604 622.27140625\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7960  --------------------------\n",
      "Train loss (all, class, reg): 39.834805472237726 0.015019048963274275 207.1250892857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 45.76783111572266 0.19922223409016926 562.5697395833333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7970  --------------------------\n",
      "Train loss (all, class, reg): 39.80584527151925 0.010295237813677107 221.42683035714285\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 46.00483489990234 0.03588888804117839 602.02859375\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7980  --------------------------\n",
      "Train loss (all, class, reg): 39.67360454014369 0.1426285661969866 217.01348214285716\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 45.550674489339194 0.0892222277323405 559.5136458333334\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7990  --------------------------\n",
      "Train loss (all, class, reg): 39.730701293945316 0.013914285387311662 197.29700892857142\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 45.71761622111003 0.20524444580078124 365.1792447916667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8000  --------------------------\n",
      "Train loss (all, class, reg): 39.63648173740932 0.09063808441162109 152.98625\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 45.79309682210287 0.2046222178141276 454.22682291666666\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8010  --------------------------\n",
      "Train loss (all, class, reg): 39.54777481079102 0.010561905588422503 204.71167410714287\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 45.60212773640951 0.39480000813802085 591.07703125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8020  --------------------------\n",
      "Train loss (all, class, reg): 39.702062290736606 0.009504761695861817 282.28517857142856\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 45.716461690266925 0.10762222290039063 402.2973177083333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8030  --------------------------\n",
      "Train loss (all, class, reg): 39.69416994367327 0.01174285616193499 202.81011160714286\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 45.96175170898437 0.14628887176513672 397.1014583333333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8040  --------------------------\n",
      "Train loss (all, class, reg): 39.687325722830636 0.008752380779811313 242.26796875\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 45.62416748046875 0.13006666819254556 504.61973958333334\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8050  --------------------------\n",
      "Train loss (all, class, reg): 39.64816696166992 0.06673333304268973 179.11510044642858\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 45.421693064371745 0.4057110595703125 457.75083333333333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8060  --------------------------\n",
      "Train loss (all, class, reg): 39.6381224496024 0.08658095223563059 164.67354910714286\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 45.23161173502604 0.04313333511352539 461.9749479166667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8070  --------------------------\n",
      "Train loss (all, class, reg): 39.58822107587542 0.003447619165693011 180.92919642857143\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 45.34737436930339 0.13284444173177085 552.339375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8080  --------------------------\n",
      "Train loss (all, class, reg): 39.51249986921038 0.18392379760742186 146.95551339285714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 45.65664713541667 0.3408666483561198 533.93515625\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8090  --------------------------\n",
      "Train loss (all, class, reg): 39.484607892717634 0.006495238031659807 181.973359375\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 45.59665456136068 0.5120667012532553 562.543125\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8100  --------------------------\n",
      "Train loss (all, class, reg): 39.471922062465126 0.011066665649414062 220.93428571428572\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 45.55881856282552 0.14379999796549478 459.8203125\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8110  --------------------------\n",
      "Train loss (all, class, reg): 39.47714235578265 0.008666666575840542 159.16832589285715\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 45.09109619140625 0.18942220052083333 557.43203125\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8120  --------------------------\n",
      "Train loss (all, class, reg): 39.37343296595982 0.007952381542750768 224.99714285714285\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 45.30043151855469 0.10582222620646159 474.29302083333334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8130  --------------------------\n",
      "Train loss (all, class, reg): 39.30862954275948 0.06122857230050223 231.87147321428571\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 45.397212219238284 0.2733333079020182 508.06244791666666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8140  --------------------------\n",
      "Train loss (all, class, reg): 39.507601579938616 0.06971428462437221 205.16696428571427\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 45.36380111694336 0.14606666564941406 472.16432291666666\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8150  --------------------------\n",
      "Train loss (all, class, reg): 39.32662756783622 0.08640953063964844 163.71939732142857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 45.3904731241862 0.2893333435058594 384.95671875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8160  --------------------------\n",
      "Train loss (all, class, reg): 39.30735201154437 0.04584761483328683 184.87410714285716\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 45.15341196695964 0.297955576578776 551.64546875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8170  --------------------------\n",
      "Train loss (all, class, reg): 39.31915525163923 0.061504756382533485 196.4139955357143\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 45.07963775634766 0.19937778472900392 605.83984375\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8180  --------------------------\n",
      "Train loss (all, class, reg): 39.34049085344587 0.015904761723109655 211.24022321428572\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 44.98558029174805 0.06895554860432943 651.5909375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8190  --------------------------\n",
      "Train loss (all, class, reg): 39.288941628592355 0.03578095027378627 218.28323660714287\n",
      "Train accuracy: 0.96\n",
      "Test loss (all, class, reg): 46.541822814941405 0.46884445190429686 357.81244791666666\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8200  --------------------------\n",
      "Train loss (all, class, reg): 39.29783388410296 0.007876190458025251 200.48408482142858\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.9930066426595 0.0870888900756836 455.65130208333335\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8210  --------------------------\n",
      "Train loss (all, class, reg): 39.34762257167271 0.0812095206124442 204.5952455357143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 45.21736740112305 0.0826888910929362 413.40002604166665\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8220  --------------------------\n",
      "Train loss (all, class, reg): 39.16598286220005 0.007838095256260464 294.99071428571426\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.92769556681315 0.3491110992431641 492.5381770833333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8230  --------------------------\n",
      "Train loss (all, class, reg): 39.12568590436663 0.02151428495134626 198.5271205357143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.956807708740236 0.21542221069335937 363.328359375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8240  --------------------------\n",
      "Train loss (all, class, reg): 39.13708483014788 0.006838095528738839 175.04573660714286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 45.219106648763024 0.11866666158040365 500.16348958333333\n",
      "Test accuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8250  --------------------------\n",
      "Train loss (all, class, reg): 39.08600391932896 0.08505713326590401 206.47497767857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 45.148140360514326 0.42457778930664064 625.9326041666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8260  --------------------------\n",
      "Train loss (all, class, reg): 39.20491853986468 0.01205714362008231 218.47457589285713\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 45.03993662516276 0.13191112518310547 496.6510416666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8270  --------------------------\n",
      "Train loss (all, class, reg): 39.00895030430385 0.019628572463989257 226.62783482142856\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.688557891845704 0.48084442138671873 560.4688020833333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8280  --------------------------\n",
      "Train loss (all, class, reg): 39.04568311418806 0.02480952399117606 182.93483258928572\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 44.89502695719401 0.15033332824707032 460.18177083333336\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8290  --------------------------\n",
      "Train loss (all, class, reg): 39.048360050746375 0.014647618702479772 215.54207589285716\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 45.01757446289062 0.06011111577351888 465.4817708333333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8300  --------------------------\n",
      "Train loss (all, class, reg): 38.98148478916713 0.02503809520176479 202.14988839285715\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 45.36658055623372 0.0988444455464681 574.6322916666667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8310  --------------------------\n",
      "Train loss (all, class, reg): 38.862550811767576 0.007685714449201311 190.16741071428572\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss (all, class, reg): 45.45814951578776 0.024155556360880535 589.6732291666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8320  --------------------------\n",
      "Train loss (all, class, reg): 38.9117030770438 0.09236190795898437 206.57388392857143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 44.77573582967123 0.07662222544352214 550.3930729166667\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  8330  --------------------------\n",
      "Train loss (all, class, reg): 38.930642918178016 0.013219048636300223 216.53502232142858\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 45.18639689127604 0.04900000254313151 397.1920572916667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8340  --------------------------\n",
      "Train loss (all, class, reg): 38.81090105329241 0.007209523064749581 224.74660714285713\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 44.574109700520836 0.15037776947021483 565.7324479166666\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8350  --------------------------\n",
      "Train loss (all, class, reg): 38.83323455810547 0.007457143238612584 215.51337053571427\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.89600138346354 0.10117777506510417 527.8578645833334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8360  --------------------------\n",
      "Train loss (all, class, reg): 38.8465090070452 0.0836857169015067 208.05651785714286\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 44.783914947509764 0.04622222264607748 442.2840625\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8370  --------------------------\n",
      "Train loss (all, class, reg): 38.780824236188614 0.009038095474243163 192.69919642857144\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 44.417264200846354 0.2361333211263021 384.273359375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8380  --------------------------\n",
      "Train loss (all, class, reg): 38.75926430838449 0.08265714372907366 232.06736607142858\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 44.61284901936849 0.19457776387532552 464.33015625\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8390  --------------------------\n",
      "Train loss (all, class, reg): 38.74536006382534 0.011752382005964008 183.89824776785716\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 44.758383178710936 0.1403777821858724 620.68515625\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8400  --------------------------\n",
      "Train loss (all, class, reg): 38.585388902936664 0.0074857139587402345 177.356640625\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 44.983717651367186 0.12924444834391277 558.8883333333333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8410  --------------------------\n",
      "Train loss (all, class, reg): 38.60916458129883 0.024409523010253908 180.72877232142858\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 44.85768244425456 0.3929333241780599 369.90369791666666\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8420  --------------------------\n",
      "Train loss (all, class, reg): 38.555965728759766 0.07718094961983817 168.51628348214285\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 44.566366831461586 0.08457777659098308 629.4983333333333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8430  --------------------------\n",
      "Train loss (all, class, reg): 38.49994158063616 0.007571428162711007 221.18107142857144\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 44.804493306477866 0.3755555725097656 487.99364583333335\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8440  --------------------------\n",
      "Train loss (all, class, reg): 38.554372961861745 0.0101238100869315 174.99261160714286\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 44.18208740234375 0.40497777303059895 333.83393229166666\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8450  --------------------------\n",
      "Train loss (all, class, reg): 38.557966090611046 0.00908571447644915 223.90417410714286\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 44.67560038248698 0.0712000020345052 408.6157552083333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8460  --------------------------\n",
      "Train loss (all, class, reg): 38.57518796648298 0.00971428598676409 211.5974107142857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.64558349609375 0.060577774047851564 565.5380729166667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8470  --------------------------\n",
      "Train loss (all, class, reg): 38.49250326974051 0.11591427394321986 212.19834821428572\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 44.33333724975586 0.2462444305419922 623.6560416666666\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8480  --------------------------\n",
      "Train loss (all, class, reg): 38.44431435721261 0.05831428527832031 164.577265625\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 44.74619379679362 0.2701333363850911 489.479375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8490  --------------------------\n",
      "Train loss (all, class, reg): 38.44809276035854 0.011704762322562082 202.66245535714285\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 44.1219867960612 0.04462222417195638 522.18484375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8500  --------------------------\n",
      "Train loss (all, class, reg): 38.492555193219864 0.10594286237444196 173.41495535714284\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.56609883626302 0.0704222297668457 630.3169270833333\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8510  --------------------------\n",
      "Train loss (all, class, reg): 38.548801465715684 0.007180952344621931 187.18135044642858\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 44.00286112467448 0.16235555013020833 407.1605729166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8520  --------------------------\n",
      "Train loss (all, class, reg): 38.41880771092006 0.017161903381347657 165.8607142857143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.30081899007161 0.0486222235361735 558.9992708333333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8530  --------------------------\n",
      "Train loss (all, class, reg): 38.47128912789481 0.01663809640066964 239.80774553571428\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.761633504231774 0.21344444274902344 564.0508333333333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8540  --------------------------\n",
      "Train loss (all, class, reg): 38.448079376220704 0.0370095225742885 200.73116071428572\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.50946263631185 0.05004444758097331 494.72078125\n",
      "Test accuracy: 0.9033333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8550  --------------------------\n",
      "Train loss (all, class, reg): 38.45837452479771 0.010580952508108957 205.53685267857142\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 44.70172134399414 0.21373334248860676 451.9146875\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8560  --------------------------\n",
      "Train loss (all, class, reg): 38.343497794015065 0.007323810032435826 244.96810267857143\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 43.97496378580729 0.2745777638753255 580.6494270833333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8570  --------------------------\n",
      "Train loss (all, class, reg): 38.31857195172991 0.09179999215262277 183.5554575892857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 44.91941263834635 0.03462222417195638 572.6675\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8580  --------------------------\n",
      "Train loss (all, class, reg): 38.53352375575474 0.01038095201764788 246.27651785714286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 44.36229675292969 0.08582222620646159 530.57796875\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8590  --------------------------\n",
      "Train loss (all, class, reg): 38.293098689488005 0.10284761701311385 165.06050223214285\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 44.281397094726564 0.3586888631184896 531.5986979166667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8600  --------------------------\n",
      "Train loss (all, class, reg): 38.3866155569894 0.008209524154663085 251.10294642857144\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 43.84243377685547 0.20042222340901691 435.91096354166666\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8610  --------------------------\n",
      "Train loss (all, class, reg): 38.29545104980469 0.10809522356305803 160.67301339285714\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 44.21174555460612 0.25980000813802084 333.35541666666666\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8620  --------------------------\n",
      "Train loss (all, class, reg): 38.3661077444894 0.04276190076555524 195.8058482142857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 44.17099980672201 0.16624444325764973 389.698671875\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8630  --------------------------\n",
      "Train loss (all, class, reg): 38.21704599652971 0.0045904765810285296 164.12574776785715\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.92748077392578 0.13128888448079426 425.81841145833334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8640  --------------------------\n",
      "Train loss (all, class, reg): 38.091260811941964 0.07099047524588449 190.725625\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.21005147298177 0.13251111348470052 617.9922916666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8650  --------------------------\n",
      "Train loss (all, class, reg): 38.167828587123324 0.011552380153111049 212.0352232142857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 44.50119623819987 0.24442220052083333 493.3886458333333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8660  --------------------------\n",
      "Train loss (all, class, reg): 38.12310782296317 0.03307619094848633 198.17381696428572\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 44.271136830647784 0.03644444465637207 470.22546875\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8670  --------------------------\n",
      "Train loss (all, class, reg): 38.18332018171038 0.08207619803292411 197.60020089285715\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.72194137573242 0.1534000015258789 500.75708333333336\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8680  --------------------------\n",
      "Train loss (all, class, reg): 38.12084498814174 0.00617142813546317 199.28765625\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.71839548746745 0.03508889516194662 458.0999479166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8690  --------------------------\n",
      "Train loss (all, class, reg): 38.14393011910575 0.008257142475673131 212.71303571428572\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 44.16168792724609 0.28246668497721356 458.6888020833333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8700  --------------------------\n",
      "Train loss (all, class, reg): 38.14948599679129 0.009828571592058454 241.28162946428571\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.83757827758789 0.050022220611572264 530.75484375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8710  --------------------------\n",
      "Train loss (all, class, reg): 38.143364998953686 0.006495238031659807 233.01607142857142\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 43.91057902018229 0.19580001831054689 434.831328125\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8720  --------------------------\n",
      "Train loss (all, class, reg): 38.13633329119001 0.00784761905670166 181.79308035714286\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.0565825398763 0.5086444091796875 388.1192447916667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8730  --------------------------\n",
      "Train loss (all, class, reg): 38.05142100742885 0.05269524165562221 201.07716517857142\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 44.301561482747395 0.3010888926188151 361.3815104166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8740  --------------------------\n",
      "Train loss (all, class, reg): 38.155567670549665 0.008599999972752162 205.14267857142858\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 44.228340555826826 0.265911127726237 447.7796354166667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8750  --------------------------\n",
      "Train loss (all, class, reg): 38.101587807791574 0.008000000544956752 228.26504464285713\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.83280568440755 0.306933339436849 403.49322916666665\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8760  --------------------------\n",
      "Train loss (all, class, reg): 38.04292168753488 0.013076190948486327 225.58660714285713\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 44.18228393554688 0.03193333307902018 521.03203125\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8770  --------------------------\n",
      "Train loss (all, class, reg): 38.07226235525949 0.008742856979370116 204.9610044642857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 43.781669921875 0.2392888895670573 441.2249479166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8780  --------------------------\n",
      "Train loss (all, class, reg): 37.893087463378905 0.009285714285714286 248.90839285714284\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 43.67592742919922 0.5198221842447917 547.0424479166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8790  --------------------------\n",
      "Train loss (all, class, reg): 37.9055670601981 0.008590476172310966 229.86609375\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 43.67723841349284 0.1210888926188151 562.754375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8800  --------------------------\n",
      "Train loss (all, class, reg): 37.90186325073242 0.007104761941092355 205.83700892857144\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.8378439839681 0.08971111297607422 525.69609375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8810  --------------------------\n",
      "Train loss (all, class, reg): 37.917069854736326 0.016628570556640625 204.01904017857143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 43.62895497639974 0.15924443562825522 510.7426041666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8820  --------------------------\n",
      "Train loss (all, class, reg): 37.79697503226144 0.008980952671595982 207.75129464285715\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 43.75901794433594 0.04695555686950684 584.3074479166667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8830  --------------------------\n",
      "Train loss (all, class, reg): 37.80658148629325 0.08210476466587611 158.24985491071428\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 43.78770380655924 0.06215555826822917 527.39984375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8840  --------------------------\n",
      "Train loss (all, class, reg): 37.79777633666992 0.009571428298950196 220.75479910714284\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.38715433756511 0.31355555216471354 346.84619791666665\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8850  --------------------------\n",
      "Train loss (all, class, reg): 37.81408211844308 0.007676189967564174 193.86763392857142\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 43.440770365397135 0.3087999979654948 502.6845833333333\n",
      "Test accuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8860  --------------------------\n",
      "Train loss (all, class, reg): 37.71605673653739 0.011561905997140067 258.87642857142856\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.32360265096029 0.4434222412109375 458.9444270833333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8870  --------------------------\n",
      "Train loss (all, class, reg): 37.686590292794364 0.04041904994419643 168.66909598214286\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.28583552042643 0.029888887405395508 579.2863020833333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8880  --------------------------\n",
      "Train loss (all, class, reg): 37.62492695399693 0.011266666821071079 242.58466517857144\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss (all, class, reg): 43.235215504964195 0.10475556055704753 508.1080729166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8890  --------------------------\n",
      "Train loss (all, class, reg): 37.63727052961077 0.00930476188659668 214.7536830357143\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 43.72345230102539 0.1798888905843099 551.6945833333333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8900  --------------------------\n",
      "Train loss (all, class, reg): 37.60015010288784 0.008161905152457101 200.47767857142858\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 43.190892130533854 0.14677777608235676 465.436875\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8910  --------------------------\n",
      "Train loss (all, class, reg): 37.6722424534389 0.08359048025948661 213.08832589285714\n",
      "Train accuracy: 0.96\n",
      "Test loss (all, class, reg): 43.53651921590169 0.2741777801513672 475.0409895833333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8920  --------------------------\n",
      "Train loss (all, class, reg): 37.57876031058175 0.007990476063319615 205.28607142857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 43.45210906982422 0.23899998982747395 541.8363020833333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8930  --------------------------\n",
      "Train loss (all, class, reg): 37.73213570731027 0.010733333315168108 214.36412946428572\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.64393636067708 0.09888888041178386 385.87734375\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8940  --------------------------\n",
      "Train loss (all, class, reg): 37.62752670288086 0.02832381112234933 183.04435267857144\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.43786092122396 0.40415555318196617 501.95635416666664\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8950  --------------------------\n",
      "Train loss (all, class, reg): 37.63007864815848 0.005076190403529576 257.1624107142857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 43.63436477661133 0.10146666844685873 537.4552083333333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8960  --------------------------\n",
      "Train loss (all, class, reg): 37.516238664899554 0.009819047791617257 180.0445982142857\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 43.196054178873695 0.10019999821980795 400.74526041666667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8970  --------------------------\n",
      "Train loss (all, class, reg): 37.46807883126395 0.07960952758789062 174.1285825892857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.557689565022784 0.05211111068725586 553.6715104166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  8980  --------------------------\n",
      "Train loss (all, class, reg): 37.5954108101981 0.01803809574672154 248.04285714285714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.29475331624349 0.11413333892822265 364.78973958333336\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  8990  --------------------------\n",
      "Train loss (all, class, reg): 37.5664397757394 0.007314286231994629 185.1653794642857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 43.584254048665365 0.22339998881022136 439.29692708333334\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  9000  --------------------------\n",
      "Train loss (all, class, reg): 37.42288822719029 0.009161904879978726 179.184453125\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 43.47192148844401 0.2408666483561198 431.91888020833335\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9010  --------------------------\n",
      "Train loss (all, class, reg): 37.360431431361604 0.0059999997275216235 187.09333705357142\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.447261047363284 0.23279998779296876 427.21106770833336\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9020  --------------------------\n",
      "Train loss (all, class, reg): 37.5434963117327 0.005771428516932896 177.5957924107143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 43.14010889689128 0.06704444885253906 561.7600520833333\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  9030  --------------------------\n",
      "Train loss (all, class, reg): 37.43326675415039 0.00607619081224714 222.64919642857143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 43.132533416748046 0.11971110026041666 515.8059895833334\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9040  --------------------------\n",
      "Train loss (all, class, reg): 37.509326847621374 0.008942856788635253 201.66167410714286\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.378537292480466 0.40762224833170574 391.2875\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9050  --------------------------\n",
      "Train loss (all, class, reg): 37.49918635777065 0.005400000299726214 212.31035714285716\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 43.28367426554362 0.15299999237060546 455.59265625\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9060  --------------------------\n",
      "Train loss (all, class, reg): 37.32134508405413 0.014819047110421316 200.41629464285714\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 43.541403198242186 0.33311111450195313 357.55997395833333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9070  --------------------------\n",
      "Train loss (all, class, reg): 37.33946480887277 0.018657142094203404 192.5871205357143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.194385375976566 0.09331110636393229 522.9433333333334\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9080  --------------------------\n",
      "Train loss (all, class, reg): 37.244043884277346 0.005695238113403321 194.53609375\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 42.92157018025716 0.08651111602783203 574.8973958333333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9090  --------------------------\n",
      "Train loss (all, class, reg): 37.288035474504746 0.014438095092773438 231.84665178571427\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 43.68033172607422 0.03591111501057943 445.46875\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9100  --------------------------\n",
      "Train loss (all, class, reg): 37.2065712411063 0.015523809705461775 215.04388392857143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 43.44284327189128 0.25195556640625 512.0611458333333\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  9110  --------------------------\n",
      "Train loss (all, class, reg): 37.1898889378139 0.006895237650190081 180.37222098214286\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.1136435953776 0.16193333943684896 531.3879166666667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9120  --------------------------\n",
      "Train loss (all, class, reg): 37.17540357317243 0.015219048091343472 218.16066964285713\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.433575541178385 0.04375555674235026 546.67390625\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9130  --------------------------\n",
      "Train loss (all, class, reg): 37.274365125383646 0.07708571297781808 150.17529017857143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 43.12245819091797 0.08240000406901042 498.590625\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9140  --------------------------\n",
      "Train loss (all, class, reg): 37.09143936157226 0.05148571559361049 159.46284598214285\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.217274525960285 0.28188891092936197 432.34270833333335\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9150  --------------------------\n",
      "Train loss (all, class, reg): 37.14934029715402 0.008285714558192662 213.55111607142857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 43.09331197102865 0.12664443969726563 434.0421875\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9160  --------------------------\n",
      "Train loss (all, class, reg): 37.00099042619978 0.04155238015311105 171.91723214285713\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 43.273832168579105 0.06482222239176433 378.972265625\n",
      "Test accuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9170  --------------------------\n",
      "Train loss (all, class, reg): 37.06680787222726 0.012971429824829102 167.78286830357143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 42.78317082722982 0.05073333422342936 648.2757291666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9180  --------------------------\n",
      "Train loss (all, class, reg): 36.93250405447824 0.011628571919032505 212.7294419642857\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 42.66184366861979 0.4454888916015625 353.6265625\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9190  --------------------------\n",
      "Train loss (all, class, reg): 37.03199443272182 0.0047428570474897114 236.26879464285713\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 42.73713872273763 0.02697778065999349 432.30169270833335\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9200  --------------------------\n",
      "Train loss (all, class, reg): 36.94823782784598 0.18405713762555803 244.59113839285715\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 42.96733973185221 0.19964444478352864 439.98380208333333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9210  --------------------------\n",
      "Train loss (all, class, reg): 36.87361330304827 0.007647619247436523 240.57685267857144\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 42.991470184326175 0.1594222132364909 402.16348958333333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9220  --------------------------\n",
      "Train loss (all, class, reg): 36.989586661202566 0.0038571432658604213 208.9372767857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.584114176432294 0.1019777806599935 471.3084375\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  9230  --------------------------\n",
      "Train loss (all, class, reg): 36.9735688999721 0.005342857156481062 195.82734375\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.69649546305339 0.38873336791992186 463.84015625\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9240  --------------------------\n",
      "Train loss (all, class, reg): 36.81484941755022 0.00822857107434954 234.5661607142857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 43.22487782796224 0.1552666727701823 495.68916666666667\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9250  --------------------------\n",
      "Train loss (all, class, reg): 36.85352770124163 0.06841904776436943 147.29061383928573\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 43.21048278808594 0.11591110229492188 561.2022916666666\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9260  --------------------------\n",
      "Train loss (all, class, reg): 36.99818649291992 0.06991428920200893 183.18748883928572\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 42.85264490763346 0.06148888905843099 563.5861458333334\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9270  --------------------------\n",
      "Train loss (all, class, reg): 36.79656396048409 0.01911428724016462 314.5104017857143\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 43.17769226074219 0.29197779337565105 459.12484375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9280  --------------------------\n",
      "Train loss (all, class, reg): 36.84197217668806 0.0058476189204624725 206.43895089285715\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 42.636800079345704 0.12708889007568358 504.54333333333335\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9290  --------------------------\n",
      "Train loss (all, class, reg): 36.722838243756975 0.005780952998570034 243.24582589285714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.513738301595055 0.12731109619140624 470.33708333333334\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9300  --------------------------\n",
      "Train loss (all, class, reg): 36.824507925851 0.013199999673025948 211.09078125\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 43.17650136311849 0.43655558268229167 442.6991145833333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9310  --------------------------\n",
      "Train loss (all, class, reg): 36.80392756870815 0.010257142611912318 177.02081473214287\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.964343821207684 0.28159998575846357 406.81377604166664\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9320  --------------------------\n",
      "Train loss (all, class, reg): 36.723946315220424 0.07534285409109934 179.28716517857143\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 42.59637502034505 0.20346666971842448 374.98315104166664\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9330  --------------------------\n",
      "Train loss (all, class, reg): 36.75973022460938 0.1182285635811942 166.89311383928572\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.72424575805664 0.01744444529215495 406.9075\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9340  --------------------------\n",
      "Train loss (all, class, reg): 36.71835564749581 0.00803809574672154 207.15604910714285\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.913041534423826 0.10142222086588541 425.673359375\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9350  --------------------------\n",
      "Train loss (all, class, reg): 36.72371117728097 0.009866666793823243 249.52607142857144\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.530567016601566 0.17735555013020834 380.56471354166666\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9360  --------------------------\n",
      "Train loss (all, class, reg): 36.521441999162946 0.009142857960292272 179.45970982142856\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 42.466756693522136 0.03706666946411133 436.6554947916667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9370  --------------------------\n",
      "Train loss (all, class, reg): 36.689422977992464 0.005761905397687639 206.22504464285714\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 42.3281064860026 0.11286666870117187 448.50296875\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9380  --------------------------\n",
      "Train loss (all, class, reg): 36.67203920636858 0.011571429116385324 211.61176339285714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.05472020467123 0.06188889821370443 549.4596875\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9390  --------------------------\n",
      "Train loss (all, class, reg): 36.54712958199637 0.008390476363045829 207.973125\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 42.33089299519857 0.2644444783528646 570.4329166666666\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9400  --------------------------\n",
      "Train loss (all, class, reg): 36.54120077950614 0.07936190468924387 181.43466517857144\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 42.34779876708984 0.2571777852376302 433.8586197916667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9410  --------------------------\n",
      "Train loss (all, class, reg): 36.41620156424386 0.014971429279872349 198.78058035714287\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 42.32250213623047 0.2415777842203776 389.830234375\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9420  --------------------------\n",
      "Train loss (all, class, reg): 36.391686357770645 0.07747619083949497 217.3283705357143\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 42.246551005045575 0.31517776489257815 391.0732291666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9430  --------------------------\n",
      "Train loss (all, class, reg): 36.41827516828265 0.09760952540806361 182.44525669642857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.70729431152344 0.3467333221435547 380.8034895833333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9440  --------------------------\n",
      "Train loss (all, class, reg): 36.368258492606024 0.0745809555053711 171.62732142857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.476704661051436 0.1903333282470703 391.89674479166666\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9450  --------------------------\n",
      "Train loss (all, class, reg): 36.35126926967076 0.058990478515625 193.87886160714285\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 42.335856170654296 0.05015555699666341 511.71765625\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9460  --------------------------\n",
      "Train loss (all, class, reg): 36.36132827758789 0.05643810272216797 167.024296875\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 42.39007837931315 0.041377776463826496 473.83734375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9470  --------------------------\n",
      "Train loss (all, class, reg): 36.284267774309434 0.006380953107561384 196.08098214285715\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 42.36984024047852 0.02024444580078125 451.7835416666667\n",
      "Test accuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9480  --------------------------\n",
      "Train loss (all, class, reg): 36.27332026890346 0.0073428569521222795 218.92185267857144\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.347427419026694 0.11180000305175782 467.33760416666667\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  9490  --------------------------\n",
      "Train loss (all, class, reg): 36.17877816336495 0.012457143238612583 189.46629464285715\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.46536783854167 0.18426666259765626 475.96317708333333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9500  --------------------------\n",
      "Train loss (all, class, reg): 36.28066787719727 0.00939999989100865 192.07901785714284\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 42.30981608072916 0.26851109822591146 407.57200520833334\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9510  --------------------------\n",
      "Train loss (all, class, reg): 36.12142421177455 0.039285714285714285 197.83625\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 42.220563608805335 0.07364444732666016 532.7047395833333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9520  --------------------------\n",
      "Train loss (all, class, reg): 36.13015230451311 0.10057141985212054 156.8103125\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 42.17557434082031 0.08322222391764322 455.49927083333336\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9530  --------------------------\n",
      "Train loss (all, class, reg): 36.055652727399554 0.0075809519631522045 236.11875\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 42.14053095499674 0.3686222330729167 448.2444791666667\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9540  --------------------------\n",
      "Train loss (all, class, reg): 36.07730773925781 0.09862857273646763 206.31834821428572\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 41.871568044026695 0.07473333358764649 582.9016666666666\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9550  --------------------------\n",
      "Train loss (all, class, reg): 36.02460224696568 0.02076190403529576 201.53642857142856\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 42.61873850504557 0.21697776794433593 408.41703125\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9560  --------------------------\n",
      "Train loss (all, class, reg): 36.02437299455915 0.0170952388218471 203.4320982142857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 42.12979288736979 1.1284889729817709 589.72921875\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9570  --------------------------\n",
      "Train loss (all, class, reg): 36.02172908238002 0.07971429007393974 177.87466517857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 41.9259066772461 0.11613333384195963 492.70239583333336\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9580  --------------------------\n",
      "Train loss (all, class, reg): 35.95488344464983 0.009533333097185407 200.92354910714286\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 41.54253926595052 0.09964444478352864 455.94083333333333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9590  --------------------------\n",
      "Train loss (all, class, reg): 36.00409417288644 0.00658095223563058 196.16542410714285\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss (all, class, reg): 42.08743179321289 0.07200000762939453 628.9640625\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9600  --------------------------\n",
      "Train loss (all, class, reg): 35.982810908726286 0.07440952845982143 185.05887276785714\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 41.81780558268229 0.02348888874053955 497.4557291666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9610  --------------------------\n",
      "Train loss (all, class, reg): 35.838984789167135 0.011714286804199218 190.96171875\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 41.50443435668945 0.11080000559488933 409.83859375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9620  --------------------------\n",
      "Train loss (all, class, reg): 35.77785027640206 0.008790475981576102 203.37825892857143\n",
      "Train accuracy: 0.96\n",
      "Test loss (all, class, reg): 41.689261271158855 0.3341778055826823 444.0783333333333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9630  --------------------------\n",
      "Train loss (all, class, reg): 35.803436846051895 0.007219047546386719 206.09808035714286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 41.555780232747395 0.01504444440205892 438.6972916666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9640  --------------------------\n",
      "Train loss (all, class, reg): 35.8803829738072 0.025171429770333428 179.249765625\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 41.56119649251302 0.05819999694824219 529.8197916666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9650  --------------------------\n",
      "Train loss (all, class, reg): 35.6376481628418 0.006047619410923549 234.86120535714286\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 41.39085606892904 0.23006668090820312 351.306484375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9660  --------------------------\n",
      "Train loss (all, class, reg): 35.632469286237445 0.006495238712855748 205.20910714285714\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 41.477991383870446 0.18926666259765626 549.7011458333334\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9670  --------------------------\n",
      "Train loss (all, class, reg): 35.541932351248605 0.010866666521344865 151.07885044642856\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.337920379638675 0.2062000020345052 364.82653645833335\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9680  --------------------------\n",
      "Train loss (all, class, reg): 35.68362989153181 0.01079047611781529 260.6094196428571\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 41.50237223307292 0.13015555063883463 387.3334635416667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9690  --------------------------\n",
      "Train loss (all, class, reg): 35.70105510166713 0.028504764011928013 177.69693080357143\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss (all, class, reg): 41.74295160929362 0.0729111099243164 470.40197916666665\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9700  --------------------------\n",
      "Train loss (all, class, reg): 35.61796506609235 0.02959047589983259 193.87037946428572\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.43964848836263 0.30648890177408855 435.22955729166665\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9710  --------------------------\n",
      "Train loss (all, class, reg): 35.518125 0.005495238304138184 223.27136160714286\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss (all, class, reg): 41.37340555826823 0.15151111602783204 392.61182291666665\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9720  --------------------------\n",
      "Train loss (all, class, reg): 35.49003699166434 0.006723809242248535 155.40145089285716\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.39812815348307 0.08164443969726562 419.6859375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9730  --------------------------\n",
      "Train loss (all, class, reg): 35.40282817295619 0.07872380937848772 169.1822767857143\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 41.61505284627279 0.08677777608235678 496.566875\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9740  --------------------------\n",
      "Train loss (all, class, reg): 35.4033844430106 0.008876190185546876 236.35910714285714\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 41.251934661865235 0.2859333292643229 355.5090104166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9750  --------------------------\n",
      "Train loss (all, class, reg): 35.422706407819476 0.07939047677176339 189.4569419642857\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 41.2151377360026 0.0906666628519694 425.2672395833333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9760  --------------------------\n",
      "Train loss (all, class, reg): 35.311470271519255 0.005542857306344169 195.95955357142856\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 41.26574895222982 0.2963555653889974 416.6765625\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9770  --------------------------\n",
      "Train loss (all, class, reg): 35.342287870134626 0.00930476188659668 177.94196428571428\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.17325337727865 0.42393335978190105 552.0005208333333\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9780  --------------------------\n",
      "Train loss (all, class, reg): 35.426594805036274 0.06867619105747767 196.09825892857143\n",
      "Train accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (all, class, reg): 41.297496439615884 0.082244447072347 392.610234375\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9790  --------------------------\n",
      "Train loss (all, class, reg): 35.364001094273156 0.006466666630336217 194.93147321428572\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.29134928385417 0.2181111145019531 474.26505208333333\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  9800  --------------------------\n",
      "Train loss (all, class, reg): 35.35611866542271 0.00490476199558803 210.78029017857142\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 41.18975840250651 0.05604443868001302 491.9440625\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9810  --------------------------\n",
      "Train loss (all, class, reg): 35.35580206734794 0.019819049835205077 217.76127232142858\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 40.94630630493164 0.4072666676839193 473.85234375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9820  --------------------------\n",
      "Train loss (all, class, reg): 35.30661372593471 0.008009523664202009 173.118046875\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 41.10565292358398 0.025466667811075847 340.2077864583333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9830  --------------------------\n",
      "Train loss (all, class, reg): 35.19450387137277 0.06394284929547991 157.7242857142857\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.27983749389649 0.11288889567057292 486.4138541666667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9840  --------------------------\n",
      "Train loss (all, class, reg): 35.324018391200475 0.005695238113403321 173.73402901785715\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.421315561930335 0.12115557352701822 456.925\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9850  --------------------------\n",
      "Train loss (all, class, reg): 35.15565789358956 0.00636190482548305 177.127890625\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 41.422990214029944 0.04573333104451498 438.5584375\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9860  --------------------------\n",
      "Train loss (all, class, reg): 35.214795205252514 0.006733333723885672 215.61066964285715\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 40.94435145060221 0.3837333170572917 383.90151041666667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9870  --------------------------\n",
      "Train loss (all, class, reg): 35.11912733895438 0.005514285905020577 143.604609375\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 41.46092651367187 0.17157778422037762 560.7507291666667\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9880  --------------------------\n",
      "Train loss (all, class, reg): 35.2059470476423 0.014561905179704938 181.52659598214285\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.22612691243489 0.11746665954589844 553.64265625\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9890  --------------------------\n",
      "Train loss (all, class, reg): 34.970299050467354 0.010704761913844518 197.1183482142857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 40.916162109375 0.47482218424479167 403.946953125\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9900  --------------------------\n",
      "Train loss (all, class, reg): 34.9638289969308 0.006447619029453822 199.22714285714287\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss (all, class, reg): 41.27428380330404 0.11411112467447916 583.1065104166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9910  --------------------------\n",
      "Train loss (all, class, reg): 35.08432253156389 0.053142858232770644 159.9791294642857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 41.16654037475586 0.04888888676961263 412.101484375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9920  --------------------------\n",
      "Train loss (all, class, reg): 35.0366926574707 0.00468571424484253 184.10279017857144\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 40.92650924682617 0.3915111287434896 452.00427083333335\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9930  --------------------------\n",
      "Train loss (all, class, reg): 35.17501722063337 0.0071523809432983395 230.54535714285714\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 41.14938842773437 0.07853333791097006 573.63640625\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9940  --------------------------\n",
      "Train loss (all, class, reg): 34.96990465436663 0.014819047110421316 195.43109375\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.19302541097005 0.054355557759602866 449.89661458333336\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9950  --------------------------\n",
      "Train loss (all, class, reg): 35.11432580130441 0.008123809950692312 196.27685267857143\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss (all, class, reg): 40.7766683959961 0.32246668497721354 524.45140625\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9960  --------------------------\n",
      "Train loss (all, class, reg): 35.07563564845494 0.022780952453613282 169.64481026785714\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss (all, class, reg): 40.85957962036133 0.08764444351196289 444.4228125\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9970  --------------------------\n",
      "Train loss (all, class, reg): 35.0160266985212 0.012038096019199916 167.68378348214284\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss (all, class, reg): 41.1764306640625 0.055800005594889325 504.51765625\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9980  --------------------------\n",
      "Train loss (all, class, reg): 35.01442921229771 0.007266665867396763 203.63098214285714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss (all, class, reg): 40.97715916951498 0.049244445164998374 498.7277604166667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9990  --------------------------\n",
      "Train loss (all, class, reg): 35.07886710030692 0.0065238094329833985 230.27348214285715\n",
      "Train accuracy: 0.95\n",
      "Test loss (all, class, reg): 41.06115966796875 0.25102223714192706 550.0597916666667\n",
      "Test accuracy: 0.9\n",
      "Epoch:  10000  --------------------------\n",
      "Train loss (all, class, reg): 34.963679613385885 0.004238095283508301 190.95816964285714\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss (all, class, reg): 41.499141184488934 0.33931111653645835 440.9167708333333\n",
      "Test accuracy: 0.9033333333333333\n"
     ]
    }
   ],
   "source": [
    "train_total_losses=[]\n",
    "train_class_losses=[]\n",
    "train_regres_losses=[]\n",
    "\n",
    "test_total_losses=[]\n",
    "test_class_losses=[]\n",
    "test_regres_losses=[]\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "alpha = 1\n",
    "beta = 0.001\n",
    "for epoch in range(10001):\n",
    "    net2.train()\n",
    "    correct = 0\n",
    "    loss_train = 0\n",
    "    loss_class = 0\n",
    "    loss_reg = 0\n",
    "    for i, (tact_i, tact_b, target, label) in enumerate(train_loader):\n",
    "        \n",
    "        tact_i = tact_i.to(device)\n",
    "        tact_b = tact_b.to(device)\n",
    "        target = target.to(device)\n",
    "        tact_i = net.get_spike(tact_i)\n",
    "        tact_b = net.get_spike(tact_b)\n",
    "        \n",
    "        # impute icub\n",
    "        tact_new = torch.zeros((tact_i.shape[0],tact_i.shape[1],1,1,tact_i.shape[-1]*2)).to(device)\n",
    "        tact_new[...,::2]  = tact_i\n",
    "        tact_i = tact_new\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            _, _, rep, _ = net.forward(tact_b)\n",
    "            \n",
    "        output, out_input = net2.forward(tact_i)\n",
    "        \n",
    "        correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "        loss_class = error.numSpikes(output, target)\n",
    "        \n",
    "        loss_reg = error2.spikeTime(out_input, rep)\n",
    "        \n",
    "        loss = alpha*loss_class + beta*loss_reg\n",
    "        \n",
    "        loss_train += loss.item()\n",
    "        loss_class += alpha*loss_class.item()\n",
    "        loss_reg += beta*loss_reg.item()\n",
    "        \n",
    "        optimizer2.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "                \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: ', epoch, ' --------------------------')\n",
    "        print('Train loss (all, class, reg):', \n",
    "              loss_train/len(train_dataset),\n",
    "              loss_class.item()/len(train_dataset),\n",
    "              loss_reg.item()/len(train_dataset))\n",
    "        print('Train accuracy:', correct/len(train_dataset))\n",
    "    train_accs.append(correct/len(train_dataset))\n",
    "    train_total_losses.append(loss_train/len(train_dataset))\n",
    "    train_class_losses.append(loss_class/len(train_dataset))\n",
    "    train_regres_losses.append(loss_reg/len(train_dataset))\n",
    "        \n",
    "    net2.eval()\n",
    "    correct = 0\n",
    "    loss_test = 0\n",
    "    loss_class = 0\n",
    "    loss_reg = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (tact_i, tact_b, target, label) in enumerate(test_loader):\n",
    "\n",
    "            tact_i = tact_i.to(device)\n",
    "            tact_b = tact_b.to(device)\n",
    "            target = target.to(device)\n",
    "            tact_i = net.get_spike(tact_i)\n",
    "            tact_b = net.get_spike(tact_b)\n",
    "\n",
    "            # impute icub\n",
    "            tact_new = torch.zeros((tact_i.shape[0],tact_i.shape[1],1,1,tact_i.shape[-1]*2)).to(device)\n",
    "            tact_new[...,::2]  = tact_i\n",
    "            tact_i = tact_new\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _, _, rep, _ = net.forward(tact_b)\n",
    "\n",
    "            output, out_input = net2.forward(tact_i)\n",
    "            \n",
    "        \n",
    "            correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "            loss_class = error.numSpikes(output, target)\n",
    "\n",
    "            loss_reg = error2.spikeTime(out_input, rep)\n",
    "\n",
    "            loss = alpha*loss_class + beta*loss_reg\n",
    "\n",
    "            loss_test += loss.item()\n",
    "            loss_class += alpha*loss_class.item()\n",
    "            loss_reg += beta*loss_reg.item()\n",
    "            \n",
    "#     if epoch%10 == 0:\n",
    "#         print('Test loss:', loss_test/len(test_dataset))\n",
    "#         print('Test accuracy:', correct/len(test_dataset))\n",
    "#     test_accs.append(correct/len(test_dataset))\n",
    "#     test_losses.append(loss_test/len(test_dataset))\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Test loss (all, class, reg):', \n",
    "              loss_test/len(test_dataset),\n",
    "              loss_class.item()/len(test_dataset),\n",
    "              loss_reg.item()/len(test_dataset))\n",
    "        print('Test accuracy:', correct/len(test_dataset))\n",
    "    test_accs.append(correct/len(test_dataset))\n",
    "    test_total_losses.append(loss_test/len(test_dataset))\n",
    "    test_class_losses.append(loss_class/len(test_dataset))\n",
    "    test_regres_losses.append(loss_reg/len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9133333333333333"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test_accs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
