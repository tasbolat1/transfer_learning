{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "CURRENT_TEST_DIR = os.getcwd()\n",
    "sys.path.append(CURRENT_TEST_DIR + \"/../../../slayerPytorch/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f538c7fc6d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import slayerSNN as snn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dtw import dtw, accelerated_dtw\n",
    "from numpy.linalg import norm\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = np.load('auxiliaries/electrodes.npy')\n",
    "X = torch.load('../BioTac_Icub_data/Bio_all.pt').permute(0,2,1).numpy()\n",
    "X_i = torch.load('../BioTac_Icub_data/ICUB_all.pt').reshape([1000, 60, 75]).numpy()\n",
    "#Y = np.load('auxiliaries/labels.npy')\n",
    "Y = np.load('../BioTac_Icub_data/ICUB_all_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 19, 150), (1000,), (1000, 60, 75))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape, X_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohe(_Y):\n",
    "    target_class = np.zeros([_Y.shape[0], 20])\n",
    "    for i in range(target_class.shape[0]):\n",
    "        target_class[i, int(_Y[i])] = 1\n",
    "    return target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], 1, 1, X.shape[-1])\n",
    "X_i = X_i.reshape(X_i.shape[0], X_i.shape[1], 1, 1, X_i.shape[-1])\n",
    "indices = np.arange(X.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, ind_train, ind_test = train_test_split(X, Y, indices, test_size=0.30, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([700, 19, 1, 1, 150]),\n",
       " torch.Size([700]),\n",
       " torch.Size([700, 20, 1, 1, 1]),\n",
       " torch.Size([700, 60, 1, 1, 75]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "target_class_train = torch.FloatTensor(get_ohe(y_train).reshape(-1, 20, 1, 1, 1))\n",
    "    \n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "target_class_test= torch.FloatTensor(get_ohe(y_test).reshape(-1, 20, 1, 1, 1))\n",
    "\n",
    "X_train_i= torch.FloatTensor(X_i[ind_train])\n",
    "X_test_i = torch.FloatTensor(X_i[ind_test])\n",
    "\n",
    "X_train.shape, y_train.shape, target_class_train.shape, X_train_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"neuron\": {\n",
    "        \"type\": \"SRMALPHA\",\n",
    "        \"theta\": 5, # 10\n",
    "        \"tauSr\": 10.0,\n",
    "        \"tauRef\": 2.0,\n",
    "        \"scaleRef\": 2,\n",
    "        \"tauRho\": 1,\n",
    "        \"scaleRho\": 1,\n",
    "    },\n",
    "    \"simulation\": {\"Ts\": 1.0, \"tSample\": 150, \"nSample\": 1},\n",
    "    \"training\": {\n",
    "        \"error\": {\n",
    "            \"type\": \"NumSpikes\",  # \"NumSpikes\" or \"ProbSpikes\"\n",
    "            \"probSlidingWin\": 20,  # only valid for ProbSpikes\n",
    "            \"tgtSpikeRegion\": {  # valid for NumSpikes and ProbSpikes\n",
    "                \"start\": 0,\n",
    "                \"stop\": 150,\n",
    "            },\n",
    "            \"tgtSpikeCount\": {True: 120, False: 20},\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "params2 = {\n",
    "    \"neuron\": {\n",
    "        \"type\": \"SRMALPHA\",\n",
    "        \"theta\": 5, # 10\n",
    "        \"tauSr\": 10.0,\n",
    "        \"tauRef\": 2.0,\n",
    "        \"scaleRef\": 2,\n",
    "        \"tauRho\": 1,\n",
    "        \"scaleRho\": 1,\n",
    "    },\n",
    "    \"simulation\": {\"Ts\": 1.0, \"tSample\": 150, \"nSample\": 1},\n",
    "    \"training\": {\n",
    "        \"error\": {\n",
    "            \"type\": \"SpikeTime\",  # \"NumSpikes\" or \"ProbSpikes\"\n",
    "            \"probSlidingWin\": 20,  # only valid for ProbSpikes\n",
    "            \"tgtSpikeRegion\": {  # valid for NumSpikes and ProbSpikes\n",
    "                \"start\": 0,\n",
    "                \"stop\": 150,\n",
    "            },\n",
    "            \"tgtSpikeCount\": {True: 120, False: 20},\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train_i, X_train, target_class_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True,batch_size=8)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test_i, X_test, target_class_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMLP(torch.nn.Module):\n",
    "    def __init__(self, params, input_size, hidden_size, output_size):\n",
    "        super(SimpleMLP, self).__init__()\n",
    "        self.slayer = snn.layer(params[\"neuron\"], params[\"simulation\"])\n",
    "        self.fc1 = self.slayer.dense(input_size, hidden_size)\n",
    "        self.fc2 = self.slayer.dense(hidden_size, output_size) # classifier\n",
    "    \n",
    "    def forward(self, spike_input):\n",
    "        spike_1 = self.slayer.spike(self.slayer.psp(self.fc1(spike_input)))\n",
    "        spike_2 = self.slayer.spike(self.slayer.psp(self.fc2(spike_1)))        \n",
    "        return spike_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(AE, self).__init__()\n",
    "        self.slayer = snn.layer(params[\"neuron\"], params[\"simulation\"])\n",
    "        \n",
    "        self.encoder_i = SimpleMLP(params, 60, 50, 40)\n",
    "        self.encoder_b = SimpleMLP(params, 19, 50, 40)\n",
    "        \n",
    "        self.fc_classr_i = self.slayer.dense(40, 20)\n",
    "        self.fc_classr_b = self.slayer.dense(40, 20)\n",
    "        \n",
    "        self.fc = self.slayer.dense(80, 40)\n",
    "        \n",
    "        self.decoder_i = SimpleMLP(params, 40, 30, 60)\n",
    "        self.decoder_b = SimpleMLP(params, 40, 30, 19)\n",
    "        \n",
    "    def get_spike(self, inp):\n",
    "        return self.slayer.spike(inp)\n",
    "    \n",
    "    def forward(self, spike_input_i, spike_input_b):\n",
    "\n",
    "        # encoder\n",
    "        encoded_i = self.encoder_i(spike_input_i)\n",
    "        encoded_b = self.encoder_b(spike_input_b)\n",
    "        \n",
    "        # classifier\n",
    "        output_class_i = self.slayer.spike(self.slayer.psp(self.fc_classr_i(encoded_i)))\n",
    "        output_class_b = self.slayer.spike(self.slayer.psp(self.fc_classr_b(encoded_b)))\n",
    "        \n",
    "        # concat\n",
    "        merged = torch.cat([encoded_i, encoded_b], dim=1)\n",
    "        \n",
    "        # representation\n",
    "        rep = self.slayer.spike(self.slayer.psp(self.fc(merged)))\n",
    "                        \n",
    "        # decoder\n",
    "        decoded_i = self.decoder_i(rep)\n",
    "        decoded_b = self.decoder_b(rep)\n",
    "        \n",
    "        return output_class_i, output_class_b, rep, decoded_i, decoded_b, encoded_i, encoded_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "net = AE(params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = snn.loss(params).to(device)\n",
    "error2 = snn.loss(params2).to(device)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 593.8391195242746 0.35837145124162945 0.3263142830984933 0.10605505580357143 0.27018375\n",
      "Train accuracy(i,b): 0.04285714285714286 0.03571428571428571\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 355.34399251302085 0.7591444905598959 0.7795000203450521 0.13735908854166667 0.71580984375\n",
      "Test accuracy(i,b): 0.06666666666666667 0.06333333333333334\n",
      "Epoch:  10  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 404.23412946428573 0.15411904471261162 0.16864761352539062 0.059969017857142856 0.07389877232142857\n",
      "Train accuracy(i,b): 0.49142857142857144 0.40714285714285714\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 165.97546936035155 0.5031333414713541 0.339522221883138 0.11712539062499999 0.2192125\n",
      "Test accuracy(i,b): 0.5266666666666666 0.4266666666666667\n",
      "Epoch:  20  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 364.6512848772321 0.13380476815359932 0.10910476684570312 0.030571908482142855 0.06834977678571429\n",
      "Train accuracy(i,b): 0.6457142857142857 0.5785714285714286\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 129.78448618570962 0.31557779947916664 0.32813334147135415 0.05697981119791667 0.15028154947916667\n",
      "Test accuracy(i,b): 0.6233333333333333 0.5833333333333334\n",
      "Epoch:  30  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 327.23576695033483 0.09225714547293527 0.13431429181780133 0.028846294642857144 0.04698301897321429\n",
      "Train accuracy(i,b): 0.69 0.6814285714285714\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 113.27130696614583 0.5303888956705729 0.39339996337890626 0.04024094401041667 0.10500684244791667\n",
      "Test accuracy(i,b): 0.69 0.6966666666666667\n",
      "Epoch:  40  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 303.8050519670759 0.10741904122488839 0.1158857182094029 0.023487354910714287 0.05342483258928571\n",
      "Train accuracy(i,b): 0.7528571428571429 0.7485714285714286\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 103.98641387939453 0.1536444346110026 0.25933334350585935 0.07214593098958333 0.0842066015625\n",
      "Test accuracy(i,b): 0.6933333333333334 0.7433333333333333\n",
      "Epoch:  50  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 288.91970598493305 0.09133809770856585 0.08964285714285715 0.020917858537946428 0.03699136439732143\n",
      "Train accuracy(i,b): 0.7828571428571428 0.8157142857142857\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 96.73529764811198 0.21960001627604167 0.29502220153808595 0.04516428385416667 0.08108223958333333\n",
      "Test accuracy(i,b): 0.72 0.82\n",
      "Epoch:  60  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 276.86677891322546 0.06903333391462053 0.0775 0.021364450334821428 0.04257373883928572\n",
      "Train accuracy(i,b): 0.7957142857142857 0.8342857142857143\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 90.95491180419921 0.3307666524251302 0.32673332214355466 0.039244423828125 0.10031555338541667\n",
      "Test accuracy(i,b): 0.7133333333333334 0.8266666666666667\n",
      "Epoch:  70  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 264.53485508510045 0.08870000566755022 0.0346952383858817 0.017679539620535714 0.03883331194196429\n",
      "Train accuracy(i,b): 0.8042857142857143 0.86\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 86.67472686767579 0.16186665852864585 0.27225555419921876 0.04335634765625 0.0689799609375\n",
      "Test accuracy(i,b): 0.71 0.8166666666666667\n",
      "Epoch:  80  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 253.69305140904018 0.11146666390555246 0.058557139805385044 0.012933013392857143 0.03865872767857143\n",
      "Train accuracy(i,b): 0.8128571428571428 0.8671428571428571\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 82.65287785847981 0.056800003051757815 0.20269999186197918 0.03588658854166667 0.08797912760416668\n",
      "Test accuracy(i,b): 0.7133333333333334 0.8333333333333334\n",
      "Epoch:  90  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 245.09307878766742 0.06208095005580357 0.0716857201712472 0.019922195870535713 0.028352265624999998\n",
      "Train accuracy(i,b): 0.8214285714285714 0.8728571428571429\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 79.00428334554036 0.16363332112630208 0.20567778269449868 0.03560029947916667 0.07458201171875001\n",
      "Test accuracy(i,b): 0.74 0.8733333333333333\n",
      "Epoch:  100  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 238.55576651436942 0.06975238255092076 0.0714999989100865 0.016011693638392856 0.036136607142857144\n",
      "Train accuracy(i,b): 0.8342857142857143 0.8942857142857142\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 77.6678096516927 0.04236666361490885 0.13484443664550783 0.02726642903645833 0.07656845052083333\n",
      "Test accuracy(i,b): 0.7466666666666667 0.84\n",
      "Epoch:  110  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 231.85738473074778 0.06549999782017299 0.07555237906319755 0.01918512416294643 0.03665214006696429\n",
      "Train accuracy(i,b): 0.8428571428571429 0.8985714285714286\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 75.121484375 0.16180000305175782 0.18101111094156902 0.03621713541666667 0.08421182291666666\n",
      "Test accuracy(i,b): 0.7433333333333333 0.87\n",
      "Epoch:  120  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 226.28883239746094 0.05325714111328125 0.11028570992606027 0.013416361607142857 0.022150647321428574\n",
      "Train accuracy(i,b): 0.84 0.91\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 73.31313741048177 0.12763333638509114 0.12318889617919922 0.037590016276041666 0.08845901692708334\n",
      "Test accuracy(i,b): 0.74 0.87\n",
      "Epoch:  130  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 220.34384687151228 0.0713904789515904 0.10412380763462611 0.01566650809151786 0.04690592633928571\n",
      "Train accuracy(i,b): 0.8471428571428572 0.9214285714285714\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 71.23312662760416 0.18732223510742188 0.20927777608235676 0.031787128906249996 0.11215533854166668\n",
      "Test accuracy(i,b): 0.7466666666666667 0.8866666666666667\n",
      "Epoch:  140  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 214.60156014578683 0.09714285714285714 0.033842857905796594 0.01563347935267857 0.03344583147321429\n",
      "Train accuracy(i,b): 0.8414285714285714 0.9242857142857143\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 69.40410603841146 0.2351111094156901 0.09091110865275065 0.028230345052083338 0.069873984375\n",
      "Test accuracy(i,b): 0.7466666666666667 0.8866666666666667\n",
      "Epoch:  150  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 209.19125470842633 0.0214238098689488 0.0684380885532924 0.01634218191964286 0.025659983258928574\n",
      "Train accuracy(i,b): 0.85 0.9214285714285714\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 67.90333048502605 0.18149998982747395 0.07928888956705729 0.02393171875 0.07929133463541667\n",
      "Test accuracy(i,b): 0.74 0.8833333333333333\n",
      "Epoch:  160  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 205.14064557756697 0.16719048636300224 0.0244952392578125 0.010496711774553573 0.029835574776785712\n",
      "Train accuracy(i,b): 0.8542857142857143 0.9214285714285714\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 66.79270060221354 0.41317779541015626 0.05063333511352539 0.024768857421875002 0.07339072265625\n",
      "Test accuracy(i,b): 0.7566666666666667 0.8766666666666667\n",
      "Epoch:  170  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 200.97982125418528 0.05195714678083147 0.043909525190080914 0.01709457170758929 0.020065597098214285\n",
      "Train accuracy(i,b): 0.8557142857142858 0.92\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 66.25062754313151 0.20459999084472658 0.09911111195882162 0.037689837239583336 0.08203294270833333\n",
      "Test accuracy(i,b): 0.7566666666666667 0.88\n",
      "Epoch:  180  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 196.6703893171038 0.06437142508370536 0.07758572169712612 0.017703444475446427 0.027725518973214288\n",
      "Train accuracy(i,b): 0.85 0.93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 64.49157368977865 0.2871111043294271 0.17764444986979167 0.03648612630208334 0.07516000651041667\n",
      "Test accuracy(i,b): 0.76 0.8966666666666666\n",
      "Epoch:  190  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 191.1048819405692 0.027980951581682477 0.046628570556640624 0.017517564174107145 0.030761757812500002\n",
      "Train accuracy(i,b): 0.8514285714285714 0.9271428571428572\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 64.27765970865886 0.16686667124430338 0.12174443562825521 0.034906067708333335 0.05018543619791667\n",
      "Test accuracy(i,b): 0.7733333333333333 0.8966666666666666\n",
      "Epoch:  200  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 185.7561972481864 0.03565237862723214 0.08914285387311663 0.018566473214285714 0.022872505580357142\n",
      "Train accuracy(i,b): 0.8657142857142858 0.93\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 62.94909301757812 0.11306666056315104 0.12730000813802084 0.030423092447916668 0.054548561197916665\n",
      "Test accuracy(i,b): 0.7733333333333333 0.8666666666666667\n",
      "Epoch:  210  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 181.57008884974888 0.025299998692103795 0.03403809683663504 0.013278680245535714 0.031800273437500005\n",
      "Train accuracy(i,b): 0.8642857142857143 0.9328571428571428\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 61.81363749186198 0.25334442138671875 0.1546999994913737 0.03435561848958334 0.05594348958333333\n",
      "Test accuracy(i,b): 0.7766666666666666 0.9033333333333333\n",
      "Epoch:  220  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 177.3512735421317 0.03874285561697824 0.07861904689243862 0.013867424665178572 0.023706297433035713\n",
      "Train accuracy(i,b): 0.87 0.9371428571428572\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 61.40570246378581 0.21258889516194662 0.10714444478352865 0.03126263346354166 0.04825449869791667\n",
      "Test accuracy(i,b): 0.7733333333333333 0.8766666666666667\n",
      "Epoch:  230  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 173.0824768066406 0.10670952933175223 0.04643809182303293 0.01034196010044643 0.023313526785714283\n",
      "Train accuracy(i,b): 0.8657142857142858 0.94\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 60.47146687825521 0.08454444885253906 0.07657777786254882 0.029222643229166668 0.0591071875\n",
      "Test accuracy(i,b): 0.78 0.9033333333333333\n",
      "Epoch:  240  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 169.5961779785156 0.03296666281563895 0.03372381210327149 0.014023956473214284 0.029179263392857143\n",
      "Train accuracy(i,b): 0.8771428571428571 0.9442857142857143\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 59.93886932373047 0.18083333333333335 0.34704442342122394 0.03730469401041667 0.09151479817708334\n",
      "Test accuracy(i,b): 0.7833333333333333 0.9066666666666666\n",
      "Epoch:  250  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 166.9383078438895 0.0533047594342913 0.020038095201764788 0.014674220145089286 0.017773166852678574\n",
      "Train accuracy(i,b): 0.8685714285714285 0.9342857142857143\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 59.18521443684896 0.3946777852376302 0.1088888931274414 0.03803291015625 0.075673515625\n",
      "Test accuracy(i,b): 0.7933333333333333 0.89\n",
      "Epoch:  260  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 163.6892933000837 0.013647618974958147 0.05781905038016183 0.010614298270089285 0.023257407924107142\n",
      "Train accuracy(i,b): 0.8742857142857143 0.9414285714285714\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 58.286841278076174 0.10054443995157877 0.08027777353922526 0.03099025390625 0.049518782552083335\n",
      "Test accuracy(i,b): 0.7933333333333333 0.8833333333333333\n",
      "Epoch:  270  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 160.703921421596 0.06715238298688617 0.060138092041015626 0.015008164062500001 0.03194835379464286\n",
      "Train accuracy(i,b): 0.8785714285714286 0.9457142857142857\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 57.96571634928385 0.1828333536783854 0.16815556844075522 0.026094501953124998 0.051525201822916665\n",
      "Test accuracy(i,b): 0.79 0.9133333333333333\n",
      "Epoch:  280  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 157.53352966308594 0.032957142421177456 0.08928571428571429 0.009669386160714286 0.026567421875000004\n",
      "Train accuracy(i,b): 0.8785714285714286 0.9442857142857143\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 57.928321533203125 0.28873331705729166 0.10714444478352865 0.040534833984375 0.05556329427083334\n",
      "Test accuracy(i,b): 0.7933333333333333 0.9133333333333333\n",
      "Epoch:  290  --------------------------\n",
      "Train loss (all, class_i, class_b, icub_reg, bio_reg): 155.42560084751673 0.04615713936941964 0.022604762486049108 0.008677685546875 0.023181397879464286\n",
      "Train accuracy(i,b): 0.88 0.9414285714285714\n",
      "Test loss (all, class_i, class_b, icub_reg, bio_reg): 56.53257446289062 0.24476664225260417 0.16900000254313152 0.02576073893229167 0.05327831705729167\n",
      "Test accuracy(i,b): 0.7833333333333333 0.9233333333333333\n"
     ]
    }
   ],
   "source": [
    "train_total_losses=[]\n",
    "train_class_losses_i=[]\n",
    "train_class_losses_b=[]\n",
    "train_regres_losses_i=[]\n",
    "train_regres_losses_b=[]\n",
    "\n",
    "test_total_losses=[]\n",
    "test_class_losses_i=[]\n",
    "test_class_losses_b=[]\n",
    "test_regres_losses_i=[]\n",
    "test_regres_losses_b=[]\n",
    "\n",
    "train_accs_i = []\n",
    "train_accs_b = []\n",
    "\n",
    "test_accs_i = []\n",
    "test_accs_b = []\n",
    "\n",
    "alpha1 = alpha2 = 1\n",
    "beta1 = beta2 = 0.001\n",
    "gamma = 0.001\n",
    "for epoch in range(601):\n",
    "    net.train()\n",
    "    correct_i = 0\n",
    "    correct_b = 0\n",
    "    loss_train = 0\n",
    "    loss_train = 0\n",
    "    loss_class_i = 0\n",
    "    loss_class_b = 0\n",
    "    loss_reg_i = 0\n",
    "    loss_reg_b = 0\n",
    "    for i, (tact_i, tact_b, target, label) in enumerate(train_loader):\n",
    "        \n",
    "        # prepare input data\n",
    "        target = target.to(device)\n",
    "        tact_i = tact_i.to(device)\n",
    "        tact_b = tact_b.to(device)\n",
    "        \n",
    "        tact_i = net.get_spike(tact_i)\n",
    "        tact_b = net.get_spike(tact_b)\n",
    "        \n",
    "        # impute icub\n",
    "        tact_new = torch.zeros((tact_i.shape[0],tact_i.shape[1],1,1,tact_i.shape[-1]*2)).to(device)\n",
    "        tact_new[...,::2]  = tact_i\n",
    "        tact_i = tact_new\n",
    "        \n",
    "        # forward pass\n",
    "        output_i, output_b, _, out_i, out_b ,enc_i, enc_d = net.forward(tact_i, tact_b)\n",
    "                \n",
    "        # loss\n",
    "        correct_i += torch.sum(snn.predict.getClass(output_i) == label).data.item()\n",
    "        correct_b += torch.sum(snn.predict.getClass(output_b) == label).data.item()\n",
    "        \n",
    "        loss_sim = error2.spikeTime(enc_i, enc_d)\n",
    "        \n",
    "        loss_class_i = error.numSpikes(output_i, target)\n",
    "        loss_class_b = error.numSpikes(output_b, target)\n",
    "        \n",
    "        loss_reg_i = error2.spikeTime(out_i, tact_i)\n",
    "        loss_reg_b = error2.spikeTime(out_b, tact_b)\n",
    "        \n",
    "        loss = alpha1*loss_class_i + alpha2*loss_class_b + beta1*loss_reg_i + beta2*loss_reg_b + gamma*loss_sim\n",
    "        \n",
    "        loss_train += loss.item()\n",
    "        loss_class_i = alpha1*loss_class_i.item()\n",
    "        loss_class_b = alpha2*loss_class_b.item()\n",
    "        loss_reg_i = beta1*loss_reg_i.item()\n",
    "        loss_reg_b = beta2*loss_reg_b.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: ', epoch, ' --------------------------')\n",
    "        print('Train loss (all, class_i, class_b, icub_reg, bio_reg):', \n",
    "              loss_train/len(train_dataset),\n",
    "              loss_class_i/len(train_dataset),\n",
    "              loss_class_b/len(train_dataset),\n",
    "              loss_reg_i/len(train_dataset),\n",
    "              loss_reg_b/len(train_dataset))\n",
    "        print('Train accuracy(i,b):', correct_i/len(train_dataset), \n",
    "                  correct_b/len(train_dataset))\n",
    "    train_accs_i.append(correct_i/len(train_dataset))\n",
    "    train_accs_b.append(correct_b/len(train_dataset))\n",
    "    train_total_losses.append(loss_train/len(train_dataset))\n",
    "    train_class_losses_i.append(loss_class_i/len(train_dataset))\n",
    "    train_class_losses_b.append(loss_class_b/len(train_dataset))\n",
    "    train_regres_losses_i.append(loss_reg_i/len(train_dataset))\n",
    "    train_regres_losses_b.append(loss_reg_b/len(train_dataset))\n",
    "        \n",
    "    net.eval()\n",
    "    correct_i = 0\n",
    "    correct_b = 0\n",
    "    loss_test = 0\n",
    "    loss_class_i = 0\n",
    "    loss_class_b = 0\n",
    "    loss_reg_i = 0\n",
    "    loss_reg_b = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (tact_i,tact_b, target, label) in enumerate(test_loader):\n",
    "\n",
    "            # prepare input data\n",
    "            target = target.to(device)\n",
    "            tact_i = tact_i.to(device)\n",
    "            tact_b = tact_b.to(device)\n",
    "\n",
    "            tact_i = net.get_spike(tact_i)\n",
    "            tact_b = net.get_spike(tact_b)\n",
    "\n",
    "            # impute icub\n",
    "            tact_new = torch.zeros((tact_i.shape[0],tact_i.shape[1],1,1,tact_i.shape[-1]*2)).to(device)\n",
    "            tact_new[...,::2]  = tact_i\n",
    "            tact_i = tact_new\n",
    "\n",
    "            # forward pass\n",
    "            output_i, output_b, _, out_i, out_b ,enc_i, enc_d  = net.forward(tact_i, tact_b)\n",
    "\n",
    "            # loss\n",
    "            correct_i += torch.sum(snn.predict.getClass(output_i) == label).data.item()\n",
    "            correct_b += torch.sum(snn.predict.getClass(output_b) == label).data.item()\n",
    "            loss_class_i = error.numSpikes(output_i, target)\n",
    "            loss_class_b = error.numSpikes(output_b, target)\n",
    "\n",
    "            loss_reg_i = error2.spikeTime(out_i, tact_i)\n",
    "            loss_reg_b = error2.spikeTime(out_b, tact_b)\n",
    "\n",
    "            loss = alpha1*loss_class_i + alpha2*loss_class_b + beta1*loss_reg_i + beta2*loss_reg_b\n",
    "\n",
    "            loss_test += loss.item()\n",
    "            loss_class_i = alpha1*loss_class_i.item()\n",
    "            loss_class_b = alpha2*loss_class_b.item()\n",
    "            loss_reg_i = beta1*loss_reg_i.item()\n",
    "            loss_reg_b = beta2*loss_reg_b.item()\n",
    "\n",
    "            loss_test += loss.item()\n",
    "    \n",
    "    if epoch%10 == 0:\n",
    "        print('Test loss (all, class_i, class_b, icub_reg, bio_reg):', \n",
    "              loss_test/len(test_dataset),\n",
    "              loss_class_i/len(test_dataset),\n",
    "              loss_class_b/len(test_dataset),\n",
    "              loss_reg_i/len(test_dataset),\n",
    "              loss_reg_b/len(test_dataset))\n",
    "        print('Test accuracy(i,b):', correct_i/len(test_dataset), \n",
    "                  correct_b/len(test_dataset))\n",
    "    test_accs_i.append(correct_i/len(test_dataset))\n",
    "    test_accs_b.append(correct_b/len(test_dataset))\n",
    "    test_total_losses.append(loss_test/len(test_dataset))\n",
    "    test_class_losses_i.append(loss_class_i/len(test_dataset))\n",
    "    test_class_losses_b.append(loss_class_b/len(test_dataset))\n",
    "    test_regres_losses_i.append(loss_reg_i/len(test_dataset))\n",
    "    test_regres_losses_b.append(loss_reg_b/len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(15,7))\n",
    "\n",
    "ax[0].plot(train_total_losses, 'b')\n",
    "ax[0].plot(500*np.array(train_class_losses_i), 'r')\n",
    "ax[0].plot(500*np.array(train_regres_losses_i), 'g')\n",
    "ax[0].plot(500*np.array(train_regres_losses_b), 'c')\n",
    "\n",
    "# ax[0].plot(test_losses)\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "\n",
    "ax[1].plot(train_accs_i)\n",
    "ax[1].plot(test_accs_i)\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend(['Train', 'Test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(test_accs_i), np.max(test_accs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(train_accs_i), np.max(train_accs_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "big_list = []\n",
    "label_list=[]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (tact_i,tact_b, target, label) in enumerate(test_loader):\n",
    "\n",
    "        # prepare input data\n",
    "        target = target.to(device)\n",
    "        tact_i = tact_i.to(device)\n",
    "        tact_b = tact_b.to(device)\n",
    "\n",
    "        tact_i = net.get_spike(tact_i)\n",
    "        tact_b = net.get_spike(tact_b)\n",
    "\n",
    "        # impute icub\n",
    "        tact_new = torch.zeros((tact_i.shape[0],tact_i.shape[1],1,1,tact_i.shape[-1]*2)).to(device)\n",
    "        tact_new[...,::2]  = tact_i\n",
    "        tact_i = tact_new\n",
    "\n",
    "        # forward pass\n",
    "        _, _, rep, _, _ = net.forward(tact_i, tact_b)\n",
    "\n",
    "        big_list.append(rep)\n",
    "        label_list.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_representation = torch.cat(big_list,0)\n",
    "test_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all = torch.cat(label_list, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all = label_all.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dist_mat = torch.zeros([300,300])\n",
    "for i in range(300):\n",
    "    for j in range(300):\n",
    "        if i == j:\n",
    "            dist_mat[i, j] = 0.0\n",
    "        else:\n",
    "            dist_mat[i,j] = error2.spikeTime(test_representation[i], test_representation[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_mat = dist_mat.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "X_embedded = TSNE(n_components=2,perplexity=20, metric='precomputed').fit_transform(dist_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_embedded[:, 0], X_embedded[:, 1], c=label_all, cmap=plt.cm.tab10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
