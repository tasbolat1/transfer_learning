{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os,sys\n",
    "CURRENT_TEST_DIR = os.getcwd()\n",
    "sys.path.append(CURRENT_TEST_DIR + \"/../new_iteration/\")\n",
    "import pickle\n",
    "import argparse\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "from vrae.vrae import VRAEC\n",
    "from vrae.utils import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data as data2\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datetime import datetime\n",
    "from tas_utils_bs import get_trainValLoader, get_testLoader\n",
    "import plotly\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa4995d66d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set hyper params\n",
    "num_class = 20\n",
    "sequence_length_B = 400\n",
    "sequence_length_I = 75\n",
    "number_of_features_B = 19\n",
    "number_of_features_I = 60\n",
    "shuffle = True\n",
    "hidden_size = 90\n",
    "hidden_layer_depth = 1\n",
    "latent_length = 40\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "n_epochs = 100\n",
    "dropout_rate = 0.2\n",
    "cuda = True # options: True, False\n",
    "print_every=30\n",
    "clip = True # options: True, False\n",
    "max_grad_norm=5\n",
    "header_B = None\n",
    "header_I = \"CNN\"\n",
    "\n",
    "w_r = 0.0001\n",
    "w_k = 1\n",
    "w_c = 1\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_dir = '../../new_data_folder/'\n",
    "kfold_number = 0\n",
    "\n",
    "logDir = 'models_and_stat/'\n",
    "# model_name_B = 'BT19_joint_hs_{}_ll_{}_hl{}_lr_{}_wr_{}_wk_{}_wc_{}_{}'.format(hidden_size, latent_length, hidden_layer_depth, learning_rate, w_r,w_k, w_c, str(kfold_number))\n",
    "# model_name_I = 'IcubCNN_joint_hs_{}_ll_{}_hl{}_lr_{}_wr_{}_wk_{}_wc_{}_{}'.format(hidden_size, latent_length, hidden_layer_depth, learning_rate, w_r,w_k, w_c, str(kfold_number))\n",
    "model_name_B = 'testB'\n",
    "model_name_I = 'testI'\n",
    "device = torch.device(\"cuda:1\")\n",
    "\n",
    "train_loader, val_loader, train_dataset, val_dataset = get_trainValLoader(data_dir, k=kfold_number, spike_ready=False, batch_size=batch_size, shuffle=False)\n",
    "test_loader, test_dataset = get_testLoader(data_dir, spike_ready=False, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/students/student9_02/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py:50: UserWarning:\n",
      "\n",
      "dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VRAE(n_epochs=100,batch_size=32,cuda=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model\n",
    "model_B_pretrained = VRAEC(num_class=num_class,\n",
    "            sequence_length=sequence_length_B,\n",
    "            number_of_features = number_of_features_B,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            dload = logDir,\n",
    "            model_name=model_name_B,\n",
    "            header=header_B,\n",
    "            device = device)\n",
    "\n",
    "model_B_pretrained.load_state_dict(torch.load(logDir + model_name_B + '.pt'))\n",
    "model_B_pretrained.eval()\n",
    "\n",
    "model_I_pretrained = VRAEC(num_class=num_class,\n",
    "            sequence_length=sequence_length_I,\n",
    "            number_of_features = number_of_features_I,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            dload = logDir,\n",
    "            model_name=model_name_I,\n",
    "            header=header_I,\n",
    "            device = device)\n",
    "model_I_pretrained.load_state_dict(torch.load(logDir + model_name_I + '.pt'))\n",
    "model_I_pretrained.eval()\n",
    "\n",
    "model_B_trained = VRAEC(num_class=num_class,\n",
    "            sequence_length=sequence_length_B,\n",
    "            number_of_features = number_of_features_B,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            dload = logDir,\n",
    "            model_name=model_name_B,\n",
    "            header=header_B,\n",
    "            device = device)\n",
    "\n",
    "model_I_trained = VRAEC(num_class=num_class,\n",
    "            sequence_length=sequence_length_I,\n",
    "            number_of_features = number_of_features_I,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            dload = logDir,\n",
    "            model_name=model_name_I,\n",
    "            header=header_I,\n",
    "            device = device)\n",
    "\n",
    "# print(model_B_trained.state_dict().keys())\n",
    "# dict_keys(['encoder.lstm.weight_ih_l0', 'encoder.lstm.weight_hh_l0', 'encoder.lstm.bias_ih_l0', 'encoder.lstm.bias_hh_l0', 'decoder.model.weight_ih_l0', 'decoder.model.weight_hh_l0', 'decoder.model.bias_ih_l0', 'decoder.model.bias_hh_l0', 'decoder.latent_to_hidden.weight', 'decoder.latent_to_hidden.bias', 'decoder.hidden_to_output.weight', 'decoder.hidden_to_output.bias', 'lmbd.hidden_to_mean.weight', 'lmbd.hidden_to_mean.bias', 'lmbd.hidden_to_logvar.weight', 'lmbd.hidden_to_logvar.bias', 'classifier.0.weight', 'classifier.0.bias'])\n",
    "# print(model_I_trained.state_dict().keys())\n",
    "# keys(['encoder.cnn.seq.0.weight', 'encoder.cnn.seq.0.bias', 'encoder.lstm.weight_ih_l0', 'encoder.lstm.weight_hh_l0', 'encoder.lstm.bias_ih_l0', 'encoder.lstm.bias_hh_l0', 'decoder.dcnn.0.weight', 'decoder.dcnn.0.bias', 'decoder.model.weight_ih_l0', 'decoder.model.weight_hh_l0', 'decoder.model.bias_ih_l0', 'decoder.model.bias_hh_l0', 'decoder.latent_to_hidden.weight', 'decoder.latent_to_hidden.bias', 'decoder.hidden_to_output.weight', 'decoder.hidden_to_output.bias', 'lmbd.hidden_to_mean.weight', 'lmbd.hidden_to_mean.bias', 'lmbd.hidden_to_logvar.weight', 'lmbd.hidden_to_logvar.bias', 'classifier.0.weight', 'classifier.0.bias'])\n",
    "\n",
    "# load origin pretrained_model\n",
    "model_B_trained.load_state_dict(model_B_pretrained.state_dict())\n",
    "model_I_trained.load_state_dict(model_I_pretrained.state_dict())\n",
    "\n",
    "model_B_trained.to(device)\n",
    "model_I_trained.to(device)\n",
    "model_B_trained.eval()\n",
    "model_I_trained.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimB = optim.Adam(model_B.parameters(), lr=learning_rate)\n",
    "optimI = optim.Adam(model_I.parameters(), lr=learning_rate)\n",
    "cl_loss_fn = nn.NLLLoss()\n",
    "recon_loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B_trained.is_fitted = True\n",
    "model_I_trained.is_fitted = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_B_trained = VRAEC(num_class=num_class,\n",
    "            sequence_length=sequence_length_B,\n",
    "            number_of_features = number_of_features_B,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            dload = logDir,\n",
    "            model_name=model_name_B,\n",
    "            header=header_B,\n",
    "            w_r = w_r, \n",
    "            w_k = w_k, \n",
    "            w_c = w_c,\n",
    "            device = device)\n",
    "model_B_trained.load_state_dict(torch.load(logDir + model_name_B + '.pt'))\n",
    "model_B_trained.to(device)\n",
    "model_B_trained.eval()\n",
    "\n",
    "model_I_trained = VRAEC(num_class=num_class,\n",
    "            sequence_length=sequence_length_I,\n",
    "            number_of_features = number_of_features_I,\n",
    "            hidden_size = hidden_size, \n",
    "            hidden_layer_depth = hidden_layer_depth,\n",
    "            latent_length = latent_length,\n",
    "            batch_size = batch_size,\n",
    "            learning_rate = learning_rate,\n",
    "            n_epochs = n_epochs,\n",
    "            dropout_rate = dropout_rate, \n",
    "            cuda = cuda,\n",
    "            print_every=print_every, \n",
    "            clip=clip, \n",
    "            max_grad_norm=max_grad_norm,\n",
    "            dload = logDir,\n",
    "            model_name=model_name_I,\n",
    "            header=header_I,\n",
    "            w_r = w_r, \n",
    "            w_k = w_k, \n",
    "            w_c = w_c,\n",
    "            device = device)\n",
    "model_I_trained.load_state_dict(torch.load(logDir + model_name_I + '.pt'))\n",
    "model_I_trained.to(device)\n",
    "model_I_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import Image\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def scale(X, x_min, x_max):\n",
    "    nom = (X-X.min(axis=0))*(x_max-x_min)\n",
    "    denom = X.max(axis=0) - X.min(axis=0)\n",
    "    denom[denom==0] = 1\n",
    "    return x_min + nom/denom \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualize feature maps of the decoder I output\n",
    "# %matplotlib inline\n",
    "# def get_activation(name):\n",
    "#     def hook(model, input, output):\n",
    "#         activation[name] = output.detach()\n",
    "#     return hook\n",
    "\n",
    "# activation = {}\n",
    "# act_dict = {}\n",
    "# decoded_dict = {}\n",
    "# test_num = 0\n",
    "# for i, (XI, XB,  y) in enumerate(train_loader):\n",
    "#     print(\"processing {} batch\".format(i))\n",
    "#     XI, XB, y = XI.to(device), XB.to(device), y.long().to(device)\n",
    "\n",
    "#     if XI.size()[0] != batch_size:\n",
    "# #             print(\"batch {} size {} < {}, skip\".format(i, x.size()[0], batch_size))\n",
    "#         break\n",
    "\n",
    "#     test_num += XI.size(0)\n",
    "\n",
    "#     # test modelI \n",
    "#     x_decoded, latent, output = model_I_trained(XI)\n",
    "    \n",
    "    \n",
    "#     x_decoded = x_decoded.data.cpu().numpy()\n",
    "#     # create decoded dict based on class\n",
    "#     for i in range(y.size(0)):\n",
    "#         label = y[i].data.cpu().item()\n",
    "#         if label not in decoded_dict:\n",
    "#             decoded_dict[label] = []\n",
    "#         decoded_dict[label].append(x_decoded[i])\n",
    "        \n",
    "# pickle.dump(decoded_dict, open(\"decoded_dict_0420.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 0 batch\n",
      "processing 1 batch\n",
      "processing 2 batch\n",
      "processing 3 batch\n",
      "processing 4 batch\n",
      "processing 5 batch\n",
      "processing 6 batch\n",
      "processing 7 batch\n",
      "processing 8 batch\n",
      "processing 9 batch\n",
      "processing 10 batch\n",
      "processing 11 batch\n",
      "processing 12 batch\n",
      "processing 13 batch\n",
      "processing 14 batch\n",
      "processing 15 batch\n",
      "processing 16 batch\n",
      "processing 17 batch\n",
      "processing 18 batch\n"
     ]
    }
   ],
   "source": [
    "# Visualize feature maps of the decoder B output\n",
    "%matplotlib inline\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "activation = {}\n",
    "act_dict = {}\n",
    "decoded_dict = {}\n",
    "test_num = 0\n",
    "for i, (XI, XB,  y) in enumerate(train_loader):\n",
    "    print(\"processing {} batch\".format(i))\n",
    "    XI, XB, y = XI.to(device), XB.to(device), y.long().to(device)\n",
    "\n",
    "    if XB.size()[0] != batch_size:\n",
    "#             print(\"batch {} size {} < {}, skip\".format(i, x.size()[0], batch_size))\n",
    "        break\n",
    "\n",
    "    test_num += XB.size(0)\n",
    "\n",
    "    # test modelI \n",
    "    x_decoded, latent, output = model_B_trained(XB)\n",
    "    x_decoded = x_decoded.data.cpu().numpy()\n",
    "    # create decoded dict based on class\n",
    "    for i in range(y.size(0)):\n",
    "        label = y[i].data.cpu().item()\n",
    "        if label not in decoded_dict:\n",
    "            decoded_dict[label] = []\n",
    "        decoded_dict[label].append(x_decoded[i])\n",
    "        \n",
    "pickle.dump(decoded_dict, open(\"decoded_dict_B_0421.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     print(decoded_dict.keys())\n",
    "        \n",
    "#         # try to plot one frame of one sample\n",
    "#         plt.imshow(x_decoded[2,:,:,60])\n",
    "\n",
    "# comment on 4.20, try to save the whole decoded_dict\n",
    "#     for i in range(20):\n",
    "#         if i in decoded_dict:\n",
    "#             print(\"class {} has {} test samples\".format(i, len(decoded_dict[i])))\n",
    "            \n",
    "            \n",
    "#     # map the class_number to number of samples\n",
    "#     def count_dict_class(key):\n",
    "#         return [key, len(decoded_dict[key])]\n",
    "  \n",
    "\n",
    "#     pairs = map(count_dict_class, decoded_dict.keys())\n",
    "#     pairs = np.array(list(pairs))\n",
    "# #     print(pairs)\n",
    "#     # find the class with maximum number of test samples\n",
    "#     _, idx = np.argmax(pairs, axis=0)\n",
    "    \n",
    "\n",
    "#     class_number = pairs[idx][0]\n",
    "#     num_samples = pairs[idx][1]\n",
    "#     T = 75\n",
    "#     print(\"max test samples, class {} has {} samples\".format(class_number, num_samples))\n",
    "    \n",
    "#     # save all frames to make video\n",
    "#     print(\"Saving dec_imgs...\")\n",
    "#     for n in range(num_samples):\n",
    "#         myarray = decoded_dict[class_number][n][:, :, :]    \n",
    "# #         print(\"myarray\", myarray.shape) #(6, 10. 75)\n",
    "#         arrayname = \"Dec_imgs/Dec_C{}_S{}\".format(class_number, n)\n",
    "#         pickle.dump(myarray, open(arrayname+\".pkl\", 'wb'))\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         print(\"reload\")\n",
    "#         dec_array = pickle.load(open(arrayname+\".pkl\",'rb'))\n",
    "\n",
    "#         for t in range(T):\n",
    "#             fname = \"Dec_imgs/Dec_C{}_S{}_T{}_c.png\".format(class_number, n, t)\n",
    "#             # normalize the data\n",
    "#             data = myarray[:,:, t]\n",
    "#             print(data.shape, type(data))\n",
    "#             print(data)\n",
    "#             norm_array = scale(data, 0, 1)\n",
    "#             im = Image.fromarray((norm_array * 255).astype(np.uint8))\n",
    "#             im = cm.gist_earth(im)\n",
    "#             im = Image.fromarray(np.uint8(cm.gist_earth(norm_array)*255))\n",
    "#             width, height = im.size\n",
    "# #             print(\"width {}, height {}\".format(width, height)) # 10, 6\n",
    "#             newsize = (100, 60) \n",
    "#             im = im.resize(newsize) \n",
    "\n",
    "        \n",
    "#             im.save(fname)\n",
    "#             display(im)\n",
    "#             raise ValueError(\"check check\")\n",
    "\n",
    "           \n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "#     '''\n",
    "#     Plot the class with maximum number of samples to visualize similarity\n",
    "#     '''\n",
    "#     # Create subplot matrix\n",
    "#     class_number = pairs[idx][0]\n",
    "#     num_col = min(pairs[idx][1], 4)\n",
    "#     # row for frames\n",
    "#     num_row = 25\n",
    "#     assert num_col > 1, \"max number of samples {} <=1\".format(num_col)\n",
    "    \n",
    "#     # create labels\n",
    "#     col_labels = list(np.repeat(class_number, num_col))\n",
    "#     cols = [str(ele) for ele in col_labels]\n",
    "\n",
    "#     rows = ['CH {} '.format(row+1) for row in range(num_row)]\n",
    "#     print(\"cols\", cols, \"rows\", rows)\n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=len(rows), ncols=len(cols), figsize=(20,10)) \n",
    "    \n",
    "#     # set labels\n",
    "#     for ax, col in zip(axes[0], cols):\n",
    "#         ax.set_title(col)\n",
    "\n",
    "#     for ax, row in zip(axes[:,0], rows):\n",
    "#         ax.set_ylabel(row, rotation=0, size='large')\n",
    "    \n",
    "#     # plot the figures\n",
    "#     for col_idx in range(num_col):\n",
    "#         for row_idx in range(num_row):\n",
    "#             axes[row_idx, col_idx].imshow(decoded_dict[class_number][col_idx][:, :,row_idx])\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "    \n",
    "#     plt.savefig(\"Dec_imgs/C{}_NS{}_NT{}.png\".format(class_number, num_col, num_row))\n",
    "#     plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "#     '''\n",
    "#     Plot for different class, to visualize the differences\n",
    "#     '''\n",
    "#     # Create subplot matrix\n",
    "#     num_col = 3\n",
    "#     class_numbers = np.random.choice(list(decoded_dict.keys()), size=num_col, replace=False)\n",
    "#     class_number = pairs[idx][0]\n",
    "    \n",
    "#     print(\"plot for classes: \", class_numbers)\n",
    "    \n",
    "#     # row for frames\n",
    "#     num_row = 20\n",
    "#     assert num_col > 1, \"max number of samples {} <=1\".format(num_col)\n",
    "    \n",
    "#     # create labels\n",
    "#     col_labels = list(class_numbers)\n",
    "#     cols = [str(ele) for ele in col_labels]\n",
    "\n",
    "#     rows = ['CH {} '.format(row+1) for row in range(num_row)]\n",
    "#     print(\"cols\", cols, \"rows\", rows)\n",
    "\n",
    "#     fig, axes = plt.subplots(nrows=len(rows), ncols=len(cols), figsize=(20,30)) \n",
    "    \n",
    "#     # set labels\n",
    "#     for ax, col in zip(axes[0], cols):\n",
    "#         ax.set_title(col)\n",
    "\n",
    "#     for ax, row in zip(axes[:,0], rows):\n",
    "#         ax.set_ylabel(row, rotation=0, size='large')\n",
    "    \n",
    "#     # plot the figures\n",
    "#     for col_idx in range(num_col):\n",
    "#         for row_idx in range(num_row):\n",
    "#             # plot for the first sample of the specified class\n",
    "#             axes[row_idx, col_idx].imshow(decoded_dict[class_numbers[col_idx]][0][:, :,row_idx])\n",
    "    \n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "# #     print(\"x_decoded\", x_decoded.size()) # [32, 6, 10, 75]\n",
    "# #     print(output.shape) # [32, 20]\n",
    "    \n",
    "    \n",
    "# #     act_layer = 'dec_conv1' # output only one frame generated by latent_to_hidden\n",
    "    \n",
    "# #     act_layer = \"decoder\"\n",
    "\n",
    "# #     model_I_trained.encoder.cnn.seq[0].register_forward_hook(get_activation(act_layer))\n",
    "\n",
    "#     # output only one frame generated by latent_to_hidden\n",
    "# #     model_I_trained.decoder.dcnn[0].register_forward_hook(get_activation(act_layer))\n",
    "# #     model_I_trained.decoder.register_forward_hook(get_activation(act_layer))\n",
    "\n",
    "    \n",
    "#     act = activation[act_layer].squeeze()\n",
    "#     print(\"act \", act.size()) # [32, 6, 10]\n",
    "#     act = act.cpu()\n",
    "    \n",
    "#     # fill in the act_dict by class\n",
    "#     for i in range(y.size(0)):\n",
    "#         label = y[i].data.cpu().item()\n",
    "#         if label not in act_dict:\n",
    "#             act_dict[label] = []\n",
    "#         act_dict[label].append(act[i])\n",
    "#     print(act_dict.keys())\n",
    "#     for i in range(20):\n",
    "#         if i in act_dict:\n",
    "#             print(\"class {} has {} test samples\".format(i, len(act_dict[i])))\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "       \n",
    "#     # Create subplot matrix\n",
    "#     class_number = 5\n",
    "#     num_col = len(act_dict[class_number])\n",
    "#     if len(list(act.size()))==4:\n",
    "#         num_row = act.size(3)\n",
    "#     else:\n",
    "#         num_row =1\n",
    "    \n",
    "#     # create labels\n",
    "#     col_labels = list(np.repeat(class_number, num_col))\n",
    "#     cols = [str(ele) for ele in col_labels]\n",
    "    \n",
    "# #     cols = [str(label) for label in y[:num_col].data.cpu().numpy()]\n",
    "#     rows = ['CH {} of act_layer'.format(row+1) for row in range(num_row)]\n",
    "#     print(\"cols\", cols, \"rows\", rows)\n",
    "\n",
    "# #     fig, axes = plt.subplots(nrows=len(rows), ncols=len(cols), figsize=(20, 15)) \n",
    "\n",
    "# #     for ax, col in zip(axes[0], cols):\n",
    "# #         ax.set_title(col)\n",
    "\n",
    "# #     for ax, row in zip(axes[:,0], rows):\n",
    "# #         ax.set_ylabel(row, rotation=0, size='large')\n",
    "        \n",
    "# #     fig, axarr = plt.subplots(act.size(3))\n",
    "    \n",
    "# #     for col_idx in range(num_col):\n",
    "# #         for row_idx in range(num_row):\n",
    "# #             axes[row_idx, col_idx].imshow(act_dict[class_number][col_idx][:, :,row_idx])\n",
    "#     fig, axes = plt.subplots(len(cols), figsize=(20, 15)) \n",
    "#     print(\"axes\", axes)\n",
    "\n",
    "# #     if num_col == 1:\n",
    "# #         axes.set_title(cols[0])\n",
    "# #     else:\n",
    "# #         for col in cols:\n",
    "# #             axes.set_title(col)\n",
    "\n",
    "# #     axes.set_ylabel(row, rotation=0, size='large')\n",
    "        \n",
    "# #     fig, axarr = plt.subplots(act.size(3))\n",
    "    \n",
    "# #     for col_idx in range(num_col):\n",
    "# #         for row_idx in range(num_row):\n",
    "# #             axes[row_idx, col_idx].imshow(act_dict[class_number][col_idx][:, :,row_idx])\n",
    "#     for col_idx in range(num_col):\n",
    "#         axes[col_idx].imshow(act_dict[class_number][col_idx])\n",
    "    \n",
    "\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
