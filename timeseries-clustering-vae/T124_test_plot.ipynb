{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "python T1_BT19_Icub_joint_ae.py -k 0 -c 0 -r 1\n",
    "\n",
    "Note: still use one-stage training with both recon loss and classification loss\n",
    "'''\n",
    "# Import\n",
    "\n",
    "import os,sys\n",
    "CURRENT_TEST_DIR = os.getcwd()\n",
    "sys.path.append(CURRENT_TEST_DIR + \"/../new_iteration/\")\n",
    "import pickle\n",
    "import argparse\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "\n",
    "from vrae.vrae import VRAEC\n",
    "from vrae.utils import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data as data2\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datetime import datetime\n",
    "from tas_utils_bs import get_trainValLoader, get_testLoader\n",
    "import plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Parse argument\n",
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument(\"-k\", \"--kfold\", type=int, default=0, help=\"kfold_number for loading data\")\n",
    "# parser.add_argument(\"-r\", \"--reduction\", type=int, default=1, help=\"data reduction ratio for partial training\")\n",
    "# parser.add_argument(\"-c\", \"--cuda\", default=0, help=\"index of cuda gpu to use\")\n",
    "# args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy class to replace argparser\n",
    "class Args:\n",
    "  kfold = 0\n",
    "  reduction = 1\n",
    "  cuda = '0'\n",
    "  removal =0\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 0 kfold number, reduce data to 1 folds, put to cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8d1b6e3130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"load {} kfold number, reduce data to {} folds, put to cuda:{}\".format(args.kfold, args.reduction, args.cuda))\n",
    "\n",
    "# Set hyper params\n",
    "kfold_number = args.kfold\n",
    "data_reduction_ratio = args.reduction\n",
    "removal = args.removal\n",
    "shuffle = True\n",
    "num_class = 20\n",
    "sequence_length_B = 400\n",
    "sequence_length_I = 75\n",
    "number_of_features_B = 19\n",
    "number_of_features_I = 60\n",
    "\n",
    "hidden_size = 90\n",
    "hidden_layer_depth = 1\n",
    "latent_length = 40\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "n_epochs = 2000\n",
    "\n",
    "learning_rate_2 = 0.01\n",
    "n_epochs_2 = 20\n",
    "\n",
    "dropout_rate = 0.2\n",
    "cuda = True # options: True, False\n",
    "print_every=30\n",
    "clip = True # options: True, False\n",
    "max_grad_norm=5\n",
    "header_B = None\n",
    "header_I = \"CNN\"\n",
    "\n",
    "w_mse = 1 # mse between latent vectors\n",
    "w_rB = 0.01 # recon for B\n",
    "w_rI = 0.01 # recon for I\n",
    "w_cB = 1 # classify for B\n",
    "w_cI = 1 # classify for I\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data_dir = '../../new_data_folder/'\n",
    "\n",
    "logDir = 'models_and_stat/'\n",
    "# new model\n",
    "model_B_joint = 'BT19_joint_ae_wrB_{}_wcB_{}_wrI_{}_wcI_{}_wC_{}_{}'\\\n",
    "    .format(w_rB,w_cB, w_rI, w_cI, w_mse, str(kfold_number))\n",
    "\n",
    "model_I_joint = 'IcubCNN_joint_ae_wrB_{}_wcB_{}_wrI_{}_wcI_{}_wC_{}_{}'\\\n",
    "    .format(w_rB,w_cB, w_rI, w_cI, w_mse, str(kfold_number))\n",
    "\n",
    "model_B = \"BT19_ae_{}_rm_{}_wrI_{}_wC_{}_{}.pt\".format(data_reduction_ratio, removal, w_rI, w_mse, str(kfold_number))\n",
    "kI = 1\n",
    "model_I =  \"IcubCNN_ae_{}_rm_{}_wrI_{}_wC_{}_{}.pt\".format(data_reduction_ratio, removal, w_rI, w_mse, str(kI))\n",
    "\n",
    "device = torch.device(\"cuda:{}\".format(args.cuda))\n",
    "print(\"Loading data...\")\n",
    "\n",
    "train_loader, val_loader, train_dataset, val_dataset = get_trainValLoader(data_dir, k=kfold_number, spike_ready=False, batch_size=batch_size, shuffle=shuffle)\n",
    "test_loader, test_dataset = get_testLoader(data_dir, spike_ready=False, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BT19_ae_1_rm_0_wrI_0.01_wC_1_0_stats.pkl\n"
     ]
    }
   ],
   "source": [
    "joint_dict_name = \"Joint-dict.pkl\"\n",
    "mB_dict_name = model_B[:-3] + \"_stats.pkl\"\n",
    "mI_dict_name = model_I[:-3] + \"_stats.pkl\"\n",
    "print(mB_dict_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models_and_stat/Joint-dict.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-32c1c9db3d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjoint_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mjoint_dict_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoint_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models_and_stat/Joint-dict.pkl'"
     ]
    }
   ],
   "source": [
    "joint_dict = pickle.load(open(logDir+joint_dict_name, 'rb'))\n",
    "print(joint_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'models_and_stat/BT19_ae_1_rm_0_wrI_0.01_wC_1_0_stats.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-08c68e4d7fb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmB_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmB_dict_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmI_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogDir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmI_dict_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmB_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'models_and_stat/BT19_ae_1_rm_0_wrI_0.01_wC_1_0_stats.pkl'"
     ]
    }
   ],
   "source": [
    "mB_dict = pickle.load(open(logDir+mB_dict_name, 'rb'))\n",
    "mI_dict = pickle.load(open(logDir+mI_dict_name, 'rb'))\n",
    "print(mB_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert n_epochs == len(epoch_train_acc), \"different epoch length {} {}\".format(n_epochs, len(epoch_train_acc))\n",
    "print(len(joint_dict['epoch_train_acc_B']), len(mB_dict['epoch_train_acc']))\n",
    "fig, ax = plt.subplots(figsize=(15, 7))\n",
    "# ax.plot(np.arange(200), joint_dict['epoch_train_acc_B'][:200], label=\"joint_B_train_acc\")\n",
    "# ax.plot(np.arange(200), mB_dict['epoch_train_acc'][:200], label=\"B_train_acc\")\n",
    "# ax.plot(np.arange(200), joint_dict['epoch_train_acc_I'][:200], label=\"joint_I_train_acc\")\n",
    "# ax.plot(np.arange(200), mI_dict['epoch_train_acc'][:200], label=\"I_train_acc\")\n",
    "\n",
    "ax.plot(np.arange(200), joint_dict['epoch_val_acc_B'][:200], label=\"joint_B_val_acc\")\n",
    "ax.plot(np.arange(200), mB_dict['epoch_val_acc'][:200], label=\"B_val_acc\")\n",
    "ax.plot(np.arange(200), joint_dict['epoch_val_acc_I'][:200], label=\"joint_I_val_acc\")\n",
    "ax.plot(np.arange(200), mI_dict['epoch_val_acc'][:200], label=\"I_val_acc\")\n",
    "\n",
    "\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('acc')\n",
    "ax.grid(True)\n",
    "plt.legend(loc='upper right')\n",
    "figname = logDir +\"T124_val_acc_comp.png\"\n",
    "plt.savefig(figname)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
