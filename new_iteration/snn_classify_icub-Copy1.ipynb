{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN on Icub Data\n",
    "\n",
    "Here we implement autoencoder:\n",
    "\n",
    "loss = loss_classification + loss_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "CURRENT_TEST_DIR = os.getcwd()\n",
    "sys.path.append(CURRENT_TEST_DIR + \"/../../../../slayerPytorch/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7713a36d90>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import slayerSNN as snn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tas_utils import get_trainValLoader, get_testLoader\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../new_data_folder/'\n",
    "logDir = 'models_and_stats/'\n",
    "kfold_number = 0\n",
    "\n",
    "model_name = 'snn_classify_icub_' + str(kfold_number)\n",
    "screen_fr = 20\n",
    "\n",
    "save_dir = logDir + model_name + '.pt'\n",
    "\n",
    "train_loader, val_loader, train_dataset, val_dataset = get_trainValLoader(data_dir, k=0)\n",
    "test_loader, test_dataset = get_testLoader(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define spike neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"neuron\": {\n",
    "        \"type\": \"SRMALPHA\",\n",
    "        \"theta\": 5, # 10\n",
    "        \"tauSr\": 10.0,\n",
    "        \"tauRef\": 2.0,\n",
    "        \"scaleRef\": 2,\n",
    "        \"tauRho\": 1,\n",
    "        \"scaleRho\": 1,\n",
    "    },\n",
    "    \"simulation\": {\"Ts\": 1.0, \"tSample\": 75, \"nSample\": 1},\n",
    "    \"training\": {\n",
    "        \"error\": {\n",
    "            \"type\": \"NumSpikes\",  # \"NumSpikes\" or \"ProbSpikes\"\n",
    "            \"probSlidingWin\": 20,  # only valid for ProbSpikes\n",
    "            \"tgtSpikeRegion\": {  # valid for NumSpikes and ProbSpikes\n",
    "                \"start\": 0,\n",
    "                \"stop\": 75,\n",
    "            },\n",
    "            \"tgtSpikeCount\": {True: 55, False: 15},\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_icub_spike(X):\n",
    "    \n",
    "#     # parameters\n",
    "#     C = 0.5\n",
    "#     p_pos = 1 \n",
    "#     p_neg = -1\n",
    "    \n",
    "    \n",
    "#     X = X.squeeze()\n",
    "    \n",
    "#     # nonzero elements -> log\n",
    "#     non_zero_indx = np.where(X > 0)\n",
    "#     log_X = torch.zeros(X.shape)\n",
    "#     log_X[non_zero_indx] = torch.log( X[ non_zero_indx ] )\n",
    "#     x_diff = log_X[..., 1:] - log_X[..., :-1]\n",
    "    \n",
    "#     brightness_diff = torch.cat([log_X[...,0].reshape([log_X.shape[0], log_X.shape[1],1]),  x_diff], dim=2)\n",
    "    \n",
    "#     spike_train_pos = torch.zeros(X.shape)\n",
    "#     spike_train_neg = torch.zeros(X.shape)\n",
    "\n",
    "#     spike_train_pos[brightness_diff >= p_pos*C] = 1\n",
    "#     spike_train_neg[brightness_diff <= p_neg*C] = 1\n",
    "    \n",
    "#     res = torch.cat([spike_train_pos, spike_train_neg], dim=1)\n",
    "    \n",
    "#     return res.reshape(res.shape[0],res.shape[1],1,1,res.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlayerMLP(torch.nn.Module):\n",
    "    def __init__(self, params, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SlayerMLP, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.slayer = snn.layer(params[\"neuron\"], params[\"simulation\"])\n",
    "        self.fc1 = self.slayer.dense(input_size, hidden_size1)\n",
    "        self.fc2 = self.slayer.dense(hidden_size1, hidden_size2)\n",
    "        self.fc3 = self.slayer.dense(hidden_size2, output_size)\n",
    "        \n",
    "    def get_spike(self, inp):\n",
    "        return self.slayer.spike(inp)\n",
    "        \n",
    "    def forward(self, spike_input):\n",
    "        spike_1 = self.slayer.spike(self.slayer.psp(self.fc1(spike_input)))\n",
    "        spike_2 = self.slayer.spike(self.slayer.psp(self.fc2(spike_1)))\n",
    "        spike_output = self.slayer.spike(self.slayer.psp(self.fc3(spike_2)))\n",
    "        \n",
    "        return spike_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "net = SlayerMLP(params, 60, 50, 50, 20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = snn.loss(params).to(device)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  --------------------------\n",
      "Train loss : 30.26331204732259\n",
      "Train accuracy: 0.08666666666666667\n",
      "Val loss (all, class, reg): 23.06846694946289\n",
      "Val accuracy: 0.115\n",
      "Saving model at  0  epoch\n",
      "Saving model at  1  epoch\n",
      "Saving model at  2  epoch\n",
      "Saving model at  3  epoch\n",
      "Saving model at  4  epoch\n",
      "Saving model at  5  epoch\n",
      "Saving model at  6  epoch\n",
      "Saving model at  8  epoch\n",
      "Saving model at  9  epoch\n",
      "Saving model at  10  epoch\n",
      "Saving model at  11  epoch\n",
      "Saving model at  12  epoch\n",
      "Saving model at  13  epoch\n",
      "Saving model at  14  epoch\n",
      "Saving model at  16  epoch\n",
      "Saving model at  17  epoch\n",
      "Saving model at  18  epoch\n",
      "Saving model at  19  epoch\n",
      "Epoch:  20  --------------------------\n",
      "Train loss : 8.495433305104573\n",
      "Train accuracy: 0.6783333333333333\n",
      "Val loss (all, class, reg): 9.399866676330566\n",
      "Val accuracy: 0.585\n",
      "Saving model at  20  epoch\n",
      "Saving model at  21  epoch\n",
      "Saving model at  22  epoch\n",
      "Saving model at  23  epoch\n",
      "Saving model at  26  epoch\n",
      "Saving model at  30  epoch\n",
      "Saving model at  34  epoch\n",
      "Saving model at  39  epoch\n",
      "Epoch:  40  --------------------------\n",
      "Train loss : 6.782988815307617\n",
      "Train accuracy: 0.75\n",
      "Val loss (all, class, reg): 7.939766750335694\n",
      "Val accuracy: 0.645\n",
      "Saving model at  40  epoch\n",
      "Saving model at  41  epoch\n",
      "Saving model at  48  epoch\n",
      "Saving model at  50  epoch\n",
      "Saving model at  54  epoch\n",
      "Epoch:  60  --------------------------\n",
      "Train loss : 5.892922194798787\n",
      "Train accuracy: 0.79\n",
      "Val loss (all, class, reg): 7.132633419036865\n",
      "Val accuracy: 0.68\n",
      "Saving model at  62  epoch\n",
      "Saving model at  63  epoch\n",
      "Saving model at  65  epoch\n",
      "Saving model at  66  epoch\n",
      "Saving model at  67  epoch\n",
      "Saving model at  68  epoch\n",
      "Saving model at  69  epoch\n",
      "Saving model at  72  epoch\n",
      "Saving model at  75  epoch\n",
      "Epoch:  80  --------------------------\n",
      "Train loss : 5.333922233581543\n",
      "Train accuracy: 0.8283333333333334\n",
      "Val loss (all, class, reg): 6.681333351135254\n",
      "Val accuracy: 0.715\n",
      "Saving model at  82  epoch\n",
      "Saving model at  94  epoch\n",
      "Saving model at  96  epoch\n",
      "Saving model at  98  epoch\n",
      "Epoch:  100  --------------------------\n",
      "Train loss : 4.9109555466969805\n",
      "Train accuracy: 0.8383333333333334\n",
      "Val loss (all, class, reg): 6.368633365631103\n",
      "Val accuracy: 0.745\n",
      "Saving model at  106  epoch\n",
      "Saving model at  107  epoch\n",
      "Epoch:  120  --------------------------\n",
      "Train loss : 4.568899997075399\n",
      "Train accuracy: 0.8616666666666667\n",
      "Val loss (all, class, reg): 6.1953332901000975\n",
      "Val accuracy: 0.725\n",
      "Saving model at  122  epoch\n",
      "Saving model at  132  epoch\n",
      "Epoch:  140  --------------------------\n",
      "Train loss : 4.205444444020589\n",
      "Train accuracy: 0.8766666666666667\n",
      "Val loss (all, class, reg): 5.792066745758056\n",
      "Val accuracy: 0.76\n",
      "Epoch:  160  --------------------------\n",
      "Train loss : 3.944822195370992\n",
      "Train accuracy: 0.8616666666666667\n",
      "Val loss (all, class, reg): 5.566033306121827\n",
      "Val accuracy: 0.765\n",
      "Saving model at  161  epoch\n",
      "Epoch:  180  --------------------------\n",
      "Train loss : 3.716977791786194\n",
      "Train accuracy: 0.8833333333333333\n",
      "Val loss (all, class, reg): 5.361033372879028\n",
      "Val accuracy: 0.765\n",
      "Epoch:  200  --------------------------\n",
      "Train loss : 3.526366670926412\n",
      "Train accuracy: 0.8866666666666667\n",
      "Val loss (all, class, reg): 5.261833400726318\n",
      "Val accuracy: 0.745\n",
      "Epoch:  220  --------------------------\n",
      "Train loss : 3.414699969291687\n",
      "Train accuracy: 0.8866666666666667\n",
      "Val loss (all, class, reg): 5.12316668510437\n",
      "Val accuracy: 0.75\n",
      "Epoch:  240  --------------------------\n",
      "Train loss : 3.283033289909363\n",
      "Train accuracy: 0.8933333333333333\n",
      "Val loss (all, class, reg): 4.939833307266236\n",
      "Val accuracy: 0.775\n",
      "Epoch:  260  --------------------------\n",
      "Train loss : 3.1878333616256715\n",
      "Train accuracy: 0.8966666666666666\n",
      "Val loss (all, class, reg): 4.823066577911377\n",
      "Val accuracy: 0.78\n",
      "Epoch:  280  --------------------------\n",
      "Train loss : 3.090488866170247\n",
      "Train accuracy: 0.8983333333333333\n",
      "Val loss (all, class, reg): 4.812466716766357\n",
      "Val accuracy: 0.775\n",
      "Saving model at  294  epoch\n",
      "Epoch:  300  --------------------------\n",
      "Train loss : 3.0152777942021687\n",
      "Train accuracy: 0.8983333333333333\n",
      "Val loss (all, class, reg): 4.821766619682312\n",
      "Val accuracy: 0.785\n",
      "Saving model at  304  epoch\n",
      "Epoch:  320  --------------------------\n",
      "Train loss : 2.9410888560612998\n",
      "Train accuracy: 0.9033333333333333\n",
      "Val loss (all, class, reg): 4.743966674804687\n",
      "Val accuracy: 0.77\n",
      "Epoch:  340  --------------------------\n",
      "Train loss : 2.8755333058039345\n",
      "Train accuracy: 0.8966666666666666\n",
      "Val loss (all, class, reg): 4.722033386230469\n",
      "Val accuracy: 0.765\n",
      "Epoch:  360  --------------------------\n",
      "Train loss : 2.805244425137838\n",
      "Train accuracy: 0.9016666666666666\n",
      "Val loss (all, class, reg): 4.630499973297119\n",
      "Val accuracy: 0.78\n",
      "Saving model at  370  epoch\n",
      "Epoch:  380  --------------------------\n",
      "Train loss : 2.756511098543803\n",
      "Train accuracy: 0.9116666666666666\n",
      "Val loss (all, class, reg): 4.7153666305541995\n",
      "Val accuracy: 0.775\n",
      "Epoch:  400  --------------------------\n",
      "Train loss : 2.6978333075841268\n",
      "Train accuracy: 0.8983333333333333\n",
      "Val loss (all, class, reg): 4.591766667366028\n",
      "Val accuracy: 0.78\n",
      "Epoch:  420  --------------------------\n",
      "Train loss : 2.6622666422526042\n",
      "Train accuracy: 0.9066666666666666\n",
      "Val loss (all, class, reg): 4.629899969100952\n",
      "Val accuracy: 0.79\n",
      "Saving model at  436  epoch\n",
      "Epoch:  440  --------------------------\n",
      "Train loss : 2.6166222143173217\n",
      "Train accuracy: 0.9033333333333333\n",
      "Val loss (all, class, reg): 4.637166624069214\n",
      "Val accuracy: 0.78\n",
      "Saving model at  450  epoch\n",
      "Saving model at  451  epoch\n",
      "Epoch:  460  --------------------------\n",
      "Train loss : 2.5902888838450115\n",
      "Train accuracy: 0.8983333333333333\n",
      "Val loss (all, class, reg): 4.558266706466675\n",
      "Val accuracy: 0.795\n",
      "Saving model at  463  epoch\n",
      "Saving model at  464  epoch\n",
      "Saving model at  469  epoch\n",
      "Saving model at  471  epoch\n",
      "Saving model at  476  epoch\n",
      "Epoch:  480  --------------------------\n",
      "Train loss : 2.5428555321693422\n",
      "Train accuracy: 0.9133333333333333\n",
      "Val loss (all, class, reg): 4.534733347892761\n",
      "Val accuracy: 0.79\n",
      "Saving model at  482  epoch\n",
      "Epoch:  500  --------------------------\n",
      "Train loss : 2.5279999685287478\n",
      "Train accuracy: 0.9166666666666666\n",
      "Val loss (all, class, reg): 4.536033344268799\n",
      "Val accuracy: 0.795\n",
      "Saving model at  502  epoch\n",
      "Epoch:  520  --------------------------\n",
      "Train loss : 2.4946999764442443\n",
      "Train accuracy: 0.9216666666666666\n",
      "Val loss (all, class, reg): 4.613899970054627\n",
      "Val accuracy: 0.8\n",
      "Saving model at  524  epoch\n",
      "Saving model at  535  epoch\n",
      "Epoch:  540  --------------------------\n",
      "Train loss : 2.4632999976476033\n",
      "Train accuracy: 0.915\n",
      "Val loss (all, class, reg): 4.556733322143555\n",
      "Val accuracy: 0.8\n",
      "Epoch:  560  --------------------------\n",
      "Train loss : 2.4381222041447956\n",
      "Train accuracy: 0.905\n",
      "Val loss (all, class, reg): 4.481133370399475\n",
      "Val accuracy: 0.795\n",
      "Saving model at  574  epoch\n",
      "Epoch:  580  --------------------------\n",
      "Train loss : 2.3979110964139303\n",
      "Train accuracy: 0.915\n",
      "Val loss (all, class, reg): 4.470999999046326\n",
      "Val accuracy: 0.795\n",
      "Epoch:  600  --------------------------\n",
      "Train loss : 2.382855549653371\n",
      "Train accuracy: 0.915\n",
      "Val loss (all, class, reg): 4.449499869346619\n",
      "Val accuracy: 0.8\n",
      "Saving model at  601  epoch\n",
      "Saving model at  605  epoch\n",
      "Saving model at  608  epoch\n",
      "Saving model at  612  epoch\n",
      "Epoch:  620  --------------------------\n",
      "Train loss : 2.35424441576004\n",
      "Train accuracy: 0.9133333333333333\n",
      "Val loss (all, class, reg): 4.418166646957397\n",
      "Val accuracy: 0.81\n",
      "Saving model at  631  epoch\n",
      "Epoch:  640  --------------------------\n",
      "Train loss : 2.321444426377614\n",
      "Train accuracy: 0.9166666666666666\n",
      "Val loss (all, class, reg): 4.448766622543335\n",
      "Val accuracy: 0.8\n",
      "Saving model at  642  epoch\n",
      "Saving model at  652  epoch\n",
      "Epoch:  660  --------------------------\n",
      "Train loss : 2.2849221801757813\n",
      "Train accuracy: 0.9166666666666666\n",
      "Val loss (all, class, reg): 4.416133389472962\n",
      "Val accuracy: 0.81\n",
      "Epoch:  680  --------------------------\n",
      "Train loss : 2.2679777693748475\n",
      "Train accuracy: 0.9266666666666666\n",
      "Val loss (all, class, reg): 4.421400022506714\n",
      "Val accuracy: 0.81\n",
      "Epoch:  700  --------------------------\n",
      "Train loss : 2.2553666361172993\n",
      "Train accuracy: 0.915\n",
      "Val loss (all, class, reg): 4.398699955940247\n",
      "Val accuracy: 0.815\n",
      "Saving model at  703  epoch\n",
      "Saving model at  707  epoch\n",
      "Saving model at  709  epoch\n",
      "Epoch:  720  --------------------------\n",
      "Train loss : 2.2406111137072244\n",
      "Train accuracy: 0.9166666666666666\n",
      "Val loss (all, class, reg): 4.4121000194549564\n",
      "Val accuracy: 0.795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at  732  epoch\n",
      "Epoch:  740  --------------------------\n",
      "Train loss : 2.201777761777242\n",
      "Train accuracy: 0.9166666666666666\n",
      "Val loss (all, class, reg): 4.416566658020019\n",
      "Val accuracy: 0.81\n",
      "Epoch:  760  --------------------------\n",
      "Train loss : 2.188688866297404\n",
      "Train accuracy: 0.92\n",
      "Val loss (all, class, reg): 4.328466625213623\n",
      "Val accuracy: 0.81\n",
      "Saving model at  764  epoch\n",
      "Saving model at  777  epoch\n",
      "Epoch:  780  --------------------------\n",
      "Train loss : 2.182277762889862\n",
      "Train accuracy: 0.9133333333333333\n",
      "Val loss (all, class, reg): 4.3241333532333375\n",
      "Val accuracy: 0.825\n",
      "Saving model at  780  epoch\n",
      "Saving model at  786  epoch\n",
      "Epoch:  800  --------------------------\n",
      "Train loss : 2.1595777757962544\n",
      "Train accuracy: 0.92\n",
      "Val loss (all, class, reg): 4.325733318328857\n",
      "Val accuracy: 0.81\n",
      "Saving model at  811  epoch\n",
      "Epoch:  820  --------------------------\n",
      "Train loss : 2.14203334013621\n",
      "Train accuracy: 0.9116666666666666\n",
      "Val loss (all, class, reg): 4.390566630363464\n",
      "Val accuracy: 0.805\n",
      "Epoch:  840  --------------------------\n",
      "Train loss : 2.118855551878611\n",
      "Train accuracy: 0.925\n",
      "Val loss (all, class, reg): 4.3083333492279055\n",
      "Val accuracy: 0.82\n",
      "Saving model at  848  epoch\n",
      "Epoch:  860  --------------------------\n",
      "Train loss : 2.1093555625279743\n",
      "Train accuracy: 0.925\n",
      "Val loss (all, class, reg): 4.353166680335999\n",
      "Val accuracy: 0.815\n",
      "Saving model at  868  epoch\n",
      "Epoch:  880  --------------------------\n",
      "Train loss : 2.10078888575236\n",
      "Train accuracy: 0.9266666666666666\n",
      "Val loss (all, class, reg): 4.326766633987427\n",
      "Val accuracy: 0.805\n",
      "Epoch:  900  --------------------------\n",
      "Train loss : 2.082855520248413\n",
      "Train accuracy: 0.925\n",
      "Val loss (all, class, reg): 4.309066658020019\n",
      "Val accuracy: 0.815\n",
      "Epoch:  920  --------------------------\n",
      "Train loss : 2.059133320649465\n",
      "Train accuracy: 0.9216666666666666\n",
      "Val loss (all, class, reg): 4.310199975967407\n",
      "Val accuracy: 0.82\n",
      "Epoch:  940  --------------------------\n",
      "Train loss : 2.039399976730347\n",
      "Train accuracy: 0.9283333333333333\n",
      "Val loss (all, class, reg): 4.322633357048034\n",
      "Val accuracy: 0.82\n",
      "Epoch:  960  --------------------------\n",
      "Train loss : 2.031877767244975\n",
      "Train accuracy: 0.9233333333333333\n",
      "Val loss (all, class, reg): 4.362166647911072\n",
      "Val accuracy: 0.815\n",
      "Epoch:  980  --------------------------\n",
      "Train loss : 2.0424222191174826\n",
      "Train accuracy: 0.925\n",
      "Val loss (all, class, reg): 4.2943333148956295\n",
      "Val accuracy: 0.82\n",
      "Epoch:  1000  --------------------------\n",
      "Train loss : 2.0199333175023395\n",
      "Train accuracy: 0.9166666666666666\n",
      "Val loss (all, class, reg): 4.368299951553345\n",
      "Val accuracy: 0.815\n",
      "Epoch:  1020  --------------------------\n",
      "Train loss : 1.9984555514653524\n",
      "Train accuracy: 0.9183333333333333\n",
      "Val loss (all, class, reg): 4.363766617774964\n",
      "Val accuracy: 0.805\n",
      "Epoch:  1040  --------------------------\n",
      "Train loss : 1.9889333335558574\n",
      "Train accuracy: 0.93\n",
      "Val loss (all, class, reg): 4.348999938964844\n",
      "Val accuracy: 0.815\n",
      "Epoch:  1060  --------------------------\n",
      "Train loss : 1.972300000190735\n",
      "Train accuracy: 0.9266666666666666\n",
      "Val loss (all, class, reg): 4.337066669464111\n",
      "Val accuracy: 0.805\n",
      "Epoch:  1080  --------------------------\n",
      "Train loss : 1.9598666644096374\n",
      "Train accuracy: 0.92\n",
      "Val loss (all, class, reg): 4.345300035476685\n",
      "Val accuracy: 0.81\n",
      "Epoch:  1100  --------------------------\n",
      "Train loss : 1.9517111031214396\n",
      "Train accuracy: 0.925\n",
      "Val loss (all, class, reg): 4.330966658592224\n",
      "Val accuracy: 0.82\n",
      "Epoch:  1120  --------------------------\n",
      "Train loss : 1.9400110936164856\n",
      "Train accuracy: 0.9216666666666666\n",
      "Val loss (all, class, reg): 4.4134332990646366\n",
      "Val accuracy: 0.805\n",
      "Epoch:  1140  --------------------------\n",
      "Train loss : 1.939055548508962\n",
      "Train accuracy: 0.92\n",
      "Val loss (all, class, reg): 4.361266603469849\n",
      "Val accuracy: 0.82\n",
      "Epoch:  1160  --------------------------\n",
      "Train loss : 1.9300999855995178\n",
      "Train accuracy: 0.93\n",
      "Val loss (all, class, reg): 4.366200017929077\n",
      "Val accuracy: 0.82\n",
      "Epoch:  1180  --------------------------\n",
      "Train loss : 1.9102555473645528\n",
      "Train accuracy: 0.92\n",
      "Val loss (all, class, reg): 4.351166687011719\n",
      "Val accuracy: 0.81\n",
      "Epoch:  1200  --------------------------\n",
      "Train loss : 1.9238666534423827\n",
      "Train accuracy: 0.92\n",
      "Val loss (all, class, reg): 4.4267666721343994\n",
      "Val accuracy: 0.815\n",
      "Epoch:  1220  --------------------------\n",
      "Train loss : 1.8932111072540283\n",
      "Train accuracy: 0.93\n",
      "Val loss (all, class, reg): 4.341699967384338\n",
      "Val accuracy: 0.825\n",
      "Saving model at  1222  epoch\n",
      "Epoch:  1240  --------------------------\n",
      "Train loss : 1.8920999828974405\n",
      "Train accuracy: 0.93\n",
      "Val loss (all, class, reg): 4.3186666297912595\n",
      "Val accuracy: 0.82\n",
      "Epoch:  1260  --------------------------\n",
      "Train loss : 1.8885333116849263\n",
      "Train accuracy: 0.92\n",
      "Val loss (all, class, reg): 4.344800071716309\n",
      "Val accuracy: 0.81\n",
      "Saving model at  1267  epoch\n",
      "Epoch:  1280  --------------------------\n",
      "Train loss : 1.8822110907236735\n",
      "Train accuracy: 0.925\n",
      "Val loss (all, class, reg): 4.304900016784668\n",
      "Val accuracy: 0.815\n",
      "Saving model at  1295  epoch\n",
      "Epoch:  1300  --------------------------\n",
      "Train loss : 1.8816555460294089\n",
      "Train accuracy: 0.9283333333333333\n",
      "Val loss (all, class, reg): 4.363133335113526\n",
      "Val accuracy: 0.8\n",
      "Saving model at  1318  epoch\n",
      "Epoch:  1320  --------------------------\n",
      "Train loss : 1.8584777808189392\n",
      "Train accuracy: 0.9216666666666666\n",
      "Val loss (all, class, reg): 4.3767666292190555\n",
      "Val accuracy: 0.805\n",
      "Saving model at  1337  epoch\n",
      "Epoch:  1340  --------------------------\n",
      "Train loss : 1.8573999762535096\n",
      "Train accuracy: 0.9183333333333333\n",
      "Val loss (all, class, reg): 4.3640333580970765\n",
      "Val accuracy: 0.825\n",
      "Saving model at  1349  epoch\n",
      "Saving model at  1354  epoch\n",
      "Epoch:  1360  --------------------------\n",
      "Train loss : 1.8589999826749166\n",
      "Train accuracy: 0.9183333333333333\n",
      "Val loss (all, class, reg): 4.354133296012878\n",
      "Val accuracy: 0.83\n",
      "Epoch:  1380  --------------------------\n",
      "Train loss : 1.8450777554512023\n",
      "Train accuracy: 0.9283333333333333\n",
      "Val loss (all, class, reg): 4.323766736984253\n",
      "Val accuracy: 0.825\n",
      "Saving model at  1384  epoch\n",
      "Saving model at  1391  epoch\n",
      "Saving model at  1395  epoch\n",
      "Epoch:  1400  --------------------------\n",
      "Train loss : 1.8354110956192016\n",
      "Train accuracy: 0.9316666666666666\n",
      "Val loss (all, class, reg): 4.33220006942749\n",
      "Val accuracy: 0.83\n",
      "Epoch:  1420  --------------------------\n",
      "Train loss : 1.8179888753096263\n",
      "Train accuracy: 0.9283333333333333\n",
      "Val loss (all, class, reg): 4.287633285522461\n",
      "Val accuracy: 0.815\n",
      "Epoch:  1440  --------------------------\n",
      "Train loss : 1.8142999951044718\n",
      "Train accuracy: 0.9183333333333333\n",
      "Val loss (all, class, reg): 4.370433330535889\n",
      "Val accuracy: 0.815\n",
      "Saving model at  1448  epoch\n",
      "Saving model at  1459  epoch\n",
      "Epoch:  1460  --------------------------\n",
      "Train loss : 1.8085110863049825\n",
      "Train accuracy: 0.9266666666666666\n",
      "Val loss (all, class, reg): 4.298766660690307\n",
      "Val accuracy: 0.82\n",
      "Saving model at  1477  epoch\n",
      "Epoch:  1480  --------------------------\n",
      "Train loss : 1.7989999890327453\n",
      "Train accuracy: 0.925\n",
      "Val loss (all, class, reg): 4.321933293342591\n",
      "Val accuracy: 0.83\n",
      "Saving model at  1493  epoch\n",
      "Epoch:  1500  --------------------------\n",
      "Train loss : 1.7980333113670348\n",
      "Train accuracy: 0.93\n",
      "Val loss (all, class, reg): 4.301199984550476\n",
      "Val accuracy: 0.82\n",
      "Saving model at  1503  epoch\n",
      "Saving model at  1506  epoch\n",
      "Saving model at  1511  epoch\n",
      "Saving model at  1517  epoch\n",
      "Epoch:  1520  --------------------------\n",
      "Train loss : 1.7876666768391927\n",
      "Train accuracy: 0.93\n",
      "Val loss (all, class, reg): 4.292533254623413\n",
      "Val accuracy: 0.83\n",
      "Saving model at  1523  epoch\n",
      "Saving model at  1533  epoch\n",
      "Epoch:  1540  --------------------------\n",
      "Train loss : 1.7925110816955567\n",
      "Train accuracy: 0.9283333333333333\n",
      "Val loss (all, class, reg): 4.283366494178772\n",
      "Val accuracy: 0.82\n",
      "Saving model at  1543  epoch\n",
      "Saving model at  1554  epoch\n",
      "Epoch:  1560  --------------------------\n",
      "Train loss : 1.778322196006775\n",
      "Train accuracy: 0.93\n",
      "Val loss (all, class, reg): 4.326366586685181\n",
      "Val accuracy: 0.815\n",
      "Epoch:  1580  --------------------------\n",
      "Train loss : 1.7799999880790711\n",
      "Train accuracy: 0.93\n",
      "Val loss (all, class, reg): 4.2253666114807125\n",
      "Val accuracy: 0.845\n",
      "Saving model at  1580  epoch\n",
      "Epoch:  1600  --------------------------\n",
      "Train loss : 1.773355545202891\n",
      "Train accuracy: 0.93\n",
      "Val loss (all, class, reg): 4.2777000904083256\n",
      "Val accuracy: 0.83\n",
      "Epoch:  1620  --------------------------\n",
      "Train loss : 1.7508444341023763\n",
      "Train accuracy: 0.9366666666666666\n",
      "Val loss (all, class, reg): 4.33269998550415\n",
      "Val accuracy: 0.83\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1640  --------------------------\n",
      "Train loss : 1.754488882223765\n",
      "Train accuracy: 0.9283333333333333\n",
      "Val loss (all, class, reg): 4.391366691589355\n",
      "Val accuracy: 0.825\n",
      "Epoch:  1660  --------------------------\n",
      "Train loss : 1.7556888794898986\n",
      "Train accuracy: 0.94\n",
      "Val loss (all, class, reg): 4.401199951171875\n",
      "Val accuracy: 0.815\n",
      "Saving model at  1677  epoch\n",
      "Epoch:  1680  --------------------------\n",
      "Train loss : 1.741944449742635\n",
      "Train accuracy: 0.9283333333333333\n",
      "Val loss (all, class, reg): 4.274833312034607\n",
      "Val accuracy: 0.84\n",
      "Epoch:  1700  --------------------------\n",
      "Train loss : 1.7295444297790528\n",
      "Train accuracy: 0.9333333333333333\n",
      "Val loss (all, class, reg): 4.353233327865601\n",
      "Val accuracy: 0.84\n",
      "Epoch:  1720  --------------------------\n",
      "Train loss : 1.7324666627248129\n",
      "Train accuracy: 0.9366666666666666\n",
      "Val loss (all, class, reg): 4.328933305740357\n",
      "Val accuracy: 0.83\n",
      "Epoch:  1740  --------------------------\n",
      "Train loss : 1.7479999979337058\n",
      "Train accuracy: 0.9316666666666666\n",
      "Val loss (all, class, reg): 4.3552666187286375\n",
      "Val accuracy: 0.825\n",
      "Epoch:  1760  --------------------------\n",
      "Train loss : 1.7260777576764426\n",
      "Train accuracy: 0.935\n",
      "Val loss (all, class, reg): 4.291433281898499\n",
      "Val accuracy: 0.835\n",
      "Epoch:  1780  --------------------------\n",
      "Train loss : 1.7282777690887452\n",
      "Train accuracy: 0.9416666666666667\n",
      "Val loss (all, class, reg): 4.372700023651123\n",
      "Val accuracy: 0.825\n",
      "Epoch:  1800  --------------------------\n",
      "Train loss : 1.7244222140312195\n",
      "Train accuracy: 0.9283333333333333\n",
      "Val loss (all, class, reg): 4.443300018310547\n",
      "Val accuracy: 0.835\n",
      "Saving model at  1812  epoch\n",
      "Epoch:  1820  --------------------------\n",
      "Train loss : 1.7204555503527323\n",
      "Train accuracy: 0.9266666666666666\n",
      "Val loss (all, class, reg): 4.3945333290100095\n",
      "Val accuracy: 0.83\n",
      "Epoch:  1840  --------------------------\n",
      "Train loss : 1.7041444373130799\n",
      "Train accuracy: 0.9366666666666666\n",
      "Val loss (all, class, reg): 4.404499988555909\n",
      "Val accuracy: 0.83\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-6d486a63273d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mloss_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tas_python_env/lib/python3.6/site-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_total_losses=[]\n",
    "train_class_losses=[]\n",
    "\n",
    "val_total_losses=[]\n",
    "val_class_losses=[]\n",
    "\n",
    "test_total_losses=[]\n",
    "test_class_losses=[]\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "val_accs = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(10001):\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    loss_train = 0\n",
    "    for i, (tact, _,  target, label) in enumerate(train_loader):\n",
    "        \n",
    "        tact = tact.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        \n",
    "        tact = net.get_spike(tact)\n",
    "\n",
    "        \n",
    "        output = net.forward(tact)\n",
    "        \n",
    "        correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "        loss = error.numSpikes(output, target)\n",
    "        \n",
    "        loss_train += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "    if epoch%screen_fr == 0:\n",
    "        print('Epoch: ', epoch, ' --------------------------')\n",
    "        print('Train loss :', \n",
    "              loss_train/len(train_dataset))\n",
    "        print('Train accuracy:', correct/len(train_dataset))\n",
    "    train_accs.append(correct/len(train_dataset))\n",
    "    train_total_losses.append(loss_train/len(train_dataset))\n",
    "    \n",
    "#     net.eval()\n",
    "    correct = 0\n",
    "    loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (tact, _, target, label) in enumerate(val_loader):\n",
    "\n",
    "            tact = tact.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            tact = net.get_spike(tact)\n",
    "\n",
    "            output = net.forward(tact)\n",
    "\n",
    "            correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "            loss = error.numSpikes(output, target)\n",
    "\n",
    "            loss_val += loss.item()\n",
    "\n",
    "    #         optimizer.zero_grad()\n",
    "    #         loss.backward()\n",
    "    #         optimizer.step()\n",
    "\n",
    "        \n",
    "    if epoch%screen_fr == 0:\n",
    "        print('Val loss (all, class, reg):', \n",
    "              loss_val/len(val_dataset))\n",
    "        print('Val accuracy:', correct/len(val_dataset))\n",
    "    val_accs.append(correct/len(val_dataset))\n",
    "    val_total_losses.append(loss_val/len(val_dataset))\n",
    "    \n",
    "    if correct/len(val_dataset) >= max_val_acc:\n",
    "        print('Saving model at ', epoch, ' epoch')\n",
    "        max_val_acc = correct/len(val_dataset)\n",
    "        torch.save(net.state_dict(), save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save stats\n",
    "import pickle\n",
    "all_stats = [\n",
    "    train_total_losses,\n",
    "    val_total_losses,\n",
    "    train_accs,\n",
    "    val_accs\n",
    "]\n",
    "\n",
    "pickle.dump(all_stats, open(logDir + model_name + '_stats.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(15,15))\n",
    "\n",
    "ax[0].set_title('Total loss')\n",
    "ax[0].plot(train_total_losses)\n",
    "ax[0].plot(val_total_losses)\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend(['Train', 'Validation'])\n",
    "\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].plot(train_accs)\n",
    "ax[1].plot(val_accs)\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SlayerMLP(\n",
       "  (slayer): spikeLayer()\n",
       "  (fc1): _denseLayer(60, 50, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "  (fc2): _denseLayer(50, 50, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "  (fc3): _denseLayer(50, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing set check\n",
    "net_trained = SlayerMLP(params, 60, 50, 50, 20).to(device)\n",
    "net_trained.load_state_dict(torch.load(save_dir))\n",
    "net_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "loss_test = 0\n",
    "with torch.no_grad():\n",
    "    for i, (tact, _, target, label) in enumerate(test_loader):\n",
    "\n",
    "        tact = tact.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        tact = net.get_spike(tact)\n",
    "        \n",
    "        output = net_trained.forward(tact)\n",
    "\n",
    "        correct += torch.sum(snn.predict.getClass(output) == label).data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825\n"
     ]
    }
   ],
   "source": [
    "print(correct/len(test_loader.dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
