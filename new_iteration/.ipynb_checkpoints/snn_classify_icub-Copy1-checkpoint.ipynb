{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNN on Icub Data\n",
    "\n",
    "Here we implement autoencoder:\n",
    "\n",
    "loss = loss_classification + loss_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "CURRENT_TEST_DIR = os.getcwd()\n",
    "sys.path.append(CURRENT_TEST_DIR + \"/../../../../slayerPytorch/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7713a36d90>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import slayerSNN as snn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tas_utils import get_trainValLoader, get_testLoader\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../../new_data_folder/'\n",
    "logDir = 'models_and_stats/'\n",
    "kfold_number = 0\n",
    "\n",
    "model_name = 'snn_classify_icub_' + str(kfold_number)\n",
    "screen_fr = 20\n",
    "\n",
    "save_dir = logDir + model_name + '.pt'\n",
    "\n",
    "train_loader, val_loader, train_dataset, val_dataset = get_trainValLoader(data_dir, k=0)\n",
    "test_loader, test_dataset = get_testLoader(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define spike neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"neuron\": {\n",
    "        \"type\": \"SRMALPHA\",\n",
    "        \"theta\": 5, # 10\n",
    "        \"tauSr\": 10.0,\n",
    "        \"tauRef\": 2.0,\n",
    "        \"scaleRef\": 2,\n",
    "        \"tauRho\": 1,\n",
    "        \"scaleRho\": 1,\n",
    "    },\n",
    "    \"simulation\": {\"Ts\": 1.0, \"tSample\": 75, \"nSample\": 1},\n",
    "    \"training\": {\n",
    "        \"error\": {\n",
    "            \"type\": \"NumSpikes\",  # \"NumSpikes\" or \"ProbSpikes\"\n",
    "            \"probSlidingWin\": 20,  # only valid for ProbSpikes\n",
    "            \"tgtSpikeRegion\": {  # valid for NumSpikes and ProbSpikes\n",
    "                \"start\": 0,\n",
    "                \"stop\": 75,\n",
    "            },\n",
    "            \"tgtSpikeCount\": {True: 55, False: 15},\n",
    "        }\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_icub_spike(X):\n",
    "    \n",
    "#     # parameters\n",
    "#     C = 0.5\n",
    "#     p_pos = 1 \n",
    "#     p_neg = -1\n",
    "    \n",
    "    \n",
    "#     X = X.squeeze()\n",
    "    \n",
    "#     # nonzero elements -> log\n",
    "#     non_zero_indx = np.where(X > 0)\n",
    "#     log_X = torch.zeros(X.shape)\n",
    "#     log_X[non_zero_indx] = torch.log( X[ non_zero_indx ] )\n",
    "#     x_diff = log_X[..., 1:] - log_X[..., :-1]\n",
    "    \n",
    "#     brightness_diff = torch.cat([log_X[...,0].reshape([log_X.shape[0], log_X.shape[1],1]),  x_diff], dim=2)\n",
    "    \n",
    "#     spike_train_pos = torch.zeros(X.shape)\n",
    "#     spike_train_neg = torch.zeros(X.shape)\n",
    "\n",
    "#     spike_train_pos[brightness_diff >= p_pos*C] = 1\n",
    "#     spike_train_neg[brightness_diff <= p_neg*C] = 1\n",
    "    \n",
    "#     res = torch.cat([spike_train_pos, spike_train_neg], dim=1)\n",
    "    \n",
    "#     return res.reshape(res.shape[0],res.shape[1],1,1,res.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlayerMLP(torch.nn.Module):\n",
    "    def __init__(self, params, input_size, hidden_size1, hidden_size2, output_size):\n",
    "        super(SlayerMLP, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.slayer = snn.layer(params[\"neuron\"], params[\"simulation\"])\n",
    "        self.fc1 = self.slayer.dense(input_size, hidden_size1)\n",
    "        self.fc2 = self.slayer.dense(hidden_size1, hidden_size2)\n",
    "        self.fc3 = self.slayer.dense(hidden_size2, output_size)\n",
    "        \n",
    "    def get_spike(self, inp):\n",
    "        return self.slayer.spike(inp)\n",
    "        \n",
    "    def forward(self, spike_input):\n",
    "        spike_1 = self.slayer.spike(self.slayer.psp(self.fc1(spike_input)))\n",
    "        spike_2 = self.slayer.spike(self.slayer.psp(self.fc2(spike_1)))\n",
    "        spike_output = self.slayer.spike(self.slayer.psp(self.fc3(spike_2)))\n",
    "        \n",
    "        return spike_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\")\n",
    "net = SlayerMLP(params, 60, 50, 50, 20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = snn.loss(params).to(device)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  --------------------------\n",
      "Train loss : 10.910644454956055\n",
      "Train accuracy: 0.115\n",
      "Val loss (all, class, reg): 10.946500091552734\n",
      "Val accuracy: 0.07\n",
      "Saving model at  0  epoch\n",
      "Saving model at  1  epoch\n",
      "Saving model at  2  epoch\n",
      "Saving model at  3  epoch\n",
      "Saving model at  4  epoch\n",
      "Saving model at  5  epoch\n",
      "Saving model at  6  epoch\n",
      "Saving model at  10  epoch\n",
      "Saving model at  12  epoch\n",
      "Saving model at  14  epoch\n",
      "Saving model at  16  epoch\n",
      "Saving model at  17  epoch\n",
      "Epoch:  20  --------------------------\n",
      "Train loss : 8.968511034647623\n",
      "Train accuracy: 0.395\n",
      "Val loss (all, class, reg): 10.200366554260254\n",
      "Val accuracy: 0.235\n",
      "Saving model at  20  epoch\n",
      "Saving model at  21  epoch\n",
      "Saving model at  23  epoch\n",
      "Saving model at  25  epoch\n",
      "Saving model at  26  epoch\n",
      "Saving model at  27  epoch\n",
      "Saving model at  29  epoch\n",
      "Saving model at  34  epoch\n",
      "Saving model at  38  epoch\n",
      "Saving model at  39  epoch\n",
      "Epoch:  40  --------------------------\n",
      "Train loss : 7.729033279418945\n",
      "Train accuracy: 0.625\n",
      "Val loss (all, class, reg): 9.876833419799805\n",
      "Val accuracy: 0.32\n",
      "Saving model at  43  epoch\n",
      "Saving model at  44  epoch\n",
      "Saving model at  47  epoch\n",
      "Saving model at  51  epoch\n",
      "Saving model at  55  epoch\n",
      "Saving model at  59  epoch\n",
      "Epoch:  60  --------------------------\n",
      "Train loss : 6.775077775319417\n",
      "Train accuracy: 0.7383333333333333\n",
      "Val loss (all, class, reg): 9.472133331298828\n",
      "Val accuracy: 0.41\n",
      "Saving model at  60  epoch\n",
      "Saving model at  61  epoch\n",
      "Saving model at  62  epoch\n",
      "Saving model at  63  epoch\n",
      "Saving model at  64  epoch\n",
      "Saving model at  65  epoch\n",
      "Saving model at  69  epoch\n",
      "Epoch:  80  --------------------------\n",
      "Train loss : 6.051233326594035\n",
      "Train accuracy: 0.8366666666666667\n",
      "Val loss (all, class, reg): 9.207533264160157\n",
      "Val accuracy: 0.445\n",
      "Saving model at  82  epoch\n",
      "Epoch:  100  --------------------------\n",
      "Train loss : 5.469188944498698\n",
      "Train accuracy: 0.8766666666666667\n",
      "Val loss (all, class, reg): 9.119533367156983\n",
      "Val accuracy: 0.495\n",
      "Saving model at  100  epoch\n",
      "Saving model at  102  epoch\n",
      "Saving model at  115  epoch\n",
      "Saving model at  119  epoch\n",
      "Epoch:  120  --------------------------\n",
      "Train loss : 4.951655530929566\n",
      "Train accuracy: 0.9216666666666666\n",
      "Val loss (all, class, reg): 8.93873332977295\n",
      "Val accuracy: 0.495\n",
      "Saving model at  125  epoch\n",
      "Saving model at  127  epoch\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-563308209ed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_icub_spike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtact\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtact\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-e2932086dd1e>\u001b[0m in \u001b[0;36mget_icub_spike\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mnon_zero_indx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlog_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mlog_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnon_zero_indx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mnon_zero_indx\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mx_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlog_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_total_losses=[]\n",
    "train_class_losses=[]\n",
    "\n",
    "val_total_losses=[]\n",
    "val_class_losses=[]\n",
    "\n",
    "test_total_losses=[]\n",
    "test_class_losses=[]\n",
    "\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "val_accs = []\n",
    "\n",
    "max_val_acc = 0\n",
    "\n",
    "for epoch in range(10001):\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    loss_train = 0\n",
    "    for i, (tact, _,  target, label) in enumerate(train_loader):\n",
    "        \n",
    "        tact = get_icub_spike(tact)\n",
    "        \n",
    "        tact = tact.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        \n",
    "        output = net.forward(tact)\n",
    "        \n",
    "        correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "        loss = error.numSpikes(output, target)\n",
    "        \n",
    "        loss_train += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "    if epoch%screen_fr == 0:\n",
    "        print('Epoch: ', epoch, ' --------------------------')\n",
    "        print('Train loss :', \n",
    "              loss_train/len(train_dataset))\n",
    "        print('Train accuracy:', correct/len(train_dataset))\n",
    "    train_accs.append(correct/len(train_dataset))\n",
    "    train_total_losses.append(loss_train/len(train_dataset))\n",
    "    \n",
    "#     net.eval()\n",
    "    correct = 0\n",
    "    loss_val = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (tact, _, target, label) in enumerate(val_loader):\n",
    "\n",
    "            tact = get_icub_spike(tact)\n",
    "            \n",
    "            tact = tact.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            \n",
    "\n",
    "            output = net.forward(tact)\n",
    "\n",
    "            correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "            loss = error.numSpikes(output, target)\n",
    "\n",
    "            loss_val += loss.item()\n",
    "\n",
    "    #         optimizer.zero_grad()\n",
    "    #         loss.backward()\n",
    "    #         optimizer.step()\n",
    "\n",
    "        \n",
    "    if epoch%screen_fr == 0:\n",
    "        print('Val loss (all, class, reg):', \n",
    "              loss_val/len(val_dataset))\n",
    "        print('Val accuracy:', correct/len(val_dataset))\n",
    "    val_accs.append(correct/len(val_dataset))\n",
    "    val_total_losses.append(loss_val/len(val_dataset))\n",
    "    \n",
    "    if correct/len(val_dataset) >= max_val_acc:\n",
    "        print('Saving model at ', epoch, ' epoch')\n",
    "        max_val_acc = correct/len(val_dataset)\n",
    "        torch.save(net.state_dict(), save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save stats\n",
    "import pickle\n",
    "all_stats = [\n",
    "    train_total_losses,\n",
    "    val_total_losses,\n",
    "    train_accs,\n",
    "    val_accs\n",
    "]\n",
    "\n",
    "pickle.dump(all_stats, open(logDir + model_name + '_stats.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(15,15))\n",
    "\n",
    "ax[0].set_title('Total loss')\n",
    "ax[0].plot(train_total_losses)\n",
    "ax[0].plot(val_total_losses)\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend(['Train', 'Validation'])\n",
    "\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].plot(train_accs)\n",
    "ax[1].plot(val_accs)\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SlayerMLP(\n",
       "  (slayer): spikeLayer()\n",
       "  (fc1): _denseLayer(60, 50, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "  (fc2): _denseLayer(50, 50, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "  (fc3): _denseLayer(50, 20, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing set check\n",
    "net_trained = SlayerMLP(params, 60, 50, 50, 20).to(device)\n",
    "net_trained.load_state_dict(torch.load(save_dir))\n",
    "net_trained.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "loss_test = 0\n",
    "with torch.no_grad():\n",
    "    for i, (tact, _, target, label) in enumerate(test_loader):\n",
    "\n",
    "        tact = tact.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        tact = net.get_spike(tact)\n",
    "        \n",
    "        output = net_trained.forward(tact)\n",
    "\n",
    "        correct += torch.sum(snn.predict.getClass(output) == label).data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.825\n"
     ]
    }
   ],
   "source": [
    "print(correct/len(test_loader.dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
