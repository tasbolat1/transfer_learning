{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "CURRENT_TEST_DIR = os.getcwd()\n",
    "sys.path.append(CURRENT_TEST_DIR + \"/../../../slayerPytorch/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f72171396d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import slayerSNN as snn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dtw import dtw, accelerated_dtw\n",
    "from numpy.linalg import norm\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import copy\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.load('../BioTac_Icub_data/ICUB_all.pt').numpy()\n",
    "X = X.reshape([1000, 60, 75])\n",
    "Y = np.load('../BioTac_Icub_data/ICUB_all_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 60, 75), (1000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_ = np.zeros((X.shape[0],X.shape[1],X.shape[-1]*2))\n",
    "# X_[...,::2] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 60, 75), (1000,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohe(_Y):\n",
    "    target_class = np.zeros([_Y.shape[0], 20])\n",
    "    for i in range(target_class.shape[0]):\n",
    "        target_class[i, int(_Y[i])] = 1\n",
    "    return target_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], X.shape[1], 1, 1, X.shape[-1])\n",
    "# Y = Y.reshape(Y.shape[0], Y.shape[1], 1, 1, Y.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42, stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([700, 60, 1, 1, 75]),\n",
       " torch.Size([700]),\n",
       " torch.Size([700, 20, 1, 1, 1]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = torch.FloatTensor(X_train)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "\n",
    "target_class_train = torch.FloatTensor(get_ohe(y_train).reshape(-1, 20, 1, 1, 1))\n",
    "    \n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "target_class_test= torch.FloatTensor(get_ohe(y_test).reshape(-1, 20, 1, 1, 1))\n",
    "\n",
    "\n",
    "X_train.shape, y_train.shape, target_class_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"neuron\": {\n",
    "        \"type\": \"SRMALPHA\",\n",
    "        \"theta\": 5, # 10, 5(best)\n",
    "        \"tauSr\": 10.0,\n",
    "        \"tauRef\": 2.0,\n",
    "        \"scaleRef\": 2,\n",
    "        \"tauRho\": 1,\n",
    "        \"scaleRho\": 1,\n",
    "    },\n",
    "    \"simulation\": {\"Ts\": 1.0, \"tSample\": 150, \"nSample\": 1},\n",
    "    \"training\": {\n",
    "        \"error\": {\n",
    "            \"type\": \"NumSpikes\",  # \"NumSpikes\" or \"ProbSpikes\"\n",
    "            \"probSlidingWin\": 20,  # only valid for ProbSpikes\n",
    "            \"tgtSpikeRegion\": {  # valid for NumSpikes and ProbSpikes\n",
    "                \"start\": 0,\n",
    "                \"stop\": 150,\n",
    "            },\n",
    "            \"tgtSpikeCount\": {True: 125, False: 20},\n",
    "        }\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torch.utils.data.TensorDataset(X_train, target_class_train, y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,shuffle=True,batch_size=8)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(X_test, target_class_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,shuffle=True,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlayerMLP(torch.nn.Module):\n",
    "    def __init__(self, params, input_size, hidden_size1,hidden_size2, output_size):\n",
    "        super(SlayerMLP, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.slayer = snn.layer(params[\"neuron\"], params[\"simulation\"])\n",
    "        self.fc1 = self.slayer.dense(60, hidden_size1)\n",
    "        self.fc2 = self.slayer.dense(hidden_size1, hidden_size2)\n",
    "        self.fc3 = self.slayer.dense(hidden_size2, output_size)\n",
    "\n",
    "    def get_spike(self, inp):\n",
    "        return self.slayer.spike(inp)\n",
    "    def forward(self, spike_input):\n",
    "        spike_1 = self.slayer.spike(self.slayer.psp(self.fc1(spike_input)))\n",
    "        spike_2 = self.slayer.spike(self.slayer.psp(self.fc2(spike_1)))\n",
    "        spike_output = self.slayer.spike(self.slayer.psp(self.fc3(spike_2)))\n",
    "        return spike_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class SlayerMLP(torch.nn.Module):\n",
    "#     def __init__(self, params, input_size, hidden_size, output_size):\n",
    "#         super(SlayerMLP, self).__init__()\n",
    "#         self.output_size = output_size\n",
    "#         self.slayer = snn.layer(params[\"neuron\"], params[\"simulation\"])\n",
    "# #         self.fc1 = self.slayer.dense((1,10,6), hidden_size)\n",
    "#         self.fc = self.slayer.dense((9,5,3), output_size)\n",
    "#         self.conv1 = self.slayer.conv(1, 3, 2)\n",
    "\n",
    "#     def forward(self, spike_input):\n",
    "#         spike1 = self.slayer.spike(self.conv1(spike_input))\n",
    "# #         print(spike1.shape)\n",
    "#         spike3 = self.slayer.spike(self.fc(self.slayer.psp(spike1)))\n",
    "# #         print(spike3.shape)\n",
    "# #         spike_1 = self.slayer.spike(self.fc1(spike_input))\n",
    "# #         spike_output = self.slayer.spike(self.slayer.psp(self.fc2(spike_1)))\n",
    "#         return spike3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "net = SlayerMLP(params, 19, 50, 50, 20).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = snn.loss(params).to(device)\n",
    "optimizer = torch.optim.RMSprop(net.parameters(), lr=0.001, weight_decay=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21142857142857144"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "148/len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0  --------------------------\n",
      "Train loss: 55.964625309535435\n",
      "Train accuracy: 0.07285714285714286\n",
      "Test loss: 49.404400939941404\n",
      "Test accuracy: 0.12666666666666668\n",
      "Epoch:  10  --------------------------\n",
      "Train loss: 28.277718952723912\n",
      "Train accuracy: 0.58\n",
      "Test loss: 28.73793347676595\n",
      "Test accuracy: 0.6033333333333334\n",
      "Epoch:  20  --------------------------\n",
      "Train loss: 22.510399992806573\n",
      "Train accuracy: 0.7285714285714285\n",
      "Test loss: 23.988877716064454\n",
      "Test accuracy: 0.6733333333333333\n",
      "Epoch:  30  --------------------------\n",
      "Train loss: 19.335552313668387\n",
      "Train accuracy: 0.75\n",
      "Test loss: 21.36278902689616\n",
      "Test accuracy: 0.7033333333333334\n",
      "Epoch:  40  --------------------------\n",
      "Train loss: 17.547895311628068\n",
      "Train accuracy: 0.7828571428571428\n",
      "Test loss: 19.872877718607583\n",
      "Test accuracy: 0.7\n",
      "Epoch:  50  --------------------------\n",
      "Train loss: 16.25632377079555\n",
      "Train accuracy: 0.8\n",
      "Test loss: 18.798322092692057\n",
      "Test accuracy: 0.73\n",
      "Epoch:  60  --------------------------\n",
      "Train loss: 15.292947622026716\n",
      "Train accuracy: 0.8157142857142857\n",
      "Test loss: 18.087232971191405\n",
      "Test accuracy: 0.7433333333333333\n",
      "Epoch:  70  --------------------------\n",
      "Train loss: 14.39760947091239\n",
      "Train accuracy: 0.83\n",
      "Test loss: 17.376855456034342\n",
      "Test accuracy: 0.73\n",
      "Epoch:  80  --------------------------\n",
      "Train loss: 13.727790189470564\n",
      "Train accuracy: 0.8357142857142857\n",
      "Test loss: 16.771722106933595\n",
      "Test accuracy: 0.75\n",
      "Epoch:  90  --------------------------\n",
      "Train loss: 13.120580918448312\n",
      "Train accuracy: 0.8442857142857143\n",
      "Test loss: 16.370744387308758\n",
      "Test accuracy: 0.76\n",
      "Epoch:  100  --------------------------\n",
      "Train loss: 12.717304785592216\n",
      "Train accuracy: 0.8571428571428571\n",
      "Test loss: 15.860699831644695\n",
      "Test accuracy: 0.7733333333333333\n",
      "Epoch:  110  --------------------------\n",
      "Train loss: 12.369819006238664\n",
      "Train accuracy: 0.8542857142857143\n",
      "Test loss: 15.603799743652344\n",
      "Test accuracy: 0.78\n",
      "Epoch:  120  --------------------------\n",
      "Train loss: 11.956876291547502\n",
      "Train accuracy: 0.8642857142857143\n",
      "Test loss: 15.377666575113933\n",
      "Test accuracy: 0.7833333333333333\n",
      "Epoch:  130  --------------------------\n",
      "Train loss: 11.662519013541086\n",
      "Train accuracy: 0.8728571428571429\n",
      "Test loss: 14.787622248331706\n",
      "Test accuracy: 0.8\n",
      "Epoch:  140  --------------------------\n",
      "Train loss: 11.365690552847726\n",
      "Train accuracy: 0.87\n",
      "Test loss: 14.696222229003906\n",
      "Test accuracy: 0.7866666666666666\n",
      "Epoch:  150  --------------------------\n",
      "Train loss: 11.007299992697579\n",
      "Train accuracy: 0.8742857142857143\n",
      "Test loss: 14.297577641805013\n",
      "Test accuracy: 0.8066666666666666\n",
      "Epoch:  160  --------------------------\n",
      "Train loss: 10.676142935071672\n",
      "Train accuracy: 0.8728571428571429\n",
      "Test loss: 13.987255605061849\n",
      "Test accuracy: 0.8033333333333333\n",
      "Epoch:  170  --------------------------\n",
      "Train loss: 10.429061878749302\n",
      "Train accuracy: 0.8828571428571429\n",
      "Test loss: 13.771444333394369\n",
      "Test accuracy: 0.8066666666666666\n",
      "Epoch:  180  --------------------------\n",
      "Train loss: 10.120185606820243\n",
      "Train accuracy: 0.8785714285714286\n",
      "Test loss: 13.626166559855143\n",
      "Test accuracy: 0.8066666666666666\n",
      "Epoch:  190  --------------------------\n",
      "Train loss: 9.963242776053292\n",
      "Train accuracy: 0.8785714285714286\n",
      "Test loss: 13.123577791849772\n",
      "Test accuracy: 0.8133333333333334\n",
      "Epoch:  200  --------------------------\n",
      "Train loss: 9.75868089403425\n",
      "Train accuracy: 0.8857142857142857\n",
      "Test loss: 13.131133289337159\n",
      "Test accuracy: 0.8033333333333333\n",
      "Epoch:  210  --------------------------\n",
      "Train loss: 9.53554757799421\n",
      "Train accuracy: 0.8857142857142857\n",
      "Test loss: 12.746144307454427\n",
      "Test accuracy: 0.8133333333333334\n",
      "Epoch:  220  --------------------------\n",
      "Train loss: 9.40766656603132\n",
      "Train accuracy: 0.8942857142857142\n",
      "Test loss: 12.702222226460774\n",
      "Test accuracy: 0.8133333333333334\n",
      "Epoch:  230  --------------------------\n",
      "Train loss: 9.249957103729248\n",
      "Train accuracy: 0.8857142857142857\n",
      "Test loss: 12.510188598632812\n",
      "Test accuracy: 0.8233333333333334\n",
      "Epoch:  240  --------------------------\n",
      "Train loss: 9.1218285042899\n",
      "Train accuracy: 0.8871428571428571\n",
      "Test loss: 12.377344512939453\n",
      "Test accuracy: 0.82\n",
      "Epoch:  250  --------------------------\n",
      "Train loss: 8.97643808364868\n",
      "Train accuracy: 0.8871428571428571\n",
      "Test loss: 12.336511154174804\n",
      "Test accuracy: 0.8233333333333334\n",
      "Epoch:  260  --------------------------\n",
      "Train loss: 8.881066695622035\n",
      "Train accuracy: 0.89\n",
      "Test loss: 12.200444456736246\n",
      "Test accuracy: 0.83\n",
      "Epoch:  270  --------------------------\n",
      "Train loss: 8.766923798152378\n",
      "Train accuracy: 0.89\n",
      "Test loss: 12.049499994913736\n",
      "Test accuracy: 0.82\n",
      "Epoch:  280  --------------------------\n",
      "Train loss: 8.649338011060442\n",
      "Train accuracy: 0.89\n",
      "Test loss: 11.874399859110515\n",
      "Test accuracy: 0.8233333333333334\n",
      "Epoch:  290  --------------------------\n",
      "Train loss: 8.542361957005092\n",
      "Train accuracy: 0.9042857142857142\n",
      "Test loss: 11.899855486551921\n",
      "Test accuracy: 0.8266666666666667\n",
      "Epoch:  300  --------------------------\n",
      "Train loss: 8.4743095098223\n",
      "Train accuracy: 0.8871428571428571\n",
      "Test loss: 11.873799832661946\n",
      "Test accuracy: 0.8166666666666667\n",
      "Epoch:  310  --------------------------\n",
      "Train loss: 8.391128461020333\n",
      "Train accuracy: 0.89\n",
      "Test loss: 11.73171095530192\n",
      "Test accuracy: 0.8233333333333334\n",
      "Epoch:  320  --------------------------\n",
      "Train loss: 8.34228095463344\n",
      "Train accuracy: 0.8957142857142857\n",
      "Test loss: 11.888722089131674\n",
      "Test accuracy: 0.84\n",
      "Epoch:  330  --------------------------\n",
      "Train loss: 8.249885657174246\n",
      "Train accuracy: 0.9\n",
      "Test loss: 11.540321922302246\n",
      "Test accuracy: 0.84\n",
      "Epoch:  340  --------------------------\n",
      "Train loss: 8.184247564588274\n",
      "Train accuracy: 0.8985714285714286\n",
      "Test loss: 11.587288780212402\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  350  --------------------------\n",
      "Train loss: 8.046538045065743\n",
      "Train accuracy: 0.9028571428571428\n",
      "Test loss: 11.878499870300294\n",
      "Test accuracy: 0.8233333333333334\n",
      "Epoch:  360  --------------------------\n",
      "Train loss: 7.9781428228105815\n",
      "Train accuracy: 0.9028571428571428\n",
      "Test loss: 11.422322133382162\n",
      "Test accuracy: 0.8333333333333334\n",
      "Epoch:  370  --------------------------\n",
      "Train loss: 7.915199986866543\n",
      "Train accuracy: 0.9028571428571428\n",
      "Test loss: 11.327111002604166\n",
      "Test accuracy: 0.83\n",
      "Epoch:  380  --------------------------\n",
      "Train loss: 7.861399977547782\n",
      "Train accuracy: 0.9014285714285715\n",
      "Test loss: 11.26221082051595\n",
      "Test accuracy: 0.84\n",
      "Epoch:  390  --------------------------\n",
      "Train loss: 7.782233273642404\n",
      "Train accuracy: 0.9028571428571428\n",
      "Test loss: 11.406911201477051\n",
      "Test accuracy: 0.84\n",
      "Epoch:  400  --------------------------\n",
      "Train loss: 7.71369521686009\n",
      "Train accuracy: 0.9028571428571428\n",
      "Test loss: 11.36255537668864\n",
      "Test accuracy: 0.8366666666666667\n",
      "Epoch:  410  --------------------------\n",
      "Train loss: 7.676152373722621\n",
      "Train accuracy: 0.9042857142857142\n",
      "Test loss: 11.306833254496256\n",
      "Test accuracy: 0.8366666666666667\n",
      "Epoch:  420  --------------------------\n",
      "Train loss: 7.539614278248378\n",
      "Train accuracy: 0.9114285714285715\n",
      "Test loss: 11.281888732910156\n",
      "Test accuracy: 0.8333333333333334\n",
      "Epoch:  430  --------------------------\n",
      "Train loss: 7.4866570949554445\n",
      "Train accuracy: 0.9071428571428571\n",
      "Test loss: 11.139988814989726\n",
      "Test accuracy: 0.84\n",
      "Epoch:  440  --------------------------\n",
      "Train loss: 7.539961902073451\n",
      "Train accuracy: 0.9014285714285715\n",
      "Test loss: 11.141644376118977\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  450  --------------------------\n",
      "Train loss: 7.457399978637695\n",
      "Train accuracy: 0.9\n",
      "Test loss: 11.186755479176838\n",
      "Test accuracy: 0.84\n",
      "Epoch:  460  --------------------------\n",
      "Train loss: 7.368480905805315\n",
      "Train accuracy: 0.9057142857142857\n",
      "Test loss: 11.229699961344402\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  470  --------------------------\n",
      "Train loss: 7.3221475137983045\n",
      "Train accuracy: 0.9128571428571428\n",
      "Test loss: 11.282899831136067\n",
      "Test accuracy: 0.8466666666666667\n",
      "Epoch:  480  --------------------------\n",
      "Train loss: 7.288704697745187\n",
      "Train accuracy: 0.9114285714285715\n",
      "Test loss: 11.012933286031087\n",
      "Test accuracy: 0.8366666666666667\n",
      "Epoch:  490  --------------------------\n",
      "Train loss: 7.20044765336173\n",
      "Train accuracy: 0.9157142857142857\n",
      "Test loss: 11.2000665918986\n",
      "Test accuracy: 0.8366666666666667\n",
      "Epoch:  500  --------------------------\n",
      "Train loss: 7.181209482465472\n",
      "Train accuracy: 0.9071428571428571\n",
      "Test loss: 11.092977517445883\n",
      "Test accuracy: 0.8433333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  510  --------------------------\n",
      "Train loss: 7.1223857239314485\n",
      "Train accuracy: 0.9114285714285715\n",
      "Test loss: 10.882566579182942\n",
      "Test accuracy: 0.85\n",
      "Epoch:  520  --------------------------\n",
      "Train loss: 7.079233293533325\n",
      "Train accuracy: 0.9114285714285715\n",
      "Test loss: 11.187655321757\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  530  --------------------------\n",
      "Train loss: 7.024404719216483\n",
      "Train accuracy: 0.9171428571428571\n",
      "Test loss: 11.091722202301025\n",
      "Test accuracy: 0.85\n",
      "Epoch:  540  --------------------------\n",
      "Train loss: 6.944238064629691\n",
      "Train accuracy: 0.92\n",
      "Test loss: 10.970944493611654\n",
      "Test accuracy: 0.84\n",
      "Epoch:  550  --------------------------\n",
      "Train loss: 6.922357147761754\n",
      "Train accuracy: 0.9142857142857143\n",
      "Test loss: 10.915933268864949\n",
      "Test accuracy: 0.8433333333333334\n",
      "Epoch:  560  --------------------------\n",
      "Train loss: 6.925709500994001\n",
      "Train accuracy: 0.9128571428571428\n",
      "Test loss: 11.000188808441163\n",
      "Test accuracy: 0.85\n",
      "Epoch:  570  --------------------------\n",
      "Train loss: 6.884614324569702\n",
      "Train accuracy: 0.9157142857142857\n",
      "Test loss: 10.88021099726359\n",
      "Test accuracy: 0.84\n",
      "Epoch:  580  --------------------------\n",
      "Train loss: 6.818709513800485\n",
      "Train accuracy: 0.9171428571428571\n",
      "Test loss: 10.949777723948161\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  590  --------------------------\n",
      "Train loss: 6.769452366147722\n",
      "Train accuracy: 0.9185714285714286\n",
      "Test loss: 10.830821971893311\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  600  --------------------------\n",
      "Train loss: 6.7230142402648925\n",
      "Train accuracy: 0.92\n",
      "Test loss: 10.821277612050375\n",
      "Test accuracy: 0.84\n",
      "Epoch:  610  --------------------------\n",
      "Train loss: 6.7236666570390975\n",
      "Train accuracy: 0.9171428571428571\n",
      "Test loss: 10.855022188822428\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  620  --------------------------\n",
      "Train loss: 6.6724904441833495\n",
      "Train accuracy: 0.9214285714285714\n",
      "Test loss: 10.6304332224528\n",
      "Test accuracy: 0.85\n",
      "Epoch:  630  --------------------------\n",
      "Train loss: 6.629119041987828\n",
      "Train accuracy: 0.92\n",
      "Test loss: 10.732222315470377\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  640  --------------------------\n",
      "Train loss: 6.633385768617902\n",
      "Train accuracy: 0.9228571428571428\n",
      "Test loss: 10.684255498250325\n",
      "Test accuracy: 0.85\n",
      "Epoch:  650  --------------------------\n",
      "Train loss: 6.587600026811872\n",
      "Train accuracy: 0.92\n",
      "Test loss: 10.634310963948568\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  660  --------------------------\n",
      "Train loss: 6.521800000326974\n",
      "Train accuracy: 0.92\n",
      "Test loss: 10.914233538309732\n",
      "Test accuracy: 0.86\n",
      "Epoch:  670  --------------------------\n",
      "Train loss: 6.511966631753104\n",
      "Train accuracy: 0.9242857142857143\n",
      "Test loss: 10.703711115519205\n",
      "Test accuracy: 0.86\n",
      "Epoch:  680  --------------------------\n",
      "Train loss: 6.463919030598232\n",
      "Train accuracy: 0.9228571428571428\n",
      "Test loss: 10.59306658744812\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  690  --------------------------\n",
      "Train loss: 6.421385691506522\n",
      "Train accuracy: 0.9242857142857143\n",
      "Test loss: 10.413944384256999\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  700  --------------------------\n",
      "Train loss: 6.389747581481934\n",
      "Train accuracy: 0.9228571428571428\n",
      "Test loss: 10.477799990971883\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  710  --------------------------\n",
      "Train loss: 6.370233365467617\n",
      "Train accuracy: 0.9228571428571428\n",
      "Test loss: 10.644788875579835\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  720  --------------------------\n",
      "Train loss: 6.335861917223249\n",
      "Train accuracy: 0.9228571428571428\n",
      "Test loss: 10.56264440536499\n",
      "Test accuracy: 0.85\n",
      "Epoch:  730  --------------------------\n",
      "Train loss: 6.304261905125209\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss: 10.4703333791097\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  740  --------------------------\n",
      "Train loss: 6.279938109261649\n",
      "Train accuracy: 0.9214285714285714\n",
      "Test loss: 10.49697790781657\n",
      "Test accuracy: 0.86\n",
      "Epoch:  750  --------------------------\n",
      "Train loss: 6.280495247159686\n",
      "Train accuracy: 0.9228571428571428\n",
      "Test loss: 10.541455510457357\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  760  --------------------------\n",
      "Train loss: 6.242938041687012\n",
      "Train accuracy: 0.9242857142857143\n",
      "Test loss: 10.555811182657878\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  770  --------------------------\n",
      "Train loss: 6.215171440669469\n",
      "Train accuracy: 0.9271428571428572\n",
      "Test loss: 10.608566551208495\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  780  --------------------------\n",
      "Train loss: 6.168952375139509\n",
      "Train accuracy: 0.9214285714285714\n",
      "Test loss: 10.483388862609864\n",
      "Test accuracy: 0.86\n",
      "Epoch:  790  --------------------------\n",
      "Train loss: 6.152190465927124\n",
      "Train accuracy: 0.9257142857142857\n",
      "Test loss: 10.509944547017415\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  800  --------------------------\n",
      "Train loss: 6.116519014494759\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss: 10.69146661758423\n",
      "Test accuracy: 0.86\n",
      "Epoch:  810  --------------------------\n",
      "Train loss: 6.135614268439157\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss: 10.398199876149496\n",
      "Test accuracy: 0.86\n",
      "Epoch:  820  --------------------------\n",
      "Train loss: 6.118176236152649\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss: 10.30697764078776\n",
      "Test accuracy: 0.86\n",
      "Epoch:  830  --------------------------\n",
      "Train loss: 6.099557121821812\n",
      "Train accuracy: 0.9185714285714286\n",
      "Test loss: 10.493966668446859\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  840  --------------------------\n",
      "Train loss: 6.051580976758684\n",
      "Train accuracy: 0.93\n",
      "Test loss: 10.465866711934408\n",
      "Test accuracy: 0.86\n",
      "Epoch:  850  --------------------------\n",
      "Train loss: 6.0163190610068185\n",
      "Train accuracy: 0.9257142857142857\n",
      "Test loss: 10.625300057729085\n",
      "Test accuracy: 0.86\n",
      "Epoch:  860  --------------------------\n",
      "Train loss: 6.002538061141967\n",
      "Train accuracy: 0.9257142857142857\n",
      "Test loss: 10.37393310546875\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  870  --------------------------\n",
      "Train loss: 5.971661831992013\n",
      "Train accuracy: 0.93\n",
      "Test loss: 10.706166687011718\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  880  --------------------------\n",
      "Train loss: 5.971866722106934\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss: 10.45346664428711\n",
      "Test accuracy: 0.85\n",
      "Epoch:  890  --------------------------\n",
      "Train loss: 5.994033328465053\n",
      "Train accuracy: 0.93\n",
      "Test loss: 10.528655548095703\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  900  --------------------------\n",
      "Train loss: 5.939928571156093\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.400155474344889\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  910  --------------------------\n",
      "Train loss: 5.937090508597238\n",
      "Train accuracy: 0.93\n",
      "Test loss: 10.408488788604735\n",
      "Test accuracy: 0.86\n",
      "Epoch:  920  --------------------------\n",
      "Train loss: 5.899828544344221\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss: 10.40302227973938\n",
      "Test accuracy: 0.86\n",
      "Epoch:  930  --------------------------\n",
      "Train loss: 5.9034714644295825\n",
      "Train accuracy: 0.9242857142857143\n",
      "Test loss: 10.30391108194987\n",
      "Test accuracy: 0.86\n",
      "Epoch:  940  --------------------------\n",
      "Train loss: 5.851752422877721\n",
      "Train accuracy: 0.9257142857142857\n",
      "Test loss: 10.164355411529542\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  950  --------------------------\n",
      "Train loss: 5.8424714687892365\n",
      "Train accuracy: 0.93\n",
      "Test loss: 10.284233360290527\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  960  --------------------------\n",
      "Train loss: 5.854723747798375\n",
      "Train accuracy: 0.9214285714285714\n",
      "Test loss: 10.223822085062663\n",
      "Test accuracy: 0.86\n",
      "Epoch:  970  --------------------------\n",
      "Train loss: 5.854704701559884\n",
      "Train accuracy: 0.9242857142857143\n",
      "Test loss: 10.287922331492107\n",
      "Test accuracy: 0.8533333333333334\n",
      "Epoch:  980  --------------------------\n",
      "Train loss: 5.820004709788731\n",
      "Train accuracy: 0.93\n",
      "Test loss: 10.38807767868042\n",
      "Test accuracy: 0.86\n",
      "Epoch:  990  --------------------------\n",
      "Train loss: 5.788857077189855\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss: 10.246522286732992\n",
      "Test accuracy: 0.85\n",
      "Epoch:  1000  --------------------------\n",
      "Train loss: 5.760361886705671\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss: 10.30544443766276\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1010  --------------------------\n",
      "Train loss: 5.741771354675293\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss: 10.087144343058268\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1020  --------------------------\n",
      "Train loss: 5.7371809128352576\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.35990006128947\n",
      "Test accuracy: 0.8633333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1030  --------------------------\n",
      "Train loss: 5.742209493773324\n",
      "Train accuracy: 0.94\n",
      "Test loss: 10.241999966303508\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1040  --------------------------\n",
      "Train loss: 5.705642786026001\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.272788887023927\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1050  --------------------------\n",
      "Train loss: 5.675247595650809\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.182633190155029\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1060  --------------------------\n",
      "Train loss: 5.646066586630685\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss: 10.234921925862631\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1070  --------------------------\n",
      "Train loss: 5.654557138170515\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss: 10.28347791671753\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1080  --------------------------\n",
      "Train loss: 5.625995205470494\n",
      "Train accuracy: 0.94\n",
      "Test loss: 10.08033322652181\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1090  --------------------------\n",
      "Train loss: 5.60556191444397\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.281066656112671\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1100  --------------------------\n",
      "Train loss: 5.588976167951311\n",
      "Train accuracy: 0.93\n",
      "Test loss: 10.25757776260376\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1110  --------------------------\n",
      "Train loss: 5.605533334187099\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss: 10.1367112159729\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1120  --------------------------\n",
      "Train loss: 5.600152405330113\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.15261108716329\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1130  --------------------------\n",
      "Train loss: 5.565538108008249\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.155644391377766\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1140  --------------------------\n",
      "Train loss: 5.506004695892334\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.073122240702311\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1150  --------------------------\n",
      "Train loss: 5.521585730143956\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.126977818806965\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1160  --------------------------\n",
      "Train loss: 5.499347584588187\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.159788697560629\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1170  --------------------------\n",
      "Train loss: 5.497809491838727\n",
      "Train accuracy: 0.9285714285714286\n",
      "Test loss: 10.140377616882324\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1180  --------------------------\n",
      "Train loss: 5.489818983078003\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.315810931523641\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1190  --------------------------\n",
      "Train loss: 5.459585651670183\n",
      "Train accuracy: 0.93\n",
      "Test loss: 10.033355439503987\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1200  --------------------------\n",
      "Train loss: 5.4296571799686975\n",
      "Train accuracy: 0.94\n",
      "Test loss: 10.002944405873617\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1210  --------------------------\n",
      "Train loss: 5.408966667992728\n",
      "Train accuracy: 0.94\n",
      "Test loss: 10.048244222005208\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1220  --------------------------\n",
      "Train loss: 5.3920428112574985\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss: 10.154944534301757\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1230  --------------------------\n",
      "Train loss: 5.3992380401066375\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.114188925425212\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1240  --------------------------\n",
      "Train loss: 5.3684571184430805\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss: 10.086488793691\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1250  --------------------------\n",
      "Train loss: 5.364209474836077\n",
      "Train accuracy: 0.93\n",
      "Test loss: 9.987033297220865\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1260  --------------------------\n",
      "Train loss: 5.3279666996002195\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.157155380249023\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1270  --------------------------\n",
      "Train loss: 5.325695242200579\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.009733276367188\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1280  --------------------------\n",
      "Train loss: 5.288699984550476\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss: 10.10871109008789\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1290  --------------------------\n",
      "Train loss: 5.294433306285313\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.97296661376953\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1300  --------------------------\n",
      "Train loss: 5.27190002305167\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 9.9747886912028\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1310  --------------------------\n",
      "Train loss: 5.267842832292829\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.135255661010742\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1320  --------------------------\n",
      "Train loss: 5.233695165089198\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.097522188822428\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1330  --------------------------\n",
      "Train loss: 5.242371384756906\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.22611115137736\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1340  --------------------------\n",
      "Train loss: 5.245218997682844\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.073766479492187\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1350  --------------------------\n",
      "Train loss: 5.1934761129106795\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.096166648864745\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1360  --------------------------\n",
      "Train loss: 5.204128556932722\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.008388849894205\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1370  --------------------------\n",
      "Train loss: 5.177142903464181\n",
      "Train accuracy: 0.9271428571428572\n",
      "Test loss: 10.097744566599529\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1380  --------------------------\n",
      "Train loss: 5.202414324624198\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.201244424184164\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1390  --------------------------\n",
      "Train loss: 5.131633363451276\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.135666516621908\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1400  --------------------------\n",
      "Train loss: 5.194319073813302\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.039088973999023\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1410  --------------------------\n",
      "Train loss: 5.185728548594883\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss: 10.018199961980184\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1420  --------------------------\n",
      "Train loss: 5.135347610201155\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 10.165022144317627\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1430  --------------------------\n",
      "Train loss: 5.138885671070644\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.051155506769817\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1440  --------------------------\n",
      "Train loss: 5.1454523686000275\n",
      "Train accuracy: 0.9271428571428572\n",
      "Test loss: 10.21071102778117\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1450  --------------------------\n",
      "Train loss: 5.098657121658325\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.954377657572428\n",
      "Test accuracy: 0.8566666666666667\n",
      "Epoch:  1460  --------------------------\n",
      "Train loss: 5.096352430752345\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.102999986012776\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1470  --------------------------\n",
      "Train loss: 5.059609505789621\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.083899873097737\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1480  --------------------------\n",
      "Train loss: 5.062290445055281\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss: 10.072855644226074\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1490  --------------------------\n",
      "Train loss: 5.072438072477068\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.11159995396932\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1500  --------------------------\n",
      "Train loss: 5.052138069697789\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.078655462265015\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1510  --------------------------\n",
      "Train loss: 5.049085667473929\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss: 10.1572110303243\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1520  --------------------------\n",
      "Train loss: 5.028842901502337\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 10.1861443456014\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1530  --------------------------\n",
      "Train loss: 5.038738064084734\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.410888799031575\n",
      "Test accuracy: 0.8766666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1540  --------------------------\n",
      "Train loss: 5.063738053185599\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.119833285013835\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1550  --------------------------\n",
      "Train loss: 5.010471447535924\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 10.158966852823893\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1560  --------------------------\n",
      "Train loss: 4.989776216234479\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.20884448369344\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1570  --------------------------\n",
      "Train loss: 5.010509519917624\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss: 10.045133228302001\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1580  --------------------------\n",
      "Train loss: 5.0383332797459195\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.161622295379638\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1590  --------------------------\n",
      "Train loss: 4.997752275466919\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss: 10.046055577596029\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1600  --------------------------\n",
      "Train loss: 4.972542867660523\n",
      "Train accuracy: 0.9328571428571428\n",
      "Test loss: 10.114111200968425\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1610  --------------------------\n",
      "Train loss: 4.988695212772915\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.06332218170166\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1620  --------------------------\n",
      "Train loss: 4.9764381054469515\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.142433191935222\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1630  --------------------------\n",
      "Train loss: 4.948409555980137\n",
      "Train accuracy: 0.94\n",
      "Test loss: 10.01755558649699\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1640  --------------------------\n",
      "Train loss: 4.989328523363386\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.061822312672932\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1650  --------------------------\n",
      "Train loss: 4.9678762326921735\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.080833282470703\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1660  --------------------------\n",
      "Train loss: 4.924561967168535\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 10.130188906987508\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1670  --------------------------\n",
      "Train loss: 4.893442762919834\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 10.12208885828654\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1680  --------------------------\n",
      "Train loss: 4.954971422467913\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.014533271789551\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1690  --------------------------\n",
      "Train loss: 4.9088047449929375\n",
      "Train accuracy: 0.94\n",
      "Test loss: 10.066833227475485\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1700  --------------------------\n",
      "Train loss: 4.909695192064558\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.998333282470703\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1710  --------------------------\n",
      "Train loss: 4.895652403150286\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 10.04327760696411\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1720  --------------------------\n",
      "Train loss: 4.89925710950579\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 10.086522280375164\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1730  --------------------------\n",
      "Train loss: 4.881138061795916\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.036811049779256\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1740  --------------------------\n",
      "Train loss: 4.847423753738403\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.064755535125732\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1750  --------------------------\n",
      "Train loss: 4.843552303314209\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 9.957255433400473\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1760  --------------------------\n",
      "Train loss: 4.848023839678083\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 10.041433378855388\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1770  --------------------------\n",
      "Train loss: 4.869019062859672\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 10.012999871571859\n",
      "Test accuracy: 0.86\n",
      "Epoch:  1780  --------------------------\n",
      "Train loss: 4.844604707445417\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 10.088588848114014\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1790  --------------------------\n",
      "Train loss: 4.809780909674508\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.041722100575765\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1800  --------------------------\n",
      "Train loss: 4.889061876024519\n",
      "Train accuracy: 0.9314285714285714\n",
      "Test loss: 10.061166756947836\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1810  --------------------------\n",
      "Train loss: 4.827142782211304\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.066633332570394\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1820  --------------------------\n",
      "Train loss: 4.820385759898595\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 10.008966547648113\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1830  --------------------------\n",
      "Train loss: 4.82218092918396\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.073844356536865\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1840  --------------------------\n",
      "Train loss: 4.76235234941755\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.069377689361572\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1850  --------------------------\n",
      "Train loss: 4.768776187896728\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 10.072766615549723\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  1860  --------------------------\n",
      "Train loss: 4.7748285525185725\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.110322284698487\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1870  --------------------------\n",
      "Train loss: 4.803766651153564\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 10.081322345733643\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1880  --------------------------\n",
      "Train loss: 4.778404753548759\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 10.027288729349772\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1890  --------------------------\n",
      "Train loss: 4.796099927084787\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 10.03811122894287\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1900  --------------------------\n",
      "Train loss: 4.7585618775231495\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 10.074255638122558\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1910  --------------------------\n",
      "Train loss: 4.75599043573652\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.975288829803468\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1920  --------------------------\n",
      "Train loss: 4.767823760168893\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 10.009866860707602\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1930  --------------------------\n",
      "Train loss: 4.705519060407366\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.8352556737264\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1940  --------------------------\n",
      "Train loss: 4.721147616250175\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 9.936766821543376\n",
      "Test accuracy: 0.87\n",
      "Epoch:  1950  --------------------------\n",
      "Train loss: 4.711538061414446\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.977666772206625\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1960  --------------------------\n",
      "Train loss: 4.7195237963540215\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 10.049222138722739\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1970  --------------------------\n",
      "Train loss: 4.728428589957101\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 10.178500061035157\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  1980  --------------------------\n",
      "Train loss: 4.725004727499826\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.931444530487061\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  1990  --------------------------\n",
      "Train loss: 4.678219051361084\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 10.116255518595377\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2000  --------------------------\n",
      "Train loss: 4.681576196125575\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 10.012866694132487\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2010  --------------------------\n",
      "Train loss: 4.705676171439035\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.9895667997996\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2020  --------------------------\n",
      "Train loss: 4.699528537477765\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.822433389027914\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2030  --------------------------\n",
      "Train loss: 4.666719048363822\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 10.179522075653075\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2040  --------------------------\n",
      "Train loss: 4.691842824390957\n",
      "Train accuracy: 0.9442857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 10.053599971135457\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2050  --------------------------\n",
      "Train loss: 4.684971440179007\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.897188886006672\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2060  --------------------------\n",
      "Train loss: 4.672642827033997\n",
      "Train accuracy: 0.9342857142857143\n",
      "Test loss: 9.89172223409017\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2070  --------------------------\n",
      "Train loss: 4.670785699571882\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.76927765528361\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2080  --------------------------\n",
      "Train loss: 4.609771453993661\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.88362227121989\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2090  --------------------------\n",
      "Train loss: 4.622752379008702\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.898222325642903\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2100  --------------------------\n",
      "Train loss: 4.654019038336617\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.921166687011718\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  2110  --------------------------\n",
      "Train loss: 4.668452392305647\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.86518898010254\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2120  --------------------------\n",
      "Train loss: 4.655647562571934\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 9.747000128428141\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2130  --------------------------\n",
      "Train loss: 4.599023767198835\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.775622094472249\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2140  --------------------------\n",
      "Train loss: 4.5933238111223496\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.905466648737589\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  2150  --------------------------\n",
      "Train loss: 4.629966667720249\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 9.708055617014567\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2160  --------------------------\n",
      "Train loss: 4.5912714120319915\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.776944408416748\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2170  --------------------------\n",
      "Train loss: 4.591128526415144\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.712055530548096\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2180  --------------------------\n",
      "Train loss: 4.554623785018921\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.790922020276387\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2190  --------------------------\n",
      "Train loss: 4.592357089178903\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.787922147115072\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2200  --------------------------\n",
      "Train loss: 4.570585717473711\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.915444367726645\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2210  --------------------------\n",
      "Train loss: 4.589723760741098\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.810733159383139\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2220  --------------------------\n",
      "Train loss: 4.572285679408482\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.878244412740072\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2230  --------------------------\n",
      "Train loss: 4.560852343014308\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.688266598383585\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2240  --------------------------\n",
      "Train loss: 4.581823806762696\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.633777637481689\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2250  --------------------------\n",
      "Train loss: 4.545504805701119\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.711322085062664\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2260  --------------------------\n",
      "Train loss: 4.537099993569511\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.893522319793702\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2270  --------------------------\n",
      "Train loss: 4.482861874444144\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.682988802591959\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2280  --------------------------\n",
      "Train loss: 4.504171374184745\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.882366574605307\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2290  --------------------------\n",
      "Train loss: 4.564476167815072\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 9.621833305358887\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2300  --------------------------\n",
      "Train loss: 4.523957109451294\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.622555478413899\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2310  --------------------------\n",
      "Train loss: 4.50650949205671\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.801088803609213\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2320  --------------------------\n",
      "Train loss: 4.540809519631522\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 9.668444366455079\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2330  --------------------------\n",
      "Train loss: 4.518023771558489\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.691944491068522\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2340  --------------------------\n",
      "Train loss: 4.5356904329572405\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.76474440574646\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2350  --------------------------\n",
      "Train loss: 4.518866646630423\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.969889017740885\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2360  --------------------------\n",
      "Train loss: 4.522595197132656\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.705288928349812\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2370  --------------------------\n",
      "Train loss: 4.482961844035557\n",
      "Train accuracy: 0.94\n",
      "Test loss: 10.02986650466919\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2380  --------------------------\n",
      "Train loss: 4.515957164764404\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.724644511540731\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2390  --------------------------\n",
      "Train loss: 4.4758571379525325\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.67562218983968\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2400  --------------------------\n",
      "Train loss: 4.503318990979876\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.638044427235922\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2410  --------------------------\n",
      "Train loss: 4.489395254680089\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.651066443125407\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2420  --------------------------\n",
      "Train loss: 4.516804726464408\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.593633295694987\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2430  --------------------------\n",
      "Train loss: 4.479042806625366\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.764944337209066\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2440  --------------------------\n",
      "Train loss: 4.444914239474706\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.800844510396322\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2450  --------------------------\n",
      "Train loss: 4.496599907193865\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.600233446756999\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2460  --------------------------\n",
      "Train loss: 4.491280909946987\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.78051123301188\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2470  --------------------------\n",
      "Train loss: 4.470528557641166\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.779533081054687\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  2480  --------------------------\n",
      "Train loss: 4.470019057137626\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.448499755859375\n",
      "Test accuracy: 0.89\n",
      "Epoch:  2490  --------------------------\n",
      "Train loss: 4.421204759052822\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.954422314961752\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2500  --------------------------\n",
      "Train loss: 4.419071369852339\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.716355565388998\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2510  --------------------------\n",
      "Train loss: 4.440990420750209\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.70073335647583\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2520  --------------------------\n",
      "Train loss: 4.444395231519427\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.517722260157267\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2530  --------------------------\n",
      "Train loss: 4.396109533309937\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.62341106414795\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  2540  --------------------------\n",
      "Train loss: 4.413447641645159\n",
      "Train accuracy: 0.9457142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 9.589922231038411\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2550  --------------------------\n",
      "Train loss: 4.424014257703509\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.588677914937337\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2560  --------------------------\n",
      "Train loss: 4.41218573978969\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.694122231801352\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2570  --------------------------\n",
      "Train loss: 4.370542820521764\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.60835553487142\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2580  --------------------------\n",
      "Train loss: 4.395661848613194\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 9.66873327255249\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2590  --------------------------\n",
      "Train loss: 4.4046238381522045\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.601899890899658\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2600  --------------------------\n",
      "Train loss: 4.379785726411002\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.47962230682373\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2610  --------------------------\n",
      "Train loss: 4.3697475753511705\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.537222239176431\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2620  --------------------------\n",
      "Train loss: 4.3280142920357845\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.533855702082317\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2630  --------------------------\n",
      "Train loss: 4.428933320726667\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 9.577177886962891\n",
      "Test accuracy: 0.8633333333333333\n",
      "Epoch:  2640  --------------------------\n",
      "Train loss: 4.352152374812535\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.564944413503012\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2650  --------------------------\n",
      "Train loss: 4.375971422195435\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 9.410599835713704\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2660  --------------------------\n",
      "Train loss: 4.328352387292044\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.432911167144775\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2670  --------------------------\n",
      "Train loss: 4.394376121248517\n",
      "Train accuracy: 0.9357142857142857\n",
      "Test loss: 9.585533358256022\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2680  --------------------------\n",
      "Train loss: 4.336257089887346\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.361666634877523\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2690  --------------------------\n",
      "Train loss: 4.349161853109087\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.407688814798991\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2700  --------------------------\n",
      "Train loss: 4.3533761705671035\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.318866672515869\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  2710  --------------------------\n",
      "Train loss: 4.294019011769976\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.45934455871582\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2720  --------------------------\n",
      "Train loss: 4.327414274896894\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.399933272997538\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2730  --------------------------\n",
      "Train loss: 4.317538115637643\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.429322026570638\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2740  --------------------------\n",
      "Train loss: 4.310947596686227\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.561644353866576\n",
      "Test accuracy: 0.86\n",
      "Epoch:  2750  --------------------------\n",
      "Train loss: 4.324080895015172\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.504333505630493\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2760  --------------------------\n",
      "Train loss: 4.267633303233556\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.44292226155599\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  2770  --------------------------\n",
      "Train loss: 4.29167140007019\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.69084447224935\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2780  --------------------------\n",
      "Train loss: 4.29730950491769\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.40118880589803\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2790  --------------------------\n",
      "Train loss: 4.322357132775443\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.602211119333903\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2800  --------------------------\n",
      "Train loss: 4.327028516360691\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.440544325510661\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  2810  --------------------------\n",
      "Train loss: 4.278561875479562\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.703866771062215\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2820  --------------------------\n",
      "Train loss: 4.336904799597604\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.550822086334229\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2830  --------------------------\n",
      "Train loss: 4.305571384429932\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.576499853134155\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2840  --------------------------\n",
      "Train loss: 4.302180922372001\n",
      "Train accuracy: 0.9371428571428572\n",
      "Test loss: 9.431700026194255\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  2850  --------------------------\n",
      "Train loss: 4.277552337646484\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.564055411020915\n",
      "Test accuracy: 0.8666666666666667\n",
      "Epoch:  2860  --------------------------\n",
      "Train loss: 4.283942822047642\n",
      "Train accuracy: 0.9385714285714286\n",
      "Test loss: 9.558411076863607\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2870  --------------------------\n",
      "Train loss: 4.250361862182618\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 9.365689007441203\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  2880  --------------------------\n",
      "Train loss: 4.243485740252903\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.294144420623779\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  2890  --------------------------\n",
      "Train loss: 4.275566671916417\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.29411101023356\n",
      "Test accuracy: 0.88\n",
      "Epoch:  2900  --------------------------\n",
      "Train loss: 4.264295253753662\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.507544660568238\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2910  --------------------------\n",
      "Train loss: 4.267485712596349\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.466866776148478\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2920  --------------------------\n",
      "Train loss: 4.253109536852155\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.366488857269287\n",
      "Test accuracy: 0.88\n",
      "Epoch:  2930  --------------------------\n",
      "Train loss: 4.249695228849139\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 9.507411047617595\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2940  --------------------------\n",
      "Train loss: 4.261080946241107\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.570500202178955\n",
      "Test accuracy: 0.88\n",
      "Epoch:  2950  --------------------------\n",
      "Train loss: 4.237647611073085\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.486477642059326\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2960  --------------------------\n",
      "Train loss: 4.207557173456465\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.671700108846029\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2970  --------------------------\n",
      "Train loss: 4.174776183537075\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.415944557189942\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  2980  --------------------------\n",
      "Train loss: 4.21883813721793\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.429855508804321\n",
      "Test accuracy: 0.87\n",
      "Epoch:  2990  --------------------------\n",
      "Train loss: 4.187642797061375\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.33265560468038\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3000  --------------------------\n",
      "Train loss: 4.204138088226318\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.395488789876302\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3010  --------------------------\n",
      "Train loss: 4.182414335523333\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.50846672375997\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3020  --------------------------\n",
      "Train loss: 4.117852400371007\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.393144365946451\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3030  --------------------------\n",
      "Train loss: 4.105557114737374\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.269322350819905\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3040  --------------------------\n",
      "Train loss: 4.214495207922799\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.555666802724202\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3050  --------------------------\n",
      "Train loss: 4.160057107380458\n",
      "Train accuracy: 0.9428571428571428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 9.329677645365397\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3060  --------------------------\n",
      "Train loss: 4.137942834581648\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.300311266581218\n",
      "Test accuracy: 0.9\n",
      "Epoch:  3070  --------------------------\n",
      "Train loss: 4.21105715070452\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.278111089070638\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3080  --------------------------\n",
      "Train loss: 4.1325618961879185\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.45355578104655\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3090  --------------------------\n",
      "Train loss: 4.193390474319458\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.364633547465006\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3100  --------------------------\n",
      "Train loss: 4.163795227323259\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.492755552927653\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3110  --------------------------\n",
      "Train loss: 4.081280977385385\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.460422223409017\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3120  --------------------------\n",
      "Train loss: 4.141204753603254\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.487544530232748\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3130  --------------------------\n",
      "Train loss: 4.14682852268219\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.516544481913249\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3140  --------------------------\n",
      "Train loss: 4.120723822116852\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 9.542888832092284\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3150  --------------------------\n",
      "Train loss: 4.1195523548126225\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.368855470021566\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  3160  --------------------------\n",
      "Train loss: 4.105366621017456\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.284889011383056\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3170  --------------------------\n",
      "Train loss: 4.076361878258841\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.531944262186686\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3180  --------------------------\n",
      "Train loss: 4.103504774911063\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.353688774108887\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3190  --------------------------\n",
      "Train loss: 4.07757620198386\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.287255585988362\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3200  --------------------------\n",
      "Train loss: 4.072780941554479\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.377544453938802\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3210  --------------------------\n",
      "Train loss: 4.085847561700003\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.363933149973551\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3220  --------------------------\n",
      "Train loss: 4.081595163345337\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.417344468434651\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3230  --------------------------\n",
      "Train loss: 4.055614253452846\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.493544260660807\n",
      "Test accuracy: 0.87\n",
      "Epoch:  3240  --------------------------\n",
      "Train loss: 4.082014264379229\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.398700135548909\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3250  --------------------------\n",
      "Train loss: 4.049528543608529\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.387666702270508\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3260  --------------------------\n",
      "Train loss: 4.0527523871830535\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 9.547722142537435\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3270  --------------------------\n",
      "Train loss: 4.053647629874093\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.35615546544393\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3280  --------------------------\n",
      "Train loss: 4.083080950123923\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.216755644480388\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3290  --------------------------\n",
      "Train loss: 4.0158523832048685\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.495521958669027\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3300  --------------------------\n",
      "Train loss: 4.034809511729649\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.407688859303793\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3310  --------------------------\n",
      "Train loss: 4.041404722758702\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.706722145080567\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3320  --------------------------\n",
      "Train loss: 4.054214269774301\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.256355616251627\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3330  --------------------------\n",
      "Train loss: 3.994947621481759\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.37785551071167\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3340  --------------------------\n",
      "Train loss: 4.05764281136649\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 9.265244464874268\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3350  --------------------------\n",
      "Train loss: 4.025395238740104\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.450911327997844\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3360  --------------------------\n",
      "Train loss: 4.018033259255546\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.411066595713297\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3370  --------------------------\n",
      "Train loss: 4.023338090692247\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.329988810221353\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3380  --------------------------\n",
      "Train loss: 3.928347611427307\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.422855459849039\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3390  --------------------------\n",
      "Train loss: 4.0351333250318255\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.442366822560627\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3400  --------------------------\n",
      "Train loss: 3.9669904480661664\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 9.214933242797851\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3410  --------------------------\n",
      "Train loss: 3.995180924960545\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.397722180684408\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3420  --------------------------\n",
      "Train loss: 3.967414276259286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.301111068725586\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3430  --------------------------\n",
      "Train loss: 3.9489571380615236\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.305811055501302\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3440  --------------------------\n",
      "Train loss: 3.979723813874381\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.318422164916992\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3450  --------------------------\n",
      "Train loss: 3.989790440968105\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.315766728719076\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3460  --------------------------\n",
      "Train loss: 3.9374713911329\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.423766527175903\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3470  --------------------------\n",
      "Train loss: 3.912638071605137\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 9.28168877919515\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3480  --------------------------\n",
      "Train loss: 3.9272000166348047\n",
      "Train accuracy: 0.94\n",
      "Test loss: 9.391300036112467\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3490  --------------------------\n",
      "Train loss: 3.946233380862645\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.28452213605245\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3500  --------------------------\n",
      "Train loss: 3.9340571253640313\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.356955416997273\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3510  --------------------------\n",
      "Train loss: 3.9190142706462314\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.455777683258056\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3520  --------------------------\n",
      "Train loss: 3.9481380455834527\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.229388898213704\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3530  --------------------------\n",
      "Train loss: 3.9047237934385026\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.47062218983968\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3540  --------------------------\n",
      "Train loss: 3.933747604233878\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.203455499013264\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3550  --------------------------\n",
      "Train loss: 3.9458237743377684\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.226688747406007\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3560  --------------------------\n",
      "Train loss: 3.887376136779785\n",
      "Train accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 9.287533365885416\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3570  --------------------------\n",
      "Train loss: 3.9041666425977435\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 9.61226671218872\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3580  --------------------------\n",
      "Train loss: 3.9195523643493653\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.086199947992961\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3590  --------------------------\n",
      "Train loss: 3.9384428759983607\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.26569990158081\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3600  --------------------------\n",
      "Train loss: 3.9418809468405587\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.159322102864584\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3610  --------------------------\n",
      "Train loss: 3.9165428481783184\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.26786657969157\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3620  --------------------------\n",
      "Train loss: 3.8663999768665858\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.184722270965576\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3630  --------------------------\n",
      "Train loss: 3.924771352495466\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.220777797698975\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  3640  --------------------------\n",
      "Train loss: 3.8955713885171073\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.333766530354819\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3650  --------------------------\n",
      "Train loss: 3.8625380638667517\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.103933321634928\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3660  --------------------------\n",
      "Train loss: 3.8236476380484445\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.081555449167887\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  3670  --------------------------\n",
      "Train loss: 3.819676160131182\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 9.346700166066487\n",
      "Test accuracy: 0.9\n",
      "Epoch:  3680  --------------------------\n",
      "Train loss: 3.8914333506992884\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.279277846018473\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3690  --------------------------\n",
      "Train loss: 3.87419048173087\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.97464454015096\n",
      "Test accuracy: 0.89\n",
      "Epoch:  3700  --------------------------\n",
      "Train loss: 3.836019070489066\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.087633272806803\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3710  --------------------------\n",
      "Train loss: 3.811190517970494\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.050566749572754\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  3720  --------------------------\n",
      "Train loss: 3.8472618665013996\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.238411223093669\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3730  --------------------------\n",
      "Train loss: 3.810709500994001\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.066422055562338\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  3740  --------------------------\n",
      "Train loss: 3.830119046483721\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 9.313233267466227\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  3750  --------------------------\n",
      "Train loss: 3.8162428276879448\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.28665553410848\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3760  --------------------------\n",
      "Train loss: 3.8478237874167305\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.214555629094441\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3770  --------------------------\n",
      "Train loss: 3.8299999935286384\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.053311208089193\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  3780  --------------------------\n",
      "Train loss: 3.8495238099779403\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.121300067901611\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3790  --------------------------\n",
      "Train loss: 3.7779809519222805\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.997966763178507\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3800  --------------------------\n",
      "Train loss: 3.7905666542053225\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.948711242675781\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3810  --------------------------\n",
      "Train loss: 3.771942811352866\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 9.103633149464924\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3820  --------------------------\n",
      "Train loss: 3.8206809207371304\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.088289082845051\n",
      "Test accuracy: 0.8733333333333333\n",
      "Epoch:  3830  --------------------------\n",
      "Train loss: 3.830899967466082\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.041411094665527\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3840  --------------------------\n",
      "Train loss: 3.811361927986145\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.954755414326986\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3850  --------------------------\n",
      "Train loss: 3.8108333206176757\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 9.05401107788086\n",
      "Test accuracy: 0.9\n",
      "Epoch:  3860  --------------------------\n",
      "Train loss: 3.788676154272897\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.860777651468913\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3870  --------------------------\n",
      "Train loss: 3.783185750416347\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.990822149912516\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3880  --------------------------\n",
      "Train loss: 3.830957144328526\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 9.042477855682373\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  3890  --------------------------\n",
      "Train loss: 3.7840190206255233\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.140711224873861\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  3900  --------------------------\n",
      "Train loss: 3.752695198740278\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 9.020288915634156\n",
      "Test accuracy: 0.89\n",
      "Epoch:  3910  --------------------------\n",
      "Train loss: 3.813904713221959\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.147977930704753\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3920  --------------------------\n",
      "Train loss: 3.791961874961853\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.072088896433513\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3930  --------------------------\n",
      "Train loss: 3.8206952122279576\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.009866669972737\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3940  --------------------------\n",
      "Train loss: 3.7923380981172836\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.10254425684611\n",
      "Test accuracy: 0.88\n",
      "Epoch:  3950  --------------------------\n",
      "Train loss: 3.756795198576791\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.091277656555176\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  3960  --------------------------\n",
      "Train loss: 3.7531999799183438\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.002177855173747\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  3970  --------------------------\n",
      "Train loss: 3.7733237648010256\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.979355583190918\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  3980  --------------------------\n",
      "Train loss: 3.7743190561022075\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 9.18481112162272\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  3990  --------------------------\n",
      "Train loss: 3.779214277267456\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.944055681228638\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4000  --------------------------\n",
      "Train loss: 3.7426999964032857\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.034633413950603\n",
      "Test accuracy: 0.9\n",
      "Epoch:  4010  --------------------------\n",
      "Train loss: 3.7899856758117676\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.774922154744466\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4020  --------------------------\n",
      "Train loss: 3.713185670035226\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 9.19334441502889\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4030  --------------------------\n",
      "Train loss: 3.8023952170780726\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.842800006866455\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4040  --------------------------\n",
      "Train loss: 3.7880714062282017\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.966588687896728\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4050  --------------------------\n",
      "Train loss: 3.742914240019662\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.825577710469563\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  4060  --------------------------\n",
      "Train loss: 3.7612570919309345\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.852833337783814\n",
      "Test accuracy: 0.88\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  4070  --------------------------\n",
      "Train loss: 3.7621333292552404\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.924799785614013\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4080  --------------------------\n",
      "Train loss: 3.7403475727353777\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.864233309427897\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4090  --------------------------\n",
      "Train loss: 3.7501523549216134\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.936333300272624\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4100  --------------------------\n",
      "Train loss: 3.7242475945608957\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 9.059133459726969\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4110  --------------------------\n",
      "Train loss: 3.7032666328975132\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.946755622227986\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4120  --------------------------\n",
      "Train loss: 3.7454524006162373\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.760788815816243\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4130  --------------------------\n",
      "Train loss: 3.738714280128479\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.90655548731486\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4140  --------------------------\n",
      "Train loss: 3.7512571566445487\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.927433280944824\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4150  --------------------------\n",
      "Train loss: 3.742299989972796\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.153088925679524\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4160  --------------------------\n",
      "Train loss: 3.730176192692348\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.941711139678954\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4170  --------------------------\n",
      "Train loss: 3.7267047664097377\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.931911067962647\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4180  --------------------------\n",
      "Train loss: 3.7356380469458443\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.82884433110555\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4190  --------------------------\n",
      "Train loss: 3.7252713850566317\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.936244436899822\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4200  --------------------------\n",
      "Train loss: 3.718990422998156\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.966055628458658\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4210  --------------------------\n",
      "Train loss: 3.7381380496706282\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.892733256022135\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4220  --------------------------\n",
      "Train loss: 3.7335714026859828\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.885388825734456\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4230  --------------------------\n",
      "Train loss: 3.6788285405295236\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.915933389663696\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4240  --------------------------\n",
      "Train loss: 3.737595195770264\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.854111156463624\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4250  --------------------------\n",
      "Train loss: 3.6700333070755007\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.935744387308757\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4260  --------------------------\n",
      "Train loss: 3.71095237663814\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.860588811238607\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4270  --------------------------\n",
      "Train loss: 3.6852713864190236\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.893299996058147\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4280  --------------------------\n",
      "Train loss: 3.6811189896719796\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.813677736918132\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4290  --------------------------\n",
      "Train loss: 3.676961854525975\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.83719997406006\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4300  --------------------------\n",
      "Train loss: 3.700190450804574\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.908211059570313\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4310  --------------------------\n",
      "Train loss: 3.6707951961244856\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.794866498311361\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4320  --------------------------\n",
      "Train loss: 3.711528528077262\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 9.117400150299073\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4330  --------------------------\n",
      "Train loss: 3.673195216315133\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 9.034555479685466\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4340  --------------------------\n",
      "Train loss: 3.659147595678057\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.898422190348308\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4350  --------------------------\n",
      "Train loss: 3.656014280319214\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.08918874422709\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4360  --------------------------\n",
      "Train loss: 3.694038083893912\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.98251106262207\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4370  --------------------------\n",
      "Train loss: 3.6530856902258737\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.852355308532715\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4380  --------------------------\n",
      "Train loss: 3.6858952052252634\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.010866622924805\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4390  --------------------------\n",
      "Train loss: 3.663204760551453\n",
      "Train accuracy: 0.95\n",
      "Test loss: 9.149877637227377\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4400  --------------------------\n",
      "Train loss: 3.7216666616712297\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.052777824401856\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4410  --------------------------\n",
      "Train loss: 3.680752364567348\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.899466883341471\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4420  --------------------------\n",
      "Train loss: 3.6710381579399107\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.879755503336588\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4430  --------------------------\n",
      "Train loss: 3.640819046497345\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.752277666727702\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4440  --------------------------\n",
      "Train loss: 3.6835047674179076\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.983910923004151\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4450  --------------------------\n",
      "Train loss: 3.6999285425458637\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.818100026448567\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4460  --------------------------\n",
      "Train loss: 3.6563047994886126\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.74929993947347\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4470  --------------------------\n",
      "Train loss: 3.6395904643195016\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.76746657371521\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4480  --------------------------\n",
      "Train loss: 3.67428574017116\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.832711118062337\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4490  --------------------------\n",
      "Train loss: 3.638823794637408\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.921799949010213\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4500  --------------------------\n",
      "Train loss: 3.674323820386614\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.872355454762777\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4510  --------------------------\n",
      "Train loss: 3.6449189969471525\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.802511049906412\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4520  --------------------------\n",
      "Train loss: 3.647509534699576\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.993866726557414\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4530  --------------------------\n",
      "Train loss: 3.6090380879810877\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 9.13167776743571\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4540  --------------------------\n",
      "Train loss: 3.656157167298453\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.7264554754893\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4550  --------------------------\n",
      "Train loss: 3.6286666325160435\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.919944458007812\n",
      "Test accuracy: 0.9\n",
      "Epoch:  4560  --------------------------\n",
      "Train loss: 3.655328584398542\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.936899808247885\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4570  --------------------------\n",
      "Train loss: 3.629266633987427\n",
      "Train accuracy: 0.9528571428571428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.829222167332967\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4580  --------------------------\n",
      "Train loss: 3.651214276722499\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.743899955749512\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4590  --------------------------\n",
      "Train loss: 3.6337333481652396\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.040333334604899\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4600  --------------------------\n",
      "Train loss: 3.5995142555236814\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.96488873799642\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4610  --------------------------\n",
      "Train loss: 3.6440713834762573\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.761299915313721\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4620  --------------------------\n",
      "Train loss: 3.6039809002195087\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.990299892425536\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4630  --------------------------\n",
      "Train loss: 3.625038105419704\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.939655717213949\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4640  --------------------------\n",
      "Train loss: 3.5825952250616893\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 9.120277811686197\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4650  --------------------------\n",
      "Train loss: 3.5951047590800695\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.86257783571879\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4660  --------------------------\n",
      "Train loss: 3.603285733972277\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.813399880727133\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4670  --------------------------\n",
      "Train loss: 3.6202856922149658\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.714188950856526\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  4680  --------------------------\n",
      "Train loss: 3.618995255742754\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.800388863881428\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4690  --------------------------\n",
      "Train loss: 3.5735095255715508\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.745144605636597\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4700  --------------------------\n",
      "Train loss: 3.625252392632621\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.740077667236328\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4710  --------------------------\n",
      "Train loss: 3.568138039452689\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.750833419164023\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4720  --------------------------\n",
      "Train loss: 3.5755952555792674\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.705210978190104\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4730  --------------------------\n",
      "Train loss: 3.612638075692313\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 9.078300018310546\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4740  --------------------------\n",
      "Train loss: 3.5916333498273576\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.864177805582683\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4750  --------------------------\n",
      "Train loss: 3.6165809467860632\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.672744426727295\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4760  --------------------------\n",
      "Train loss: 3.602442851747785\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 9.105488850275675\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4770  --------------------------\n",
      "Train loss: 3.5651427963801794\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.719400068918864\n",
      "Test accuracy: 0.91\n",
      "Epoch:  4780  --------------------------\n",
      "Train loss: 3.569809513092041\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.892455466588338\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4790  --------------------------\n",
      "Train loss: 3.5532333012989588\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.686622327168783\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4800  --------------------------\n",
      "Train loss: 3.5865904085976736\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.745111096700033\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4810  --------------------------\n",
      "Train loss: 3.595666642189026\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.840966580708821\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4820  --------------------------\n",
      "Train loss: 3.6007951988492692\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.780411020914714\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4830  --------------------------\n",
      "Train loss: 3.52492374760764\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.762955563863118\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4840  --------------------------\n",
      "Train loss: 3.6170713799340386\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.722899881998698\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4850  --------------------------\n",
      "Train loss: 3.6211333417892457\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.700610980987548\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4860  --------------------------\n",
      "Train loss: 3.580742817606245\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.675966466267903\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4870  --------------------------\n",
      "Train loss: 3.5663666473116193\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.756766646703085\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4880  --------------------------\n",
      "Train loss: 3.593176174845014\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.617977797190349\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4890  --------------------------\n",
      "Train loss: 3.5820856635911125\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.624999866485595\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4900  --------------------------\n",
      "Train loss: 3.581171430179051\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.837866592407227\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4910  --------------------------\n",
      "Train loss: 3.5827190358298164\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.667799886067709\n",
      "Test accuracy: 0.88\n",
      "Epoch:  4920  --------------------------\n",
      "Train loss: 3.5356571565355575\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.69392223040263\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4930  --------------------------\n",
      "Train loss: 3.594538118498666\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.72258886973063\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4940  --------------------------\n",
      "Train loss: 3.5419475752966743\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.601510976155598\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4950  --------------------------\n",
      "Train loss: 3.5831381034851075\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.673922348022462\n",
      "Test accuracy: 0.89\n",
      "Epoch:  4960  --------------------------\n",
      "Train loss: 3.569623757771083\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.636477686564128\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4970  --------------------------\n",
      "Train loss: 3.516147565841675\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.567066694895427\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  4980  --------------------------\n",
      "Train loss: 3.5162476481710163\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.498600050608317\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  4990  --------------------------\n",
      "Train loss: 3.5346856662205286\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.712210877736409\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5000  --------------------------\n",
      "Train loss: 3.574557100704738\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 8.57007760365804\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5010  --------------------------\n",
      "Train loss: 3.5914523942129954\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.774211025238037\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5020  --------------------------\n",
      "Train loss: 3.525423777444022\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.66772219022115\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5030  --------------------------\n",
      "Train loss: 3.560052365575518\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.719966576894125\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5040  --------------------------\n",
      "Train loss: 3.57992856161935\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.627477836608886\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5050  --------------------------\n",
      "Train loss: 3.535095227105277\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.59305564880371\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5060  --------------------------\n",
      "Train loss: 3.563557082584926\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.621377671559651\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5070  --------------------------\n",
      "Train loss: 3.5426952259881155\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.694444405237833\n",
      "Test accuracy: 0.8833333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  5080  --------------------------\n",
      "Train loss: 3.5356380953107562\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.721933314005534\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5090  --------------------------\n",
      "Train loss: 3.570923763683864\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.774655405680338\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5100  --------------------------\n",
      "Train loss: 3.5987094681603566\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.742366580963134\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5110  --------------------------\n",
      "Train loss: 3.5433000019618444\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.64688896814982\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5120  --------------------------\n",
      "Train loss: 3.553933330944606\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.590377833048503\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5130  --------------------------\n",
      "Train loss: 3.520666605404445\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.578111057281495\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5140  --------------------------\n",
      "Train loss: 3.5251380940846033\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.937922140757243\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5150  --------------------------\n",
      "Train loss: 3.6357523621831622\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.70638884862264\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5160  --------------------------\n",
      "Train loss: 3.5624189955847605\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.800166625976562\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5170  --------------------------\n",
      "Train loss: 3.4770618738446917\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.771433385213216\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5180  --------------------------\n",
      "Train loss: 3.5644190079825266\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.651277592976887\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5190  --------------------------\n",
      "Train loss: 3.520985732078552\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.600144335428874\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5200  --------------------------\n",
      "Train loss: 3.5495666599273683\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.549455579121908\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5210  --------------------------\n",
      "Train loss: 3.5244618701934813\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.659110972086589\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5220  --------------------------\n",
      "Train loss: 3.5603428227560863\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.756688817342122\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5230  --------------------------\n",
      "Train loss: 3.573699962752206\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.500733102162679\n",
      "Test accuracy: 0.88\n",
      "Epoch:  5240  --------------------------\n",
      "Train loss: 3.5274190153394427\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.524766594568888\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5250  --------------------------\n",
      "Train loss: 3.5265475722721646\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.57847775777181\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5260  --------------------------\n",
      "Train loss: 3.5265952798298428\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.584900023142497\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5270  --------------------------\n",
      "Train loss: 3.535814277103969\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.629666493733724\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5280  --------------------------\n",
      "Train loss: 3.53384288924081\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.447222194671632\n",
      "Test accuracy: 0.91\n",
      "Epoch:  5290  --------------------------\n",
      "Train loss: 3.5190475899832587\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.484188849131266\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5300  --------------------------\n",
      "Train loss: 3.536976227079119\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.563222217559815\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5310  --------------------------\n",
      "Train loss: 3.4770523377827236\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.535099817911783\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5320  --------------------------\n",
      "Train loss: 3.5201904705592564\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.625744406382243\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5330  --------------------------\n",
      "Train loss: 3.5300666114262174\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.475766652425131\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5340  --------------------------\n",
      "Train loss: 3.5517333146503995\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.560755449930827\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5350  --------------------------\n",
      "Train loss: 3.5286095046997072\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.50880002339681\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5360  --------------------------\n",
      "Train loss: 3.5348809596470425\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.587210868199666\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5370  --------------------------\n",
      "Train loss: 3.499233268329075\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.517911081314088\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5380  --------------------------\n",
      "Train loss: 3.4668666587557113\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.494511151313782\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5390  --------------------------\n",
      "Train loss: 3.4868285574231828\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.318088779449463\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5400  --------------------------\n",
      "Train loss: 3.488995227132525\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.652711044947306\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  5410  --------------------------\n",
      "Train loss: 3.4911333090918406\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.450700041453043\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5420  --------------------------\n",
      "Train loss: 3.5726857103620255\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.407977692286174\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5430  --------------------------\n",
      "Train loss: 3.527471399307251\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.427755476633708\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5440  --------------------------\n",
      "Train loss: 3.483909499985831\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.659288902282714\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5450  --------------------------\n",
      "Train loss: 3.4216428007398334\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.484833380381266\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5460  --------------------------\n",
      "Train loss: 3.485323828288487\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.700822226206462\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5470  --------------------------\n",
      "Train loss: 3.541947627067566\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.410922234853109\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5480  --------------------------\n",
      "Train loss: 3.5172999743052893\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.516300029754639\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5490  --------------------------\n",
      "Train loss: 3.493395265170506\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.36002230644226\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5500  --------------------------\n",
      "Train loss: 3.5316142381940567\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.460255502065023\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5510  --------------------------\n",
      "Train loss: 3.4769666389056613\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.53863343556722\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5520  --------------------------\n",
      "Train loss: 3.5275953102111814\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.613755551973979\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5530  --------------------------\n",
      "Train loss: 3.554576131956918\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.667011076609294\n",
      "Test accuracy: 0.8766666666666667\n",
      "Epoch:  5540  --------------------------\n",
      "Train loss: 3.5282856907163347\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.411455637613932\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5550  --------------------------\n",
      "Train loss: 3.480719005720956\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.59209983507792\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5560  --------------------------\n",
      "Train loss: 3.4832048157283237\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.435888735453288\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5570  --------------------------\n",
      "Train loss: 3.5129475906917027\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.355422089894613\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5580  --------------------------\n",
      "Train loss: 3.5141713673727852\n",
      "Train accuracy: 0.9428571428571428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.481011091868083\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5590  --------------------------\n",
      "Train loss: 3.5107142700467793\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.45432217915853\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5600  --------------------------\n",
      "Train loss: 3.4991618531090873\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.431755555470785\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5610  --------------------------\n",
      "Train loss: 3.507204793521336\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.497922210693359\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5620  --------------------------\n",
      "Train loss: 3.4995143270492552\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.47729975382487\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5630  --------------------------\n",
      "Train loss: 3.4628809247698102\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.505977840423585\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5640  --------------------------\n",
      "Train loss: 3.502619032178606\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.518833395640055\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5650  --------------------------\n",
      "Train loss: 3.499052357673645\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.578244584401448\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5660  --------------------------\n",
      "Train loss: 3.461723777907235\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.360855385462443\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5670  --------------------------\n",
      "Train loss: 3.492038061278207\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.699855502446493\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5680  --------------------------\n",
      "Train loss: 3.505557099069868\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.460288778940837\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5690  --------------------------\n",
      "Train loss: 3.485238073553358\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.383888963063558\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5700  --------------------------\n",
      "Train loss: 3.4854904685701644\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.476944313049316\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5710  --------------------------\n",
      "Train loss: 3.4383666358675273\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.450299968719483\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  5720  --------------------------\n",
      "Train loss: 3.492376164368221\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.492200053532919\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5730  --------------------------\n",
      "Train loss: 3.4627856969833375\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.324233309427898\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5740  --------------------------\n",
      "Train loss: 3.4588428579057964\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.361066557566325\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5750  --------------------------\n",
      "Train loss: 3.485800016266959\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.876311117808024\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5760  --------------------------\n",
      "Train loss: 3.47681905065264\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.345210984547933\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5770  --------------------------\n",
      "Train loss: 3.478166644232614\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.515977789560953\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5780  --------------------------\n",
      "Train loss: 3.4388095133645193\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.60547752380371\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5790  --------------------------\n",
      "Train loss: 3.4707856920787266\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.447066659927367\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5800  --------------------------\n",
      "Train loss: 3.4846095044272287\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.356933369636536\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5810  --------------------------\n",
      "Train loss: 3.454457084110805\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.54753314336141\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5820  --------------------------\n",
      "Train loss: 3.450914310727801\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.66573319753011\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5830  --------------------------\n",
      "Train loss: 3.4410428496769496\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.449599997202556\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5840  --------------------------\n",
      "Train loss: 3.4350285720825195\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.500011021296183\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  5850  --------------------------\n",
      "Train loss: 3.4657523386819022\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.425299911499023\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5860  --------------------------\n",
      "Train loss: 3.44635715007782\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.447522214253743\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5870  --------------------------\n",
      "Train loss: 3.4905857011250085\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.346866594950358\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5880  --------------------------\n",
      "Train loss: 3.394028512409755\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.377922191619874\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5890  --------------------------\n",
      "Train loss: 3.4307809155327935\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.355777756373088\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5900  --------------------------\n",
      "Train loss: 3.4764666414260863\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.390711018244426\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5910  --------------------------\n",
      "Train loss: 3.4656237949643818\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.380277716318766\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5920  --------------------------\n",
      "Train loss: 3.4470666558401923\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.426633491516114\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  5930  --------------------------\n",
      "Train loss: 3.457800006185259\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.454455560048421\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5940  --------------------------\n",
      "Train loss: 3.4211998973573956\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.431611162821453\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5950  --------------------------\n",
      "Train loss: 3.479842816080366\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.198344440460206\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5960  --------------------------\n",
      "Train loss: 3.3940047543389458\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.332833167711893\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  5970  --------------------------\n",
      "Train loss: 3.4565904085976737\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.417433230082194\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5980  --------------------------\n",
      "Train loss: 3.4760380894797187\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.589622103373209\n",
      "Test accuracy: 0.89\n",
      "Epoch:  5990  --------------------------\n",
      "Train loss: 3.44132851600647\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.348677752812703\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6000  --------------------------\n",
      "Train loss: 3.521085695539202\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.472411155700684\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6010  --------------------------\n",
      "Train loss: 3.4365761831828525\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.389555498758952\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6020  --------------------------\n",
      "Train loss: 3.4379047652653285\n",
      "Train accuracy: 0.96\n",
      "Test loss: 8.33762217203776\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6030  --------------------------\n",
      "Train loss: 3.3907952717372347\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.35099988937378\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6040  --------------------------\n",
      "Train loss: 3.4737285831996374\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.284466718037923\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6050  --------------------------\n",
      "Train loss: 3.390647623879569\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.80579999923706\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6060  --------------------------\n",
      "Train loss: 3.4459094878605434\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.479022331237793\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6070  --------------------------\n",
      "Train loss: 3.4308142743791854\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.371633211771647\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6080  --------------------------\n",
      "Train loss: 3.375123779773712\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.553499952952068\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6090  --------------------------\n",
      "Train loss: 3.4216951785768783\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.260944334665934\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6100  --------------------------\n",
      "Train loss: 3.423523770059858\n",
      "Train accuracy: 0.9514285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.414533228874207\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6110  --------------------------\n",
      "Train loss: 3.429157072475978\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.29289997736613\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6120  --------------------------\n",
      "Train loss: 3.4134523330416\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.31717776298523\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6130  --------------------------\n",
      "Train loss: 3.4369856548309325\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.305711040496826\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6140  --------------------------\n",
      "Train loss: 3.4288142633438112\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.479844347635906\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6150  --------------------------\n",
      "Train loss: 3.446771387372698\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.419588934580485\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6160  --------------------------\n",
      "Train loss: 3.4207618318285262\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.507277736663818\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6170  --------------------------\n",
      "Train loss: 3.4107999971934726\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.406710968017578\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6180  --------------------------\n",
      "Train loss: 3.3990856810978483\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.310533269246418\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6190  --------------------------\n",
      "Train loss: 3.423676131112235\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.450577754974365\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6200  --------------------------\n",
      "Train loss: 3.422176136289324\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.25560002009074\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6210  --------------------------\n",
      "Train loss: 3.3978189952032904\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.43837792714437\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6220  --------------------------\n",
      "Train loss: 3.4478570897238594\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.35025547027588\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6230  --------------------------\n",
      "Train loss: 3.379319006374904\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.222777690887451\n",
      "Test accuracy: 0.91\n",
      "Epoch:  6240  --------------------------\n",
      "Train loss: 3.399333328519549\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.326210994720459\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6250  --------------------------\n",
      "Train loss: 3.3904809406825476\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.403966439565023\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6260  --------------------------\n",
      "Train loss: 3.405409484250205\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.461233291625977\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6270  --------------------------\n",
      "Train loss: 3.394647619383676\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.514677680333456\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6280  --------------------------\n",
      "Train loss: 3.354223789487566\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.454677836100261\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6290  --------------------------\n",
      "Train loss: 3.4028571231024607\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.552199980417887\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6300  --------------------------\n",
      "Train loss: 3.3320142909458705\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.55148889541626\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6310  --------------------------\n",
      "Train loss: 3.3949476316996985\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.537577622731527\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6320  --------------------------\n",
      "Train loss: 3.411066643169948\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.431666685740153\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6330  --------------------------\n",
      "Train loss: 3.402338060651507\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.253255558013915\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6340  --------------------------\n",
      "Train loss: 3.374499966757638\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.296822299957276\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6350  --------------------------\n",
      "Train loss: 3.3661999709265573\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.475711104075113\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6360  --------------------------\n",
      "Train loss: 3.419985672405788\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.493099829355875\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6370  --------------------------\n",
      "Train loss: 3.3947952164922444\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.322922147115072\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6380  --------------------------\n",
      "Train loss: 3.3663285561970304\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.223444480895996\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6390  --------------------------\n",
      "Train loss: 3.3457285594940185\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.309422213236491\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6400  --------------------------\n",
      "Train loss: 3.4055571487971714\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.394666469891867\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6410  --------------------------\n",
      "Train loss: 3.422261896814619\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.341188761393228\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6420  --------------------------\n",
      "Train loss: 3.3839285809653146\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.248611145019531\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6430  --------------------------\n",
      "Train loss: 3.314495185443333\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.4289000193278\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6440  --------------------------\n",
      "Train loss: 3.3690999828066146\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.438511110941569\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6450  --------------------------\n",
      "Train loss: 3.36247613293784\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.30887789408366\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6460  --------------------------\n",
      "Train loss: 3.397119041851589\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.485711027781168\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6470  --------------------------\n",
      "Train loss: 3.339633274078369\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.396611029307048\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6480  --------------------------\n",
      "Train loss: 3.34606187411717\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.338322124481202\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6490  --------------------------\n",
      "Train loss: 3.4009476014545985\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.34207784016927\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  6500  --------------------------\n",
      "Train loss: 3.3674857125963484\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.246188802719116\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6510  --------------------------\n",
      "Train loss: 3.3854285178865706\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.4483891359965\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6520  --------------------------\n",
      "Train loss: 3.3687856592450824\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.481811122894287\n",
      "Test accuracy: 0.88\n",
      "Epoch:  6530  --------------------------\n",
      "Train loss: 3.321319008554731\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.248633302052816\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6540  --------------------------\n",
      "Train loss: 3.3706428146362306\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.463477687835693\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6550  --------------------------\n",
      "Train loss: 3.3666571140289308\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.379099871317546\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6560  --------------------------\n",
      "Train loss: 3.3573570946284703\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.413699887593587\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6570  --------------------------\n",
      "Train loss: 3.3677094841003417\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.30636667251587\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6580  --------------------------\n",
      "Train loss: 3.36994282245636\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.441133187611898\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6590  --------------------------\n",
      "Train loss: 3.350676129545484\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.336711031595867\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6600  --------------------------\n",
      "Train loss: 3.403657125745501\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.288199907938639\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6610  --------------------------\n",
      "Train loss: 3.3492237956183297\n",
      "Train accuracy: 0.9514285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.247010927200318\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6620  --------------------------\n",
      "Train loss: 3.3749951553344726\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.299111080169677\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6630  --------------------------\n",
      "Train loss: 3.326014258180346\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.328455486297607\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6640  --------------------------\n",
      "Train loss: 3.3099142381123134\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.28675547917684\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6650  --------------------------\n",
      "Train loss: 3.3178523506437028\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.280777695973715\n",
      "Test accuracy: 0.9\n",
      "Epoch:  6660  --------------------------\n",
      "Train loss: 3.3889571149008613\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.287711194356282\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6670  --------------------------\n",
      "Train loss: 3.360828535216195\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.350366675059\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6680  --------------------------\n",
      "Train loss: 3.362776174545288\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.233133347829183\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6690  --------------------------\n",
      "Train loss: 3.3631094666889734\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.401333294709524\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6700  --------------------------\n",
      "Train loss: 3.3670380973815917\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.289888725280761\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6710  --------------------------\n",
      "Train loss: 3.347866610118321\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.210466607411702\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6720  --------------------------\n",
      "Train loss: 3.341795229911804\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.162011057535807\n",
      "Test accuracy: 0.91\n",
      "Epoch:  6730  --------------------------\n",
      "Train loss: 3.302690460341317\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.254744281768799\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6740  --------------------------\n",
      "Train loss: 3.2877713741574968\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.394633331298827\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  6750  --------------------------\n",
      "Train loss: 3.319390448161534\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.54525561650594\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6760  --------------------------\n",
      "Train loss: 3.346457153047834\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.274488830566407\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6770  --------------------------\n",
      "Train loss: 3.361542818205697\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.337722072601318\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6780  --------------------------\n",
      "Train loss: 3.322185661792755\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.42417778968811\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6790  --------------------------\n",
      "Train loss: 3.3156285537992205\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.37726661682129\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6800  --------------------------\n",
      "Train loss: 3.3796047367368427\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.374299748738606\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6810  --------------------------\n",
      "Train loss: 3.334928562300546\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.321244405110678\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6820  --------------------------\n",
      "Train loss: 3.3507238476616994\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.310422166188557\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6830  --------------------------\n",
      "Train loss: 3.3505333430426463\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.389355748494467\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6840  --------------------------\n",
      "Train loss: 3.3189142513275147\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.403955615361532\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6850  --------------------------\n",
      "Train loss: 3.2921809305463516\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.472799854278565\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6860  --------------------------\n",
      "Train loss: 3.36089515379497\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.241488768259684\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6870  --------------------------\n",
      "Train loss: 3.3523189987455098\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.209844500223795\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6880  --------------------------\n",
      "Train loss: 3.3181809323174614\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.360410963694255\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6890  --------------------------\n",
      "Train loss: 3.3373428794315885\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.462199872334798\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6900  --------------------------\n",
      "Train loss: 3.3601047345570154\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.290455503463745\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6910  --------------------------\n",
      "Train loss: 3.315123802593776\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.32026647567749\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6920  --------------------------\n",
      "Train loss: 3.30877617086683\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.313266582489014\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6930  --------------------------\n",
      "Train loss: 3.289676124027797\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.40214433670044\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  6940  --------------------------\n",
      "Train loss: 3.3451809331348965\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.240077670415243\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6950  --------------------------\n",
      "Train loss: 3.34841427053724\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.141866671244303\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6960  --------------------------\n",
      "Train loss: 3.3361762033190048\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.219222138722738\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  6970  --------------------------\n",
      "Train loss: 3.349571409566062\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.169600028991699\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6980  --------------------------\n",
      "Train loss: 3.3324523149217877\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.288022282918295\n",
      "Test accuracy: 0.89\n",
      "Epoch:  6990  --------------------------\n",
      "Train loss: 3.330090445109776\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.1793443997701\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7000  --------------------------\n",
      "Train loss: 3.2802809606279646\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.268722146352133\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7010  --------------------------\n",
      "Train loss: 3.292423783711025\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.224344294865926\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7020  --------------------------\n",
      "Train loss: 3.3347809083121165\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.37971097946167\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7030  --------------------------\n",
      "Train loss: 3.323023770877293\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.474288736979167\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7040  --------------------------\n",
      "Train loss: 3.336466657093593\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.272077770233155\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7050  --------------------------\n",
      "Train loss: 3.308747548375811\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.24084425608317\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7060  --------------------------\n",
      "Train loss: 3.308133325576782\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.142988812128703\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  7070  --------------------------\n",
      "Train loss: 3.314571386745998\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.298755464553834\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7080  --------------------------\n",
      "Train loss: 3.3215142679214478\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.419433403015137\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7090  --------------------------\n",
      "Train loss: 3.2797570855276925\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.398933102289835\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7100  --------------------------\n",
      "Train loss: 3.2850047547476633\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.356333201726278\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7110  --------------------------\n",
      "Train loss: 3.3173761251994542\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.462622114817302\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7120  --------------------------\n",
      "Train loss: 3.339809510367257\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.250011088053386\n",
      "Test accuracy: 0.8866666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  7130  --------------------------\n",
      "Train loss: 3.305666629246303\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.39088872273763\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7140  --------------------------\n",
      "Train loss: 3.311300007615771\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.261411135991414\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7150  --------------------------\n",
      "Train loss: 3.2694476079940795\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.20099977493286\n",
      "Test accuracy: 0.91\n",
      "Epoch:  7160  --------------------------\n",
      "Train loss: 3.343280940055847\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.355100024541219\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7170  --------------------------\n",
      "Train loss: 3.286071357727051\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.334600048065186\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7180  --------------------------\n",
      "Train loss: 3.2965952478136336\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.25763339360555\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7190  --------------------------\n",
      "Train loss: 3.2596190077917915\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.39964422861735\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7200  --------------------------\n",
      "Train loss: 3.308290455000741\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.2772998046875\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7210  --------------------------\n",
      "Train loss: 3.2898856857844763\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.285822057724\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7220  --------------------------\n",
      "Train loss: 3.303957099233355\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.366599899927776\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7230  --------------------------\n",
      "Train loss: 3.3146523666381835\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.267311083475748\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7240  --------------------------\n",
      "Train loss: 3.2608666222436087\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.285211187998454\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7250  --------------------------\n",
      "Train loss: 3.3010381255831036\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.249644171396891\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7260  --------------------------\n",
      "Train loss: 3.2552809078352793\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.444877758026124\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7270  --------------------------\n",
      "Train loss: 3.308571391786848\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.280833199818929\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7280  --------------------------\n",
      "Train loss: 3.293109519822257\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.328277829488119\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7290  --------------------------\n",
      "Train loss: 3.283528560910906\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.296777941385905\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7300  --------------------------\n",
      "Train loss: 3.3305856956754414\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.321966749827068\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7310  --------------------------\n",
      "Train loss: 3.3012904371534075\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.212144298553467\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7320  --------------------------\n",
      "Train loss: 3.3187285709381102\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.267344268163045\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7330  --------------------------\n",
      "Train loss: 3.273295228821891\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.810144472122193\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7340  --------------------------\n",
      "Train loss: 3.2693475907189504\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.258155638376872\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7350  --------------------------\n",
      "Train loss: 3.2557809768404278\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.302266686757406\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7360  --------------------------\n",
      "Train loss: 3.26241899899074\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.348988812764485\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7370  --------------------------\n",
      "Train loss: 3.3053142411368235\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.538255519866944\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7380  --------------------------\n",
      "Train loss: 3.2771857166290284\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.38942211151123\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7390  --------------------------\n",
      "Train loss: 3.275095237323216\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.275999987920125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7400  --------------------------\n",
      "Train loss: 3.262042774472918\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.281111075083414\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7410  --------------------------\n",
      "Train loss: 3.2855047736849103\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.352999998728434\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7420  --------------------------\n",
      "Train loss: 3.275409483909607\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.392011216481526\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7430  --------------------------\n",
      "Train loss: 3.2865476049695697\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.36021108309428\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7440  --------------------------\n",
      "Train loss: 3.296542864527021\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.403133144378662\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7450  --------------------------\n",
      "Train loss: 3.3320666347231183\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.278411118189494\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7460  --------------------------\n",
      "Train loss: 3.2605571106501987\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.506255569458007\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7470  --------------------------\n",
      "Train loss: 3.2880856813703265\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.44086643854777\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7480  --------------------------\n",
      "Train loss: 3.283733301843916\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.265288931528728\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7490  --------------------------\n",
      "Train loss: 3.2790857444490706\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.449877837498983\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7500  --------------------------\n",
      "Train loss: 3.283790446690151\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.316011091868083\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7510  --------------------------\n",
      "Train loss: 3.335780918938773\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.393855578104654\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7520  --------------------------\n",
      "Train loss: 3.3117666339874265\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.389700063069661\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7530  --------------------------\n",
      "Train loss: 3.3121238279342653\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.276155586242675\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7540  --------------------------\n",
      "Train loss: 3.2931237704413276\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.357344439824422\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7550  --------------------------\n",
      "Train loss: 3.2565142917633056\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.32886664390564\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7560  --------------------------\n",
      "Train loss: 3.3037142504964554\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.37421112060547\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7570  --------------------------\n",
      "Train loss: 3.3005904422487533\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.331577609380087\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7580  --------------------------\n",
      "Train loss: 3.2630809211730956\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.395355339050292\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7590  --------------------------\n",
      "Train loss: 3.288642851965768\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.30978885014852\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7600  --------------------------\n",
      "Train loss: 3.275242862360818\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.24997787475586\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7610  --------------------------\n",
      "Train loss: 3.2635095085416523\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.436055634816487\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7620  --------------------------\n",
      "Train loss: 3.2659238600730895\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.218055421511332\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7630  --------------------------\n",
      "Train loss: 3.2890142842701504\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.404866568247478\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7640  --------------------------\n",
      "Train loss: 3.2579047305243356\n",
      "Train accuracy: 0.9457142857142857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.479199844996135\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7650  --------------------------\n",
      "Train loss: 3.2550951875959124\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.275811208089193\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7660  --------------------------\n",
      "Train loss: 3.284104755946568\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.372933228810629\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7670  --------------------------\n",
      "Train loss: 3.2586618982042586\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.370311183929443\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  7680  --------------------------\n",
      "Train loss: 3.2932142400741578\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.415055548350017\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7690  --------------------------\n",
      "Train loss: 3.2700047418049403\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.301999934514363\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7700  --------------------------\n",
      "Train loss: 3.244619073186602\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.356833127339682\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7710  --------------------------\n",
      "Train loss: 3.3117238027708873\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.35117774327596\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7720  --------------------------\n",
      "Train loss: 3.263471397672381\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.416088933944701\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7730  --------------------------\n",
      "Train loss: 3.2134904561723983\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.504322134653727\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7740  --------------------------\n",
      "Train loss: 3.2689523601531985\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.228255449930828\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7750  --------------------------\n",
      "Train loss: 3.2629904420035225\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.360422163009643\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7760  --------------------------\n",
      "Train loss: 3.2517666264942715\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.28300004641215\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7770  --------------------------\n",
      "Train loss: 3.241519000870841\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.427322018941243\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7780  --------------------------\n",
      "Train loss: 3.2597333438055855\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.44567761103312\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7790  --------------------------\n",
      "Train loss: 3.2168142543520246\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.40051098505656\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7800  --------------------------\n",
      "Train loss: 3.2164523322241645\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.24186669031779\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7810  --------------------------\n",
      "Train loss: 3.244133278301784\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.251333338419597\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7820  --------------------------\n",
      "Train loss: 3.251709471430097\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.39565528869629\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7830  --------------------------\n",
      "Train loss: 3.195695229257856\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.374511105219524\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7840  --------------------------\n",
      "Train loss: 3.2495190586362566\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.483622430165608\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7850  --------------------------\n",
      "Train loss: 3.251728517668588\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.434011030197144\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7860  --------------------------\n",
      "Train loss: 3.2494523777280535\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.436622222264608\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7870  --------------------------\n",
      "Train loss: 3.216595210347857\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.340133326848347\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7880  --------------------------\n",
      "Train loss: 3.226676177978516\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.336822090148926\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7890  --------------------------\n",
      "Train loss: 3.2703571254866466\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.232411142985026\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7900  --------------------------\n",
      "Train loss: 3.228004729407174\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.440189043680826\n",
      "Test accuracy: 0.89\n",
      "Epoch:  7910  --------------------------\n",
      "Train loss: 3.221509463446481\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.521410916646321\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7920  --------------------------\n",
      "Train loss: 3.2762523576191493\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.286111081441243\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7930  --------------------------\n",
      "Train loss: 3.248080917426518\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.353877677917481\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  7940  --------------------------\n",
      "Train loss: 3.1963190501076832\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.467333367665608\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7950  --------------------------\n",
      "Train loss: 3.183395212718419\n",
      "Train accuracy: 0.9614285714285714\n",
      "Test loss: 8.495277856190999\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7960  --------------------------\n",
      "Train loss: 3.1558237613950455\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.518700160980224\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  7970  --------------------------\n",
      "Train loss: 3.256557091304234\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.375199960072836\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  7980  --------------------------\n",
      "Train loss: 3.2219237995147707\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.342999992370606\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  7990  --------------------------\n",
      "Train loss: 3.2140000023160664\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.58867769241333\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8000  --------------------------\n",
      "Train loss: 3.2009237916128974\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.326222155888875\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8010  --------------------------\n",
      "Train loss: 3.240709502696991\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.34713311513265\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8020  --------------------------\n",
      "Train loss: 3.230552327973502\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.252122192382812\n",
      "Test accuracy: 0.88\n",
      "Epoch:  8030  --------------------------\n",
      "Train loss: 3.240290457180568\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.311788756052653\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8040  --------------------------\n",
      "Train loss: 3.2099951675959995\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.352488962809245\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8050  --------------------------\n",
      "Train loss: 3.2594332715443204\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.481533466974895\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  8060  --------------------------\n",
      "Train loss: 3.224895226614816\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.249555498758951\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8070  --------------------------\n",
      "Train loss: 3.2069380371911187\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.361566530863444\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  8080  --------------------------\n",
      "Train loss: 3.2484571279798233\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.281399828592937\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8090  --------------------------\n",
      "Train loss: 3.2694809007644654\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.313488858540852\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8100  --------------------------\n",
      "Train loss: 3.2213000086375647\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.267499955495198\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8110  --------------------------\n",
      "Train loss: 3.2397094794682095\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.297199878692627\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8120  --------------------------\n",
      "Train loss: 3.1683047260556902\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.28411106745402\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8130  --------------------------\n",
      "Train loss: 3.1966761643545967\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.41568878173828\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  8140  --------------------------\n",
      "Train loss: 3.2066190092904225\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.314233353932698\n",
      "Test accuracy: 0.8866666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  8150  --------------------------\n",
      "Train loss: 3.206152379172189\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.298688945770264\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8160  --------------------------\n",
      "Train loss: 3.2089380700247627\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.35238899230957\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8170  --------------------------\n",
      "Train loss: 3.2055285603659494\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.228033250172933\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8180  --------------------------\n",
      "Train loss: 3.205485681806292\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.418277645111084\n",
      "Test accuracy: 0.88\n",
      "Epoch:  8190  --------------------------\n",
      "Train loss: 3.1941761302948\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.31489982922872\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8200  --------------------------\n",
      "Train loss: 3.2386094794954574\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.36906670888265\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8210  --------------------------\n",
      "Train loss: 3.204695227486747\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.387855574289958\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  8220  --------------------------\n",
      "Train loss: 3.266680977003915\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.177311007181803\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8230  --------------------------\n",
      "Train loss: 3.1689047084535873\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.234555594126384\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8240  --------------------------\n",
      "Train loss: 3.185847614152091\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.215177783966064\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8250  --------------------------\n",
      "Train loss: 3.211533284187317\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.346577555338541\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8260  --------------------------\n",
      "Train loss: 3.2019380453654698\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.224910860061646\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  8270  --------------------------\n",
      "Train loss: 3.2118999740055627\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.308344484965007\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  8280  --------------------------\n",
      "Train loss: 3.1720285844802856\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.311855583190917\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8290  --------------------------\n",
      "Train loss: 3.1747142471585956\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.354677734375\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8300  --------------------------\n",
      "Train loss: 3.212290474346706\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.268144356409708\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8310  --------------------------\n",
      "Train loss: 3.1919714525767735\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.095366617838542\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8320  --------------------------\n",
      "Train loss: 3.2050142226900373\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.225699939727782\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8330  --------------------------\n",
      "Train loss: 3.2501095029285976\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.250166625976563\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8340  --------------------------\n",
      "Train loss: 3.1287095373017446\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.256933291753134\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8350  --------------------------\n",
      "Train loss: 3.167623768533979\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.234844392140706\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8360  --------------------------\n",
      "Train loss: 3.1656380823680332\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.276633097330729\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8370  --------------------------\n",
      "Train loss: 3.1707285935538154\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.4400222269694\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8380  --------------------------\n",
      "Train loss: 3.1735237959453038\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.25420009613037\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8390  --------------------------\n",
      "Train loss: 3.147152398654393\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.29056669553121\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8400  --------------------------\n",
      "Train loss: 3.2052333116531373\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.161277853647867\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8410  --------------------------\n",
      "Train loss: 3.2042428064346313\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.370288950602214\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8420  --------------------------\n",
      "Train loss: 3.2311951984677996\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.341466579437256\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8430  --------------------------\n",
      "Train loss: 3.2414809226989747\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.293655541737875\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8440  --------------------------\n",
      "Train loss: 3.1597999436514717\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.350833473205567\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8450  --------------------------\n",
      "Train loss: 3.1683238192967007\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.216666765213013\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8460  --------------------------\n",
      "Train loss: 3.146942847796849\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.414722194671631\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8470  --------------------------\n",
      "Train loss: 3.186990483828953\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.097488956451416\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8480  --------------------------\n",
      "Train loss: 3.193995248249599\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.251177806854248\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8490  --------------------------\n",
      "Train loss: 3.1809856714521136\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.166755568186442\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8500  --------------------------\n",
      "Train loss: 3.2126333325249807\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.097377694447836\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8510  --------------------------\n",
      "Train loss: 3.170009494509016\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.144611015319825\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8520  --------------------------\n",
      "Train loss: 3.159018996783665\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.17704444249471\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8530  --------------------------\n",
      "Train loss: 3.193938093866621\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.173188762664795\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8540  --------------------------\n",
      "Train loss: 3.148852355139596\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.14444434483846\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8550  --------------------------\n",
      "Train loss: 3.1403761632101874\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.28513333638509\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8560  --------------------------\n",
      "Train loss: 3.185323780945369\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.08528891245524\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8570  --------------------------\n",
      "Train loss: 3.211295208930969\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.131433359781902\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8580  --------------------------\n",
      "Train loss: 3.164033328465053\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.248033199310303\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8590  --------------------------\n",
      "Train loss: 3.1624857119151524\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.128155496915182\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8600  --------------------------\n",
      "Train loss: 3.1954856518336703\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.100822168986003\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8610  --------------------------\n",
      "Train loss: 3.1580380937031336\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.208099861145019\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8620  --------------------------\n",
      "Train loss: 3.1947618831907\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.144077796936035\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8630  --------------------------\n",
      "Train loss: 3.193733284132821\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.126544494628906\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8640  --------------------------\n",
      "Train loss: 3.1175285639081682\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.08907766342163\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8650  --------------------------\n",
      "Train loss: 3.2017380816595895\n",
      "Train accuracy: 0.9485714285714286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.292377738952636\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8660  --------------------------\n",
      "Train loss: 3.1750761679240633\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.07298900604248\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8670  --------------------------\n",
      "Train loss: 3.172357107571193\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.220211060841878\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8680  --------------------------\n",
      "Train loss: 3.1532857050214496\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.30273333231608\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8690  --------------------------\n",
      "Train loss: 3.1789951842171806\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.139355535507201\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  8700  --------------------------\n",
      "Train loss: 3.179309522083827\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.238644288380941\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8710  --------------------------\n",
      "Train loss: 3.1715285440853664\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.30545550028483\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8720  --------------------------\n",
      "Train loss: 3.150580937521798\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.099111162821451\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8730  --------------------------\n",
      "Train loss: 3.129919022151402\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.260933214823405\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8740  --------------------------\n",
      "Train loss: 3.203733316830226\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.124210993448893\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8750  --------------------------\n",
      "Train loss: 3.140790454319545\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.398322153091431\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  8760  --------------------------\n",
      "Train loss: 3.1199952370779855\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.172133394877116\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8770  --------------------------\n",
      "Train loss: 3.1713714177267893\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.22156650543213\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8780  --------------------------\n",
      "Train loss: 3.1806190490722654\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.264444726308186\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8790  --------------------------\n",
      "Train loss: 3.1524666380882262\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.11562219619751\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8800  --------------------------\n",
      "Train loss: 3.1177809248651775\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.029277947743735\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8810  --------------------------\n",
      "Train loss: 3.1556999914986745\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.150644512176514\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8820  --------------------------\n",
      "Train loss: 3.1583047887257165\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.110622272491455\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8830  --------------------------\n",
      "Train loss: 3.1264333275386265\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.037055511474609\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8840  --------------------------\n",
      "Train loss: 3.1834523483685087\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.125599988301595\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8850  --------------------------\n",
      "Train loss: 3.207999974659511\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.223744386037191\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8860  --------------------------\n",
      "Train loss: 3.139923822539193\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.097288824717204\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8870  --------------------------\n",
      "Train loss: 3.100161871910095\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.135277722676594\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8880  --------------------------\n",
      "Train loss: 3.134538062640599\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.328111209869384\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8890  --------------------------\n",
      "Train loss: 3.1607094860076903\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.167299849192302\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8900  --------------------------\n",
      "Train loss: 3.174052334172385\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.130466442108155\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8910  --------------------------\n",
      "Train loss: 3.16406662600381\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.088844413757323\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8920  --------------------------\n",
      "Train loss: 3.1667904247556415\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.112555570602417\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8930  --------------------------\n",
      "Train loss: 3.137999988964626\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.13076659520467\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8940  --------------------------\n",
      "Train loss: 3.145866678101676\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.126366545359293\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8950  --------------------------\n",
      "Train loss: 3.156357111930847\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.235699892044067\n",
      "Test accuracy: 0.89\n",
      "Epoch:  8960  --------------------------\n",
      "Train loss: 3.1775999600546703\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.171900116602579\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8970  --------------------------\n",
      "Train loss: 3.135547607966832\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.25788880666097\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  8980  --------------------------\n",
      "Train loss: 3.116019037791661\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.174533265431721\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  8990  --------------------------\n",
      "Train loss: 3.110838063103812\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.095177567799887\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9000  --------------------------\n",
      "Train loss: 3.1345571415764946\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.207010974884033\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9010  --------------------------\n",
      "Train loss: 3.1497285154887606\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.045488783518474\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9020  --------------------------\n",
      "Train loss: 3.1675571271351406\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.365944334665935\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9030  --------------------------\n",
      "Train loss: 3.158338073321751\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.10941100438436\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9040  --------------------------\n",
      "Train loss: 3.1500047557694573\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.165688778559367\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9050  --------------------------\n",
      "Train loss: 3.1293190615517754\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.206466585795084\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9060  --------------------------\n",
      "Train loss: 3.106561904634748\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.321988722483317\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9070  --------------------------\n",
      "Train loss: 3.1701428522382464\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.14476668993632\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9080  --------------------------\n",
      "Train loss: 3.1580285590035575\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.160977853139242\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9090  --------------------------\n",
      "Train loss: 3.1329190152032034\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.146855640411378\n",
      "Test accuracy: 0.91\n",
      "Epoch:  9100  --------------------------\n",
      "Train loss: 3.1455524151665823\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.23064466158549\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9110  --------------------------\n",
      "Train loss: 3.107980921609061\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.163099950154622\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9120  --------------------------\n",
      "Train loss: 3.1541189432144163\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.063111063639322\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9130  --------------------------\n",
      "Train loss: 3.155580912998744\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.268744150797525\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9140  --------------------------\n",
      "Train loss: 3.1074570955548966\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.284633274078368\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9150  --------------------------\n",
      "Train loss: 3.131380946976798\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.218455441792806\n",
      "Test accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9160  --------------------------\n",
      "Train loss: 3.1541047382354734\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.16867764790853\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9170  --------------------------\n",
      "Train loss: 3.119390447480338\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.299244448343913\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9180  --------------------------\n",
      "Train loss: 3.1705856697899955\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.190855433146158\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9190  --------------------------\n",
      "Train loss: 3.1280380926813396\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.154922103881836\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9200  --------------------------\n",
      "Train loss: 3.094757102557591\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.162155561447143\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9210  --------------------------\n",
      "Train loss: 3.114433309010097\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.18653325398763\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9220  --------------------------\n",
      "Train loss: 3.1336142594473704\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.311811100641886\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9230  --------------------------\n",
      "Train loss: 3.1519808949743\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.37640012105306\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9240  --------------------------\n",
      "Train loss: 3.0714808988571165\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.136999950408935\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  9250  --------------------------\n",
      "Train loss: 3.1573999990735735\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.22859990119934\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9260  --------------------------\n",
      "Train loss: 3.058819044658116\n",
      "Train accuracy: 0.96\n",
      "Test loss: 8.071999988555909\n",
      "Test accuracy: 0.91\n",
      "Epoch:  9270  --------------------------\n",
      "Train loss: 3.081223784855434\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.216211036046346\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  9280  --------------------------\n",
      "Train loss: 3.133390476363046\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.152588707605998\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9290  --------------------------\n",
      "Train loss: 3.1258142505373274\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.125388793945312\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9300  --------------------------\n",
      "Train loss: 3.1001856899261475\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.123455613454183\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9310  --------------------------\n",
      "Train loss: 3.11264760357993\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.228177671432496\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9320  --------------------------\n",
      "Train loss: 3.1322285301344737\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.256355590820313\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9330  --------------------------\n",
      "Train loss: 3.1109856905255997\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.094033393859863\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9340  --------------------------\n",
      "Train loss: 3.094547566005162\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.220799849828085\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9350  --------------------------\n",
      "Train loss: 3.1394142494882855\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.173722171783448\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9360  --------------------------\n",
      "Train loss: 3.117228499140058\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.104788777033487\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9370  --------------------------\n",
      "Train loss: 3.1008904913493565\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.08152219772339\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9380  --------------------------\n",
      "Train loss: 3.1015951831000192\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.200488815307617\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9390  --------------------------\n",
      "Train loss: 3.1159380565370833\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.110211257934571\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9400  --------------------------\n",
      "Train loss: 3.1162047515596663\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.254677677154541\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  9410  --------------------------\n",
      "Train loss: 3.117538083621434\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.203144302368164\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  9420  --------------------------\n",
      "Train loss: 3.1245666214397976\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.219744440714518\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9430  --------------------------\n",
      "Train loss: 3.1165666341781617\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.150944391886393\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9440  --------------------------\n",
      "Train loss: 3.086538077081953\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.98623327255249\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  9450  --------------------------\n",
      "Train loss: 3.044676169667925\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.111666606267294\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9460  --------------------------\n",
      "Train loss: 3.095614279338292\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.055310980478923\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9470  --------------------------\n",
      "Train loss: 3.0846523680005755\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.036244525909424\n",
      "Test accuracy: 0.9\n",
      "Epoch:  9480  --------------------------\n",
      "Train loss: 3.082157130241394\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.020388867060344\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9490  --------------------------\n",
      "Train loss: 3.051938123021807\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.253722241719563\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9500  --------------------------\n",
      "Train loss: 3.086842862537929\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.091177717844646\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9510  --------------------------\n",
      "Train loss: 3.0875904628208706\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.1125\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9520  --------------------------\n",
      "Train loss: 3.124033269882202\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.060610976219177\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9530  --------------------------\n",
      "Train loss: 3.1351618821280343\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.064688787460327\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9540  --------------------------\n",
      "Train loss: 3.104976120676313\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.167033150990804\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9550  --------------------------\n",
      "Train loss: 3.09783809866224\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.077088896433512\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9560  --------------------------\n",
      "Train loss: 3.114299965585981\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.005433006286621\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9570  --------------------------\n",
      "Train loss: 3.100042779786246\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.085510932604471\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9580  --------------------------\n",
      "Train loss: 3.1091094616481234\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.119322121938069\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9590  --------------------------\n",
      "Train loss: 3.129666621685028\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.11704439798991\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9600  --------------------------\n",
      "Train loss: 3.113076182774135\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.05513328552246\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9610  --------------------------\n",
      "Train loss: 3.09238094329834\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.112644430796305\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9620  --------------------------\n",
      "Train loss: 3.1255047103336877\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.14733304977417\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9630  --------------------------\n",
      "Train loss: 3.069547537394932\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.326411062876383\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9640  --------------------------\n",
      "Train loss: 3.0806332901545934\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.27988886833191\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9650  --------------------------\n",
      "Train loss: 3.104280890056065\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.186477654774984\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9660  --------------------------\n",
      "Train loss: 3.054885632651193\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.148621934254964\n",
      "Test accuracy: 0.8933333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  9670  --------------------------\n",
      "Train loss: 3.0791142102650233\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.223288758595784\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9680  --------------------------\n",
      "Train loss: 3.090271427971976\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.263333218892415\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9690  --------------------------\n",
      "Train loss: 3.089028503554208\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.274933223724366\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9700  --------------------------\n",
      "Train loss: 3.041766631943839\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.225110966364543\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9710  --------------------------\n",
      "Train loss: 3.0941094403607505\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.075933361053467\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  9720  --------------------------\n",
      "Train loss: 3.0892142500196185\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.174022146860759\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9730  --------------------------\n",
      "Train loss: 3.085752400670733\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.290955435434977\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  9740  --------------------------\n",
      "Train loss: 3.099004763875689\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.202588691711426\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9750  --------------------------\n",
      "Train loss: 3.0792237670081004\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.180666516621908\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9760  --------------------------\n",
      "Train loss: 3.0790618453707013\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.03449997584025\n",
      "Test accuracy: 0.91\n",
      "Epoch:  9770  --------------------------\n",
      "Train loss: 3.097828540802002\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.19628885904948\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9780  --------------------------\n",
      "Train loss: 3.045266672543117\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.197788931528727\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9790  --------------------------\n",
      "Train loss: 3.0638190146854947\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.238266592025758\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  9800  --------------------------\n",
      "Train loss: 3.0749142381123136\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.136522223154703\n",
      "Test accuracy: 0.91\n",
      "Epoch:  9810  --------------------------\n",
      "Train loss: 3.0518190254483906\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.138599926630656\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  9820  --------------------------\n",
      "Train loss: 3.0754761232648575\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.045399837493896\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9830  --------------------------\n",
      "Train loss: 3.08433328969138\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.28342229684194\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  9840  --------------------------\n",
      "Train loss: 3.0823761538096837\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.252588853836059\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9850  --------------------------\n",
      "Train loss: 3.068090441226959\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.226333314577738\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9860  --------------------------\n",
      "Train loss: 3.0610047040666855\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.256233399709066\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9870  --------------------------\n",
      "Train loss: 3.0613190249034337\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.05185557683309\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9880  --------------------------\n",
      "Train loss: 3.059542851448059\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.057844320933023\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  9890  --------------------------\n",
      "Train loss: 3.06789046389716\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.201444489161174\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9900  --------------------------\n",
      "Train loss: 3.059866625240871\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.239099966684977\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  9910  --------------------------\n",
      "Train loss: 3.080280910219465\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.113755620320639\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9920  --------------------------\n",
      "Train loss: 3.0819618722370694\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.112888663609823\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  9930  --------------------------\n",
      "Train loss: 3.095647623198373\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.203255316416422\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9940  --------------------------\n",
      "Train loss: 3.088366665840149\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.065788799921672\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9950  --------------------------\n",
      "Train loss: 3.0871523400715417\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.101377824147542\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9960  --------------------------\n",
      "Train loss: 3.096328551598958\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.09686653137207\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9970  --------------------------\n",
      "Train loss: 3.0969190413611276\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.188299922943115\n",
      "Test accuracy: 0.89\n",
      "Epoch:  9980  --------------------------\n",
      "Train loss: 3.0555237865448\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.057833245595296\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  9990  --------------------------\n",
      "Train loss: 3.088195223467691\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.215944379170736\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10000  --------------------------\n",
      "Train loss: 3.09170949118478\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.108744319279989\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10010  --------------------------\n",
      "Train loss: 3.0943856593540735\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.035044415791829\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10020  --------------------------\n",
      "Train loss: 3.0921999638421194\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.263477884928385\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10030  --------------------------\n",
      "Train loss: 3.0741189997536797\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.333444468180339\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  10040  --------------------------\n",
      "Train loss: 3.097433342933655\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.095044441223145\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10050  --------------------------\n",
      "Train loss: 3.0973571678570337\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.07549997329712\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10060  --------------------------\n",
      "Train loss: 3.0972666553088595\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.09382207552592\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10070  --------------------------\n",
      "Train loss: 3.0843523243495397\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.205711085001628\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10080  --------------------------\n",
      "Train loss: 3.066828557423183\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.10812213897705\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10090  --------------------------\n",
      "Train loss: 3.0735237434932166\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.16993333498637\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10100  --------------------------\n",
      "Train loss: 3.077776168073927\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.050644474029541\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10110  --------------------------\n",
      "Train loss: 3.0651571215902056\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.09413335164388\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10120  --------------------------\n",
      "Train loss: 3.073866631644113\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.175244309107462\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10130  --------------------------\n",
      "Train loss: 3.071285659245082\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.33285566965739\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10140  --------------------------\n",
      "Train loss: 3.0297332872663225\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.053277708689372\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  10150  --------------------------\n",
      "Train loss: 3.0594047594070433\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.24562209447225\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10160  --------------------------\n",
      "Train loss: 3.074971397944859\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.073499952952067\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10170  --------------------------\n",
      "Train loss: 3.041409492492676\n",
      "Train accuracy: 0.9485714285714286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.27517770767212\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10180  --------------------------\n",
      "Train loss: 3.0556618469102044\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.084522126515706\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  10190  --------------------------\n",
      "Train loss: 3.0648571137019567\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.014977652231853\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10200  --------------------------\n",
      "Train loss: 3.0551094722747805\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.229433104197184\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10210  --------------------------\n",
      "Train loss: 3.043471416745867\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.222266534169515\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10220  --------------------------\n",
      "Train loss: 3.0568524193763733\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.12694449742635\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  10230  --------------------------\n",
      "Train loss: 3.0119857239723205\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.022388807932536\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10240  --------------------------\n",
      "Train loss: 3.0611666032246183\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.127799943288167\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10250  --------------------------\n",
      "Train loss: 3.027461849621364\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.15899984995524\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10260  --------------------------\n",
      "Train loss: 3.021866660118103\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.037210960388183\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10270  --------------------------\n",
      "Train loss: 3.0444095168794902\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.261822156906128\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10280  --------------------------\n",
      "Train loss: 3.040942836488996\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.134511108398437\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10290  --------------------------\n",
      "Train loss: 3.0841000093732562\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.0771888478597\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10300  --------------------------\n",
      "Train loss: 3.079571383340018\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.10906655629476\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10310  --------------------------\n",
      "Train loss: 3.0117761741365707\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.022688767115275\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10320  --------------------------\n",
      "Train loss: 3.0016761554990494\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.17841108640035\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10330  --------------------------\n",
      "Train loss: 3.0339999539511546\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.23848884264628\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10340  --------------------------\n",
      "Train loss: 3.1158999606541227\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.297599970499675\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10350  --------------------------\n",
      "Train loss: 3.0578856631687708\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.078488801320393\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10360  --------------------------\n",
      "Train loss: 3.0247666311264036\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.071688906351726\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10370  --------------------------\n",
      "Train loss: 3.026695212636675\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.166844234466552\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10380  --------------------------\n",
      "Train loss: 3.075061903681074\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.157299861907958\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10390  --------------------------\n",
      "Train loss: 3.041980925968715\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.07322208404541\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10400  --------------------------\n",
      "Train loss: 3.026857142448425\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.069610970815022\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10410  --------------------------\n",
      "Train loss: 3.0316380902699063\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.174622198740641\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10420  --------------------------\n",
      "Train loss: 3.0888904346738544\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.107133353551228\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10430  --------------------------\n",
      "Train loss: 3.044061916896275\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.129055452346801\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10440  --------------------------\n",
      "Train loss: 3.027323817525591\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.141366551717123\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10450  --------------------------\n",
      "Train loss: 3.0440952287401473\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.310288515090942\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10460  --------------------------\n",
      "Train loss: 3.0452618994031635\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.20819993019104\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10470  --------------------------\n",
      "Train loss: 3.029095186505999\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.093366575241088\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10480  --------------------------\n",
      "Train loss: 3.0845047521591185\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.206999918619792\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10490  --------------------------\n",
      "Train loss: 2.9946428189958847\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.228910992940268\n",
      "Test accuracy: 0.9\n",
      "Epoch:  10500  --------------------------\n",
      "Train loss: 3.0257047394343783\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.24523328145345\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10510  --------------------------\n",
      "Train loss: 3.083519023486546\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.221688922246297\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10520  --------------------------\n",
      "Train loss: 3.0097238057000295\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.283600018819174\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10530  --------------------------\n",
      "Train loss: 3.0374951928002494\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.169155356089274\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10540  --------------------------\n",
      "Train loss: 3.0444285198620387\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.038144321441651\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10550  --------------------------\n",
      "Train loss: 3.043871398653303\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.351766681671142\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10560  --------------------------\n",
      "Train loss: 3.003499982016427\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.111766633987427\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10570  --------------------------\n",
      "Train loss: 2.9913332881246295\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.076377537250519\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10580  --------------------------\n",
      "Train loss: 3.029190466403961\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.058322035471598\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10590  --------------------------\n",
      "Train loss: 3.0080190379279\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.048011083602905\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10600  --------------------------\n",
      "Train loss: 3.0310666050229753\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.99938879330953\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10610  --------------------------\n",
      "Train loss: 3.0043142179080418\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.123400007883708\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10620  --------------------------\n",
      "Train loss: 3.0151713732310705\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.18249989191691\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10630  --------------------------\n",
      "Train loss: 3.00162376335689\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.069977674484253\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10640  --------------------------\n",
      "Train loss: 3.008238060133798\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.040566527048746\n",
      "Test accuracy: 0.91\n",
      "Epoch:  10650  --------------------------\n",
      "Train loss: 3.0065999283109393\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.23313325881958\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10660  --------------------------\n",
      "Train loss: 3.0368904290880474\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.046033306121826\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10670  --------------------------\n",
      "Train loss: 3.0631857000078475\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.15501096089681\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10680  --------------------------\n",
      "Train loss: 3.0369190161568778\n",
      "Train accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.04259972890218\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10690  --------------------------\n",
      "Train loss: 3.006766651017325\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.211788730621338\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10700  --------------------------\n",
      "Train loss: 2.978204778262547\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.225899957021078\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10710  --------------------------\n",
      "Train loss: 3.0140857437678745\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.154833262761434\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10720  --------------------------\n",
      "Train loss: 3.0861142553601946\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.06494447072347\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10730  --------------------------\n",
      "Train loss: 3.0461761120387485\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.23609990119934\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10740  --------------------------\n",
      "Train loss: 3.0089713852746147\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.05519993464152\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10750  --------------------------\n",
      "Train loss: 3.051390448297773\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.042944428126017\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10760  --------------------------\n",
      "Train loss: 3.0147047339166915\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.088377831776937\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10770  --------------------------\n",
      "Train loss: 3.0255094477108546\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.104944413503011\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10780  --------------------------\n",
      "Train loss: 3.025185684135982\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.091622161865235\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10790  --------------------------\n",
      "Train loss: 2.987404774257115\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.979999853769939\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10800  --------------------------\n",
      "Train loss: 3.0125999477931433\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.103222115834553\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10810  --------------------------\n",
      "Train loss: 3.0184428208214897\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.250288963317871\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10820  --------------------------\n",
      "Train loss: 3.0105476433890206\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.040788962046305\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10830  --------------------------\n",
      "Train loss: 3.0255285508292062\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.09887766202291\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10840  --------------------------\n",
      "Train loss: 3.038357140677316\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.173644307454428\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10850  --------------------------\n",
      "Train loss: 2.985380948611668\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.006622193654378\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10860  --------------------------\n",
      "Train loss: 3.033314257689885\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.04313331604004\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10870  --------------------------\n",
      "Train loss: 2.9894332674571444\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.201166645685833\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10880  --------------------------\n",
      "Train loss: 3.008595165184566\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.162088921864827\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10890  --------------------------\n",
      "Train loss: 3.0020094789777483\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.21913330078125\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10900  --------------------------\n",
      "Train loss: 2.9845047651018417\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.23397773106893\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  10910  --------------------------\n",
      "Train loss: 3.0239428547450475\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.059533224105834\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10920  --------------------------\n",
      "Train loss: 3.0042809104919432\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.139944383303325\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10930  --------------------------\n",
      "Train loss: 3.012190498624529\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.116055456797282\n",
      "Test accuracy: 0.89\n",
      "Epoch:  10940  --------------------------\n",
      "Train loss: 2.9946190711430143\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.118077837626139\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10950  --------------------------\n",
      "Train loss: 3.0045523677553447\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.251744384765624\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10960  --------------------------\n",
      "Train loss: 3.030628503731319\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.980677731831869\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  10970  --------------------------\n",
      "Train loss: 3.0089714087758748\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.063399937947592\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10980  --------------------------\n",
      "Train loss: 3.0165428134373258\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.144477678934733\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  10990  --------------------------\n",
      "Train loss: 3.0018333223887854\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.301611003875733\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11000  --------------------------\n",
      "Train loss: 3.0052095552853175\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.987444438934326\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11010  --------------------------\n",
      "Train loss: 3.0040285914284843\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.095244280497234\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11020  --------------------------\n",
      "Train loss: 3.020014245850699\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.076333274841309\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11030  --------------------------\n",
      "Train loss: 3.0161333087512423\n",
      "Train accuracy: 0.94\n",
      "Test loss: 8.268655567169189\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11040  --------------------------\n",
      "Train loss: 3.017680912699018\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.064266649881999\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11050  --------------------------\n",
      "Train loss: 2.9946666417803085\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.117688911755879\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11060  --------------------------\n",
      "Train loss: 3.020557149478367\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.009255495071411\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11070  --------------------------\n",
      "Train loss: 3.0255428743362427\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.112655506134033\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11080  --------------------------\n",
      "Train loss: 3.0199571125847955\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.095911064147948\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11090  --------------------------\n",
      "Train loss: 2.972018976211548\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.358444430033366\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11100  --------------------------\n",
      "Train loss: 2.962638077735901\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.03974443435669\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  11110  --------------------------\n",
      "Train loss: 3.0218523618153164\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.005311133066813\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11120  --------------------------\n",
      "Train loss: 2.9832999437195915\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.281066665649414\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11130  --------------------------\n",
      "Train loss: 3.0108428525924684\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.021711057027181\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11140  --------------------------\n",
      "Train loss: 3.025795191356114\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.058277746836344\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11150  --------------------------\n",
      "Train loss: 3.0252238157817297\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.063388767242431\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11160  --------------------------\n",
      "Train loss: 3.01425705909729\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.469111124674479\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11170  --------------------------\n",
      "Train loss: 3.0024856798989434\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.192588812510172\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11180  --------------------------\n",
      "Train loss: 2.9797427790505546\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.135177733103435\n",
      "Test accuracy: 0.8933333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11190  --------------------------\n",
      "Train loss: 3.0027476031439644\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.054633337656657\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11200  --------------------------\n",
      "Train loss: 2.983085733822414\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.086677888234457\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11210  --------------------------\n",
      "Train loss: 3.0043618849345615\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.11176663716634\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11220  --------------------------\n",
      "Train loss: 2.95015237058912\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.25791106859843\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11230  --------------------------\n",
      "Train loss: 3.0066761759349276\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.260344282786052\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11240  --------------------------\n",
      "Train loss: 2.9688952456201827\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.040488780339558\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11250  --------------------------\n",
      "Train loss: 3.0057523829596384\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.046477603912354\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11260  --------------------------\n",
      "Train loss: 2.98043806212289\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.079933211008708\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11270  --------------------------\n",
      "Train loss: 3.0104380675724576\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.078455543518066\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11280  --------------------------\n",
      "Train loss: 2.95570948941367\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.007577616373698\n",
      "Test accuracy: 0.91\n",
      "Epoch:  11290  --------------------------\n",
      "Train loss: 2.999004770006452\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.933033383687337\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11300  --------------------------\n",
      "Train loss: 2.979352399962289\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.08847765604655\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11310  --------------------------\n",
      "Train loss: 2.9649285571915764\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.123922080993653\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11320  --------------------------\n",
      "Train loss: 2.9594190086637226\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.095688978830973\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  11330  --------------------------\n",
      "Train loss: 2.941614273275648\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.267510999043783\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11340  --------------------------\n",
      "Train loss: 2.9649571200779508\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.175555528004963\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  11350  --------------------------\n",
      "Train loss: 2.985052396229335\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.188311020533243\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11360  --------------------------\n",
      "Train loss: 2.9508094981738497\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.134622249603272\n",
      "Test accuracy: 0.91\n",
      "Epoch:  11370  --------------------------\n",
      "Train loss: 2.9681332867486137\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.168022244771322\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11380  --------------------------\n",
      "Train loss: 2.9560714421953476\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.224133288065593\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11390  --------------------------\n",
      "Train loss: 3.0043952648980277\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.080422217051188\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11400  --------------------------\n",
      "Train loss: 3.006761895588466\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.162088883717855\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11410  --------------------------\n",
      "Train loss: 3.019961830547878\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.05123326619466\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11420  --------------------------\n",
      "Train loss: 2.989457130091531\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.132277717590332\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11430  --------------------------\n",
      "Train loss: 3.006661846637726\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.142922223409016\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11440  --------------------------\n",
      "Train loss: 3.008685656615666\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.130766690572102\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11450  --------------------------\n",
      "Train loss: 2.9577666875294275\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.20928884188334\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11460  --------------------------\n",
      "Train loss: 3.0311618552889144\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.091433347066243\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11470  --------------------------\n",
      "Train loss: 2.983585708481925\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.15614418665568\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11480  --------------------------\n",
      "Train loss: 2.9968761839185443\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.131577628453572\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11490  --------------------------\n",
      "Train loss: 3.011423795563834\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.245211092631022\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11500  --------------------------\n",
      "Train loss: 2.9873999411719185\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.110710989634196\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11510  --------------------------\n",
      "Train loss: 3.030019014562879\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.168488931655883\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11520  --------------------------\n",
      "Train loss: 3.0134428075381687\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.05215565363566\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11530  --------------------------\n",
      "Train loss: 2.9903332802227567\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.02731113433838\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11540  --------------------------\n",
      "Train loss: 2.964495258331299\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.293944352467856\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11550  --------------------------\n",
      "Train loss: 2.902904735973903\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.09094441095988\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11560  --------------------------\n",
      "Train loss: 3.010561898776463\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.045455449422201\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11570  --------------------------\n",
      "Train loss: 3.0078380257742747\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.170899899800618\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11580  --------------------------\n",
      "Train loss: 2.9815284981046406\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.174744300842285\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11590  --------------------------\n",
      "Train loss: 2.9659285736083985\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.15582234064738\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11600  --------------------------\n",
      "Train loss: 2.9975333649771554\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.089833065668742\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11610  --------------------------\n",
      "Train loss: 2.9851809331348966\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.066500072479249\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11620  --------------------------\n",
      "Train loss: 3.0199333538327897\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.99239990234375\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11630  --------------------------\n",
      "Train loss: 2.9920142510959082\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.228299878438314\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11640  --------------------------\n",
      "Train loss: 3.0018713889803204\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.211966552734374\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11650  --------------------------\n",
      "Train loss: 2.9650856593676975\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.253944384256998\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11660  --------------------------\n",
      "Train loss: 2.980809520993914\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.197855396270752\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11670  --------------------------\n",
      "Train loss: 3.004499953814915\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.15338882446289\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11680  --------------------------\n",
      "Train loss: 2.942514251981463\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.259377667109172\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11690  --------------------------\n",
      "Train loss: 2.988238047191075\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.122210925420125\n",
      "Test accuracy: 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  11700  --------------------------\n",
      "Train loss: 2.9817856465067183\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.145555426279703\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11710  --------------------------\n",
      "Train loss: 2.963457087789263\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.065755513509115\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11720  --------------------------\n",
      "Train loss: 2.9712904521397183\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.010322081247965\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11730  --------------------------\n",
      "Train loss: 3.0059904629843577\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.231011079947153\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11740  --------------------------\n",
      "Train loss: 2.9686523267201017\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.070355450312297\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11750  --------------------------\n",
      "Train loss: 2.9700428336007256\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.088588835398356\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11760  --------------------------\n",
      "Train loss: 3.0053476095199585\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.144488814671835\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11770  --------------------------\n",
      "Train loss: 2.9595333007403783\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.147755355834962\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11780  --------------------------\n",
      "Train loss: 3.0070428698403493\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.107988878885905\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11790  --------------------------\n",
      "Train loss: 2.982395188467843\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.999033247629802\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11800  --------------------------\n",
      "Train loss: 2.9750618955067227\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.105311241149902\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11810  --------------------------\n",
      "Train loss: 2.9950713757106238\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.172644230524698\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11820  --------------------------\n",
      "Train loss: 2.9953333003180367\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.129311122894286\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11830  --------------------------\n",
      "Train loss: 2.996914292063032\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.062433319091797\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  11840  --------------------------\n",
      "Train loss: 2.9216809626988\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.147988736629486\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11850  --------------------------\n",
      "Train loss: 2.9193190452030726\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.220833276112874\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11860  --------------------------\n",
      "Train loss: 2.961428563935416\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.419866631825766\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11870  --------------------------\n",
      "Train loss: 2.979228593962533\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.102611004511516\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11880  --------------------------\n",
      "Train loss: 2.978866686820984\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.22177760442098\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11890  --------------------------\n",
      "Train loss: 2.961114260809762\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.361933224995932\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11900  --------------------------\n",
      "Train loss: 2.9847142546517507\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.00874444961548\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11910  --------------------------\n",
      "Train loss: 2.983557083947318\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.12983351389567\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11920  --------------------------\n",
      "Train loss: 3.003495193549565\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.113066641489665\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11930  --------------------------\n",
      "Train loss: 3.0085809023039682\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.04783327738444\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11940  --------------------------\n",
      "Train loss: 2.9566285538673402\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.29630007425944\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11950  --------------------------\n",
      "Train loss: 3.0001952266693115\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.084433161417643\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  11960  --------------------------\n",
      "Train loss: 2.998757084437779\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.071766659418742\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11970  --------------------------\n",
      "Train loss: 2.936752389839717\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.199544506072998\n",
      "Test accuracy: 0.89\n",
      "Epoch:  11980  --------------------------\n",
      "Train loss: 2.968842866080148\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.073810971577963\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  11990  --------------------------\n",
      "Train loss: 2.98387141091483\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.045899957021078\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12000  --------------------------\n",
      "Train loss: 2.937271399157388\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.0575332959493\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12010  --------------------------\n",
      "Train loss: 2.9388332755225046\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.276233342488608\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12020  --------------------------\n",
      "Train loss: 2.9952094881875175\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.198788887659708\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12030  --------------------------\n",
      "Train loss: 2.984909486089434\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.289122152328492\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12040  --------------------------\n",
      "Train loss: 2.968642816884177\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.108644440968831\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12050  --------------------------\n",
      "Train loss: 2.9740142485073635\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.212944094340006\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12060  --------------------------\n",
      "Train loss: 2.996204717840467\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.132355359395346\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12070  --------------------------\n",
      "Train loss: 3.016980971438544\n",
      "Train accuracy: 0.94\n",
      "Test loss: 8.146833283106487\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12080  --------------------------\n",
      "Train loss: 2.9969142614092146\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.155877679189047\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12090  --------------------------\n",
      "Train loss: 2.9655809238978796\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.120299930572509\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12100  --------------------------\n",
      "Train loss: 2.984223818778992\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.17559986114502\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12110  --------------------------\n",
      "Train loss: 2.9542237874439783\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.06974427541097\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12120  --------------------------\n",
      "Train loss: 2.989133332116263\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.090466480255127\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12130  --------------------------\n",
      "Train loss: 2.9631856768471856\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.339033336639405\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12140  --------------------------\n",
      "Train loss: 2.978542834009443\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.364177926381428\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12150  --------------------------\n",
      "Train loss: 2.9862142624173846\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.124411271413168\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12160  --------------------------\n",
      "Train loss: 3.0032809455054146\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.042022384007772\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12170  --------------------------\n",
      "Train loss: 2.93585241317749\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.160122133890788\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12180  --------------------------\n",
      "Train loss: 2.9473142310551235\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.246455465952556\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12190  --------------------------\n",
      "Train loss: 2.9706333330699377\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.258866558074951\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12200  --------------------------\n",
      "Train loss: 2.966542843750545\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.095044377644857\n",
      "Test accuracy: 0.8966666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  12210  --------------------------\n",
      "Train loss: 3.014999978882926\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.252122116088866\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12220  --------------------------\n",
      "Train loss: 2.9820809473310197\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.1121555519104\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  12230  --------------------------\n",
      "Train loss: 2.9956475523539954\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.15380000114441\n",
      "Test accuracy: 0.89\n",
      "Epoch:  12240  --------------------------\n",
      "Train loss: 2.9375047070639475\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.244711020787557\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12250  --------------------------\n",
      "Train loss: 2.9795142378125874\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.195566631952921\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12260  --------------------------\n",
      "Train loss: 2.985376170022147\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.117522083918253\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  12270  --------------------------\n",
      "Train loss: 2.9600237900870185\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.069344282150269\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12280  --------------------------\n",
      "Train loss: 2.9630238028935025\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.074199891090393\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12290  --------------------------\n",
      "Train loss: 2.9615523638044086\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.221977787017822\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12300  --------------------------\n",
      "Train loss: 2.935290449006217\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.137822230656942\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12310  --------------------------\n",
      "Train loss: 2.9147285434177945\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.0707443745931\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12320  --------------------------\n",
      "Train loss: 2.963480931690761\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.014155489603679\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12330  --------------------------\n",
      "Train loss: 2.9627618626185828\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.056644376118978\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12340  --------------------------\n",
      "Train loss: 2.958747583116804\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.111799964904785\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12350  --------------------------\n",
      "Train loss: 2.956599989618574\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.103977642059327\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12360  --------------------------\n",
      "Train loss: 2.964057125364031\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.994888871510824\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12370  --------------------------\n",
      "Train loss: 2.9719428219114032\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.06171101252238\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12380  --------------------------\n",
      "Train loss: 2.9453428016390117\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.232211093902588\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12390  --------------------------\n",
      "Train loss: 2.9589952319008965\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.297444502512613\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12400  --------------------------\n",
      "Train loss: 2.9361142417362758\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.044522059758505\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12410  --------------------------\n",
      "Train loss: 2.964928526197161\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.137677485148112\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12420  --------------------------\n",
      "Train loss: 2.982733310971941\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.013588803609212\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12430  --------------------------\n",
      "Train loss: 2.943709452833448\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.10308897336324\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12440  --------------------------\n",
      "Train loss: 2.958204711505345\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.217322095235188\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12450  --------------------------\n",
      "Train loss: 2.9651142617634365\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.13891137123108\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12460  --------------------------\n",
      "Train loss: 2.949571438516889\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.069033241271972\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12470  --------------------------\n",
      "Train loss: 2.95632376738957\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.0704110399882\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12480  --------------------------\n",
      "Train loss: 2.9686809158325196\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.161366608937582\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12490  --------------------------\n",
      "Train loss: 2.9668286098752703\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.065788815816244\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12500  --------------------------\n",
      "Train loss: 2.9631142902374266\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.942555570602417\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12510  --------------------------\n",
      "Train loss: 2.950261937890734\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.9610220845540365\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12520  --------------------------\n",
      "Train loss: 2.9471904863630023\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.037510973612468\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12530  --------------------------\n",
      "Train loss: 2.939557112285069\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.103055483500162\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12540  --------------------------\n",
      "Train loss: 2.956757102353232\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.089666582743327\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12550  --------------------------\n",
      "Train loss: 2.9676856844765798\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.094866542816161\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12560  --------------------------\n",
      "Train loss: 2.931666628292629\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.893044439951579\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12570  --------------------------\n",
      "Train loss: 2.944499966757638\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.199011063575744\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12580  --------------------------\n",
      "Train loss: 2.9077428988048006\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.227155555089315\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12590  --------------------------\n",
      "Train loss: 2.9100523815836223\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.193688815434774\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12600  --------------------------\n",
      "Train loss: 2.959480936186654\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.092211023966472\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12610  --------------------------\n",
      "Train loss: 2.961738052368164\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.934511165618897\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12620  --------------------------\n",
      "Train loss: 2.9529952015195575\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.026711098353069\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12630  --------------------------\n",
      "Train loss: 2.95317615372794\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.969077768325806\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12640  --------------------------\n",
      "Train loss: 2.897261896814619\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.07837776184082\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12650  --------------------------\n",
      "Train loss: 2.9624856856891086\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.146866512298583\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  12660  --------------------------\n",
      "Train loss: 2.966199936185564\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.090877593358357\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12670  --------------------------\n",
      "Train loss: 2.9598571382250105\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.113755575815837\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12680  --------------------------\n",
      "Train loss: 2.9602952160154072\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.063799845377604\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12690  --------------------------\n",
      "Train loss: 2.953495227268764\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.418255564371744\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12700  --------------------------\n",
      "Train loss: 2.928342832497188\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.973544387817383\n",
      "Test accuracy: 0.92\n",
      "Epoch:  12710  --------------------------\n",
      "Train loss: 2.933890390736716\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.979333273569742\n",
      "Test accuracy: 0.92\n",
      "Epoch:  12720  --------------------------\n",
      "Train loss: 2.9208713803972515\n",
      "Train accuracy: 0.9471428571428572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.085310961405437\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12730  --------------------------\n",
      "Train loss: 2.9131666782924106\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.192277666727701\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12740  --------------------------\n",
      "Train loss: 2.9625333452224734\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.018433307011922\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12750  --------------------------\n",
      "Train loss: 2.954642810480935\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.076355555852254\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12760  --------------------------\n",
      "Train loss: 2.9410999407087055\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.21325545946757\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12770  --------------------------\n",
      "Train loss: 2.932228558404105\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.019899853070577\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12780  --------------------------\n",
      "Train loss: 2.9379618794577462\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.09213322321574\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12790  --------------------------\n",
      "Train loss: 2.949357101576669\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.984300038019816\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  12800  --------------------------\n",
      "Train loss: 2.9338952139445715\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.074599968592326\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12810  --------------------------\n",
      "Train loss: 2.931476182256426\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.071577657063802\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12820  --------------------------\n",
      "Train loss: 2.964452372959682\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.197721996307372\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12830  --------------------------\n",
      "Train loss: 2.908423788206918\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.054255558649698\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12840  --------------------------\n",
      "Train loss: 2.922914306436266\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.05441107749939\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12850  --------------------------\n",
      "Train loss: 2.9215047757966177\n",
      "Train accuracy: 0.9414285714285714\n",
      "Test loss: 7.989399960835775\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12860  --------------------------\n",
      "Train loss: 2.9406809513909478\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.076777744293214\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12870  --------------------------\n",
      "Train loss: 2.895085696492876\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.437244551976521\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12880  --------------------------\n",
      "Train loss: 2.9375951978138515\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.198566563924153\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12890  --------------------------\n",
      "Train loss: 2.9150142567498345\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.003144499460856\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12900  --------------------------\n",
      "Train loss: 2.929938054765974\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.102955513000488\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12910  --------------------------\n",
      "Train loss: 2.9615285491943357\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.10862206141154\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12920  --------------------------\n",
      "Train loss: 2.905904811450413\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.027366708119711\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  12930  --------------------------\n",
      "Train loss: 2.934680938039507\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.069844309488932\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12940  --------------------------\n",
      "Train loss: 2.9399190357753207\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.078344357808431\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12950  --------------------------\n",
      "Train loss: 2.94673803125109\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.050122159322102\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12960  --------------------------\n",
      "Train loss: 2.954804697036743\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.14616668065389\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  12970  --------------------------\n",
      "Train loss: 2.923447641645159\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.249444332122803\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  12980  --------------------------\n",
      "Train loss: 2.9251475756508962\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.262122109731038\n",
      "Test accuracy: 0.9\n",
      "Epoch:  12990  --------------------------\n",
      "Train loss: 2.934538050379072\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.062944399515787\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13000  --------------------------\n",
      "Train loss: 2.888685675348554\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.239511114756267\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13010  --------------------------\n",
      "Train loss: 2.908680964197431\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.115266574223837\n",
      "Test accuracy: 0.9\n",
      "Epoch:  13020  --------------------------\n",
      "Train loss: 2.9290046882629395\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.132333291371664\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13030  --------------------------\n",
      "Train loss: 2.922161884307861\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.316188831329345\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13040  --------------------------\n",
      "Train loss: 2.9760095170566014\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.174310830434164\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13050  --------------------------\n",
      "Train loss: 2.915738077844892\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.114433380762735\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  13060  --------------------------\n",
      "Train loss: 2.895999985422407\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.142099984486897\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13070  --------------------------\n",
      "Train loss: 2.9507856634684972\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.17551108678182\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13080  --------------------------\n",
      "Train loss: 2.9275856569835117\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.07873330116272\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13090  --------------------------\n",
      "Train loss: 2.9312333468028475\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.11414454460144\n",
      "Test accuracy: 0.9\n",
      "Epoch:  13100  --------------------------\n",
      "Train loss: 2.9318476329530987\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.165389003753662\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13110  --------------------------\n",
      "Train loss: 2.9382809053148544\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.343022270202637\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13120  --------------------------\n",
      "Train loss: 2.9345476143700737\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.148377717336018\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13130  --------------------------\n",
      "Train loss: 2.9347142478397914\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.197511034011841\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13140  --------------------------\n",
      "Train loss: 2.945609476225717\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.192333192825318\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13150  --------------------------\n",
      "Train loss: 2.911314226899828\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.171977831522623\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13160  --------------------------\n",
      "Train loss: 2.9174857010160173\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.184244413375854\n",
      "Test accuracy: 0.9\n",
      "Epoch:  13170  --------------------------\n",
      "Train loss: 2.9190428393227714\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.103133180936178\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13180  --------------------------\n",
      "Train loss: 2.9434761902264186\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.242144266764322\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13190  --------------------------\n",
      "Train loss: 2.9426904286657063\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.084499810536702\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13200  --------------------------\n",
      "Train loss: 2.942604741709573\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.038299973805746\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13210  --------------------------\n",
      "Train loss: 2.9231285674231393\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.234810994466146\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13220  --------------------------\n",
      "Train loss: 2.947138091496059\n",
      "Train accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.217822030385335\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13230  --------------------------\n",
      "Train loss: 2.968980928829738\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.105544481277466\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13240  --------------------------\n",
      "Train loss: 2.9689618464878627\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.058299999237061\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13250  --------------------------\n",
      "Train loss: 2.933700008392334\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.158033275604248\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13260  --------------------------\n",
      "Train loss: 2.901699969427926\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.049455521901448\n",
      "Test accuracy: 0.9\n",
      "Epoch:  13270  --------------------------\n",
      "Train loss: 2.9434666735785346\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.05275557200114\n",
      "Test accuracy: 0.9\n",
      "Epoch:  13280  --------------------------\n",
      "Train loss: 2.9589618403570994\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.197266343434652\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13290  --------------------------\n",
      "Train loss: 2.9709428221838814\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.006688874562581\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13300  --------------------------\n",
      "Train loss: 2.9702095331464493\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.24872210820516\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13310  --------------------------\n",
      "Train loss: 2.9622714155060903\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.135733245213826\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  13320  --------------------------\n",
      "Train loss: 2.9533142501967293\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.188399823506673\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13330  --------------------------\n",
      "Train loss: 2.9359571153776987\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.086733214060466\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13340  --------------------------\n",
      "Train loss: 2.968233323778425\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.033422215779622\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13350  --------------------------\n",
      "Train loss: 2.923076173237392\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.093288917541503\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13360  --------------------------\n",
      "Train loss: 2.92720477104187\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.094055538177491\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13370  --------------------------\n",
      "Train loss: 2.9269618572507587\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.21704443613688\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13380  --------------------------\n",
      "Train loss: 2.92085232428142\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.123644351959229\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13390  --------------------------\n",
      "Train loss: 2.9488999397414073\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.148955561319987\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13400  --------------------------\n",
      "Train loss: 2.947980943407331\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.16996654510498\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13410  --------------------------\n",
      "Train loss: 2.9187047222682407\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.25785545984904\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13420  --------------------------\n",
      "Train loss: 2.9473190116882324\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.175388685862224\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13430  --------------------------\n",
      "Train loss: 2.9533285750661578\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.30793337504069\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13440  --------------------------\n",
      "Train loss: 2.996423781939915\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.156077829996745\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13450  --------------------------\n",
      "Train loss: 2.9522809573582243\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.273833249409993\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13460  --------------------------\n",
      "Train loss: 2.9400095081329347\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.266977774302164\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13470  --------------------------\n",
      "Train loss: 2.939366590636117\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.9946443510055545\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13480  --------------------------\n",
      "Train loss: 2.9440380777631487\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.106555490493774\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13490  --------------------------\n",
      "Train loss: 2.9799189942223685\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.166266536712646\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13500  --------------------------\n",
      "Train loss: 2.93372378723962\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.116922232309976\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13510  --------------------------\n",
      "Train loss: 2.939671414920262\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.439777787526449\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13520  --------------------------\n",
      "Train loss: 2.938976150921413\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.224188753763835\n",
      "Test accuracy: 0.9\n",
      "Epoch:  13530  --------------------------\n",
      "Train loss: 2.9501095254080636\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.150255368550619\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13540  --------------------------\n",
      "Train loss: 2.8990047557013376\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.068233229319254\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13550  --------------------------\n",
      "Train loss: 2.938657103266035\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.193777770996094\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13560  --------------------------\n",
      "Train loss: 2.9468856975010462\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.192721939086914\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13570  --------------------------\n",
      "Train loss: 2.9378142653192794\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.16417776107788\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13580  --------------------------\n",
      "Train loss: 2.9190380709511894\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.200610939661662\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  13590  --------------------------\n",
      "Train loss: 2.944914266722543\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.256133282979329\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13600  --------------------------\n",
      "Train loss: 2.9588332993643625\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.06339994430542\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13610  --------------------------\n",
      "Train loss: 2.9517904445103236\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.141666609446208\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13620  --------------------------\n",
      "Train loss: 2.936219013077872\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.085122057596843\n",
      "Test accuracy: 0.91\n",
      "Epoch:  13630  --------------------------\n",
      "Train loss: 2.954276176180158\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.113810965220134\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13640  --------------------------\n",
      "Train loss: 2.9360904952457973\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.147811063130696\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13650  --------------------------\n",
      "Train loss: 2.9157333305903843\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.127911073366802\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13660  --------------------------\n",
      "Train loss: 2.966985681397574\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.218944339752197\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  13670  --------------------------\n",
      "Train loss: 2.940895173209054\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.344710985819498\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13680  --------------------------\n",
      "Train loss: 2.934442804200309\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.30531096458435\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13690  --------------------------\n",
      "Train loss: 2.9674952173233033\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.148833249409993\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13700  --------------------------\n",
      "Train loss: 2.922723776272365\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.233444344202677\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  13710  --------------------------\n",
      "Train loss: 2.9238190528324672\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.544955603281657\n",
      "Test accuracy: 0.88\n",
      "Epoch:  13720  --------------------------\n",
      "Train loss: 2.9347618900026595\n",
      "Train accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.249255441029867\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13730  --------------------------\n",
      "Train loss: 2.956471389702388\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.082033166885376\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13740  --------------------------\n",
      "Train loss: 2.9392428289140975\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.416711018880209\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13750  --------------------------\n",
      "Train loss: 2.9250666400364467\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.228766536712646\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13760  --------------------------\n",
      "Train loss: 2.9126999916349137\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.418922360738119\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  13770  --------------------------\n",
      "Train loss: 2.910590478352138\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.116377623875936\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  13780  --------------------------\n",
      "Train loss: 2.938680932181222\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.112988692919414\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13790  --------------------------\n",
      "Train loss: 2.9441999667031427\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.320055500666301\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13800  --------------------------\n",
      "Train loss: 2.952590432848249\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.162911160786946\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13810  --------------------------\n",
      "Train loss: 2.940123782839094\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.15515547434489\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13820  --------------------------\n",
      "Train loss: 2.995295215334211\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.231577529907227\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13830  --------------------------\n",
      "Train loss: 2.930204747744969\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.15424430847168\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13840  --------------------------\n",
      "Train loss: 2.924104734148298\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.322599957784018\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  13850  --------------------------\n",
      "Train loss: 2.9609571272986277\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.16152216275533\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13860  --------------------------\n",
      "Train loss: 2.9302904564993724\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.20781109491984\n",
      "Test accuracy: 0.89\n",
      "Epoch:  13870  --------------------------\n",
      "Train loss: 2.913009527070182\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.173899898529053\n",
      "Test accuracy: 0.91\n",
      "Epoch:  13880  --------------------------\n",
      "Train loss: 2.9495856622287207\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.020255511601766\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13890  --------------------------\n",
      "Train loss: 2.9571237884249006\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.35295550664266\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13900  --------------------------\n",
      "Train loss: 2.956019058227539\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.028377784093221\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  13910  --------------------------\n",
      "Train loss: 2.905342789377485\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.087266702651977\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13920  --------------------------\n",
      "Train loss: 2.901152353967939\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.238610967000325\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13930  --------------------------\n",
      "Train loss: 2.931899983201708\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.081522143681845\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13940  --------------------------\n",
      "Train loss: 2.9008666597093855\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.337644386291505\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13950  --------------------------\n",
      "Train loss: 2.890128564834595\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.16008893330892\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13960  --------------------------\n",
      "Train loss: 2.9340524108069284\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.136855525970459\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13970  --------------------------\n",
      "Train loss: 2.886785706451961\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.338566592534383\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  13980  --------------------------\n",
      "Train loss: 2.912852394240243\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.339766670862833\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  13990  --------------------------\n",
      "Train loss: 2.913776160308293\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.12818870862325\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14000  --------------------------\n",
      "Train loss: 2.906223808356694\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.19249994913737\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14010  --------------------------\n",
      "Train loss: 2.9094571243013654\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.200066601435344\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14020  --------------------------\n",
      "Train loss: 2.9244428287233624\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.118477760950725\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14030  --------------------------\n",
      "Train loss: 2.9141856908798216\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.083733142217\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14040  --------------------------\n",
      "Train loss: 2.917928514480591\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.52425550142924\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14050  --------------------------\n",
      "Train loss: 2.9029190363202777\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.131944394111633\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14060  --------------------------\n",
      "Train loss: 2.906880941390991\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.200533377329508\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14070  --------------------------\n",
      "Train loss: 2.8968951974596298\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.257133274078369\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14080  --------------------------\n",
      "Train loss: 2.901166635581425\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.101710971196493\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14090  --------------------------\n",
      "Train loss: 2.915033289023808\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.21638884862264\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14100  --------------------------\n",
      "Train loss: 2.9560094911711556\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.103888765970867\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14110  --------------------------\n",
      "Train loss: 2.9261713763645716\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.150144367218017\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14120  --------------------------\n",
      "Train loss: 2.927261876378741\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.178999910354614\n",
      "Test accuracy: 0.9\n",
      "Epoch:  14130  --------------------------\n",
      "Train loss: 2.9260094635827203\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.259077625274658\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14140  --------------------------\n",
      "Train loss: 2.9265095220293316\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.484844309488933\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  14150  --------------------------\n",
      "Train loss: 2.879338072368077\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.383010965983074\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14160  --------------------------\n",
      "Train loss: 2.930790455681937\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.301344451904297\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14170  --------------------------\n",
      "Train loss: 2.8806380673817227\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.510333245595296\n",
      "Test accuracy: 0.9\n",
      "Epoch:  14180  --------------------------\n",
      "Train loss: 2.9135380901609147\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.214099985758464\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14190  --------------------------\n",
      "Train loss: 2.9395523520878384\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.11894437789917\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14200  --------------------------\n",
      "Train loss: 2.951285695689065\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.13041122754415\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14210  --------------------------\n",
      "Train loss: 2.939799972942897\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.112011076609294\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14220  --------------------------\n",
      "Train loss: 2.926052349976131\n",
      "Train accuracy: 0.9471428571428572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.204177560806274\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14230  --------------------------\n",
      "Train loss: 2.9404428454807827\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.252377872467042\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14240  --------------------------\n",
      "Train loss: 2.906085683277675\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.377300078074137\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14250  --------------------------\n",
      "Train loss: 2.9361095448902677\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.354188874562581\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14260  --------------------------\n",
      "Train loss: 2.9233428021839685\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.09782219250997\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14270  --------------------------\n",
      "Train loss: 2.922919046878815\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.846199858983358\n",
      "Test accuracy: 0.88\n",
      "Epoch:  14280  --------------------------\n",
      "Train loss: 2.909538119861058\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.232799838383993\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14290  --------------------------\n",
      "Train loss: 2.9416476113455636\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.26593321164449\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14300  --------------------------\n",
      "Train loss: 2.922871412890298\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.239133113225302\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14310  --------------------------\n",
      "Train loss: 2.8577333249364583\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.2382443745931\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14320  --------------------------\n",
      "Train loss: 2.8846237938744683\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.139244318008423\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14330  --------------------------\n",
      "Train loss: 2.9056571245193483\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.20048880259196\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14340  --------------------------\n",
      "Train loss: 2.9217618768555775\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.169177856445312\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14350  --------------------------\n",
      "Train loss: 2.9151238053185597\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.15875565846761\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14360  --------------------------\n",
      "Train loss: 2.8866428443363734\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.204411026636759\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  14370  --------------------------\n",
      "Train loss: 2.9139190455845423\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.251944316228231\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14380  --------------------------\n",
      "Train loss: 2.9280094855172294\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.178444423675536\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14390  --------------------------\n",
      "Train loss: 2.9050142744609286\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.18491099357605\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14400  --------------------------\n",
      "Train loss: 2.944652364594596\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.069022420247396\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14410  --------------------------\n",
      "Train loss: 2.9081428006717136\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.144288619359335\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14420  --------------------------\n",
      "Train loss: 2.9077428463527135\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.075744342803954\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14430  --------------------------\n",
      "Train loss: 2.9278761502674646\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.20389980951945\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14440  --------------------------\n",
      "Train loss: 2.924295184271676\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.330488947232565\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14450  --------------------------\n",
      "Train loss: 2.9072857332229614\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.318466714223225\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14460  --------------------------\n",
      "Train loss: 2.8798428198269437\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.193777764638265\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14470  --------------------------\n",
      "Train loss: 2.8893809509277344\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.167410869598388\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14480  --------------------------\n",
      "Train loss: 2.922895199911935\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.177566661834717\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14490  --------------------------\n",
      "Train loss: 2.907676170894078\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.180733127593994\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14500  --------------------------\n",
      "Train loss: 2.89865711416517\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.09367774327596\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14510  --------------------------\n",
      "Train loss: 2.896876181874956\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.14785561243693\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14520  --------------------------\n",
      "Train loss: 2.8609047480991907\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.212388833363852\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14530  --------------------------\n",
      "Train loss: 2.913838074547904\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.234922326405844\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14540  --------------------------\n",
      "Train loss: 2.9294189616612027\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.11588888168335\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14550  --------------------------\n",
      "Train loss: 2.8915619080407278\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.23072203318278\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14560  --------------------------\n",
      "Train loss: 2.960552396433694\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.153355490366618\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14570  --------------------------\n",
      "Train loss: 2.900976127556392\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.25531108379364\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14580  --------------------------\n",
      "Train loss: 2.926923792362213\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.14784426053365\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14590  --------------------------\n",
      "Train loss: 2.8851476321901592\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.131688906351725\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14600  --------------------------\n",
      "Train loss: 2.9109047821589877\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.35954423268636\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14610  --------------------------\n",
      "Train loss: 2.91426185301372\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.24105549176534\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14620  --------------------------\n",
      "Train loss: 2.8756999819619313\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.216222165425618\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14630  --------------------------\n",
      "Train loss: 2.8949237547601974\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.287288970947266\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14640  --------------------------\n",
      "Train loss: 2.8869189936774116\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.269655577341716\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14650  --------------------------\n",
      "Train loss: 2.9144095029149737\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.226111068725587\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14660  --------------------------\n",
      "Train loss: 2.9140904583249774\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.139744386672973\n",
      "Test accuracy: 0.91\n",
      "Epoch:  14670  --------------------------\n",
      "Train loss: 2.8862571443830216\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.27398894627889\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  14680  --------------------------\n",
      "Train loss: 2.883333307674953\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.221244341532389\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14690  --------------------------\n",
      "Train loss: 2.95560952595302\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.176844313939412\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  14700  --------------------------\n",
      "Train loss: 2.8608856875555855\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.295588836669921\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14710  --------------------------\n",
      "Train loss: 2.903695195743016\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.282388871510824\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  14720  --------------------------\n",
      "Train loss: 2.8947380539349146\n",
      "Train accuracy: 0.95\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.167944405873616\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14730  --------------------------\n",
      "Train loss: 2.9398428521837507\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.149422124226888\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14740  --------------------------\n",
      "Train loss: 2.879028513772147\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.208155501683553\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14750  --------------------------\n",
      "Train loss: 2.9016856561388287\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.272822300593058\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14760  --------------------------\n",
      "Train loss: 2.9085094778878346\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.207155532836914\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14770  --------------------------\n",
      "Train loss: 2.8965286135673525\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.03627779642741\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14780  --------------------------\n",
      "Train loss: 2.8933808967045374\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.182455412546794\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14790  --------------------------\n",
      "Train loss: 2.890942837851388\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.29983331044515\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14800  --------------------------\n",
      "Train loss: 2.9043523556845527\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.14308874130249\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14810  --------------------------\n",
      "Train loss: 2.885433330535889\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.332299842834473\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14820  --------------------------\n",
      "Train loss: 2.907452337060656\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.079855531056722\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14830  --------------------------\n",
      "Train loss: 2.8695619096074787\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.198088874816895\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14840  --------------------------\n",
      "Train loss: 2.9255475905963353\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.246677729288736\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14850  --------------------------\n",
      "Train loss: 2.910223756517683\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.177877724965413\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  14860  --------------------------\n",
      "Train loss: 2.893085740634373\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.350555515289306\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14870  --------------------------\n",
      "Train loss: 2.888309455599104\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.17154452641805\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14880  --------------------------\n",
      "Train loss: 2.8809238294192725\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.397022177378336\n",
      "Test accuracy: 0.88\n",
      "Epoch:  14890  --------------------------\n",
      "Train loss: 2.922295220920018\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.13663314819336\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14900  --------------------------\n",
      "Train loss: 2.940223789215088\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.167622108459472\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14910  --------------------------\n",
      "Train loss: 2.8991094950267247\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.1662664159139\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14920  --------------------------\n",
      "Train loss: 2.8533095223563056\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.178488794962565\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14930  --------------------------\n",
      "Train loss: 2.9311809730529785\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.388811066945394\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14940  --------------------------\n",
      "Train loss: 2.8971999631609235\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.05232213973999\n",
      "Test accuracy: 0.89\n",
      "Epoch:  14950  --------------------------\n",
      "Train loss: 2.8304476172583444\n",
      "Train accuracy: 0.96\n",
      "Test loss: 8.157766647338867\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14960  --------------------------\n",
      "Train loss: 2.928780902794429\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.082055498758951\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14970  --------------------------\n",
      "Train loss: 2.8950190547534396\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.995199947357178\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14980  --------------------------\n",
      "Train loss: 2.9051094566072737\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.058188915252686\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  14990  --------------------------\n",
      "Train loss: 2.8880237194469998\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.242888819376628\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15000  --------------------------\n",
      "Train loss: 2.930899968147278\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.339888744354248\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15010  --------------------------\n",
      "Train loss: 2.860752350262233\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.987422211964925\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15020  --------------------------\n",
      "Train loss: 2.9484618813650947\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.104655462900798\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15030  --------------------------\n",
      "Train loss: 2.9260571329934257\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.113655420939127\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15040  --------------------------\n",
      "Train loss: 2.891357112612043\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.06643316268921\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15050  --------------------------\n",
      "Train loss: 2.8958285209110803\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.130833307902018\n",
      "Test accuracy: 0.89\n",
      "Epoch:  15060  --------------------------\n",
      "Train loss: 2.9227094425473896\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.100822025934855\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15070  --------------------------\n",
      "Train loss: 2.904757093020848\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.07029987970988\n",
      "Test accuracy: 0.89\n",
      "Epoch:  15080  --------------------------\n",
      "Train loss: 2.8540237610680714\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.11867769241333\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  15090  --------------------------\n",
      "Train loss: 2.8769523991857255\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.147922197977701\n",
      "Test accuracy: 0.89\n",
      "Epoch:  15100  --------------------------\n",
      "Train loss: 2.896166588578905\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.21614441871643\n",
      "Test accuracy: 0.89\n",
      "Epoch:  15110  --------------------------\n",
      "Train loss: 2.918366620200021\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.131188626289367\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15120  --------------------------\n",
      "Train loss: 2.869804718153817\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.1029776318868\n",
      "Test accuracy: 0.89\n",
      "Epoch:  15130  --------------------------\n",
      "Train loss: 2.8999190098898753\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.15824452082316\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15140  --------------------------\n",
      "Train loss: 2.9116714150565013\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.067077859242756\n",
      "Test accuracy: 0.89\n",
      "Epoch:  15150  --------------------------\n",
      "Train loss: 2.910619034767151\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.154644419352213\n",
      "Test accuracy: 0.89\n",
      "Epoch:  15160  --------------------------\n",
      "Train loss: 2.9119285328047617\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.059277744293214\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15170  --------------------------\n",
      "Train loss: 2.8862523800986155\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.985988960266114\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15180  --------------------------\n",
      "Train loss: 2.8843047778947013\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.574122327168782\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  15190  --------------------------\n",
      "Train loss: 2.952599972656795\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.064777777989706\n",
      "Test accuracy: 0.89\n",
      "Epoch:  15200  --------------------------\n",
      "Train loss: 2.8908095145225525\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.043133335113525\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15210  --------------------------\n",
      "Train loss: 2.859304693767003\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.233099996248882\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15220  --------------------------\n",
      "Train loss: 2.9110095007078987\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.926533371607462\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15230  --------------------------\n",
      "Train loss: 2.877314301899501\n",
      "Train accuracy: 0.9514285714285714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.133422037760417\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15240  --------------------------\n",
      "Train loss: 2.900090453965323\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.057933349609375\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15250  --------------------------\n",
      "Train loss: 2.917190418243408\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.13738881111145\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15260  --------------------------\n",
      "Train loss: 2.9053952431678773\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.165700016021729\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15270  --------------------------\n",
      "Train loss: 2.880509470190321\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.074088929494222\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15280  --------------------------\n",
      "Train loss: 2.8497856872422354\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.124155416488648\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15290  --------------------------\n",
      "Train loss: 2.9082333012989587\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.126877794265747\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15300  --------------------------\n",
      "Train loss: 2.8860618952342443\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.991588983535767\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15310  --------------------------\n",
      "Train loss: 2.8644285804884775\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.342755568822225\n",
      "Test accuracy: 0.89\n",
      "Epoch:  15320  --------------------------\n",
      "Train loss: 2.899728548526764\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.127066694895426\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15330  --------------------------\n",
      "Train loss: 2.887628575052534\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.044911069869995\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15340  --------------------------\n",
      "Train loss: 2.869152408327375\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.0049888865153\n",
      "Test accuracy: 0.92\n",
      "Epoch:  15350  --------------------------\n",
      "Train loss: 2.9001857015064783\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.03643320719401\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15360  --------------------------\n",
      "Train loss: 2.880738099643162\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.135455484390258\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15370  --------------------------\n",
      "Train loss: 2.8780000158718653\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.172555518150329\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15380  --------------------------\n",
      "Train loss: 2.9070143151283263\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.014511025746664\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15390  --------------------------\n",
      "Train loss: 2.892509491784232\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.034666681289673\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15400  --------------------------\n",
      "Train loss: 2.8880714130401612\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.2488223361969\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15410  --------------------------\n",
      "Train loss: 2.9143523645401\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.062611074447632\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15420  --------------------------\n",
      "Train loss: 2.876114229474749\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.098966592152914\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15430  --------------------------\n",
      "Train loss: 2.870419044494629\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.110099951426188\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15440  --------------------------\n",
      "Train loss: 2.8778999873570035\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.27998883565267\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15450  --------------------------\n",
      "Train loss: 2.9420618629455566\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.234088776906331\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15460  --------------------------\n",
      "Train loss: 2.9013523319789343\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.231444403330485\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15470  --------------------------\n",
      "Train loss: 2.884604798725673\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.039155317942301\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15480  --------------------------\n",
      "Train loss: 2.834761870588575\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.512588831583658\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  15490  --------------------------\n",
      "Train loss: 2.889314293180193\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.406366659800211\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15500  --------------------------\n",
      "Train loss: 2.8772285665784563\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.150066630045574\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15510  --------------------------\n",
      "Train loss: 2.8441856915610177\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.461955350240071\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15520  --------------------------\n",
      "Train loss: 2.8802428562300544\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.09935559908549\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15530  --------------------------\n",
      "Train loss: 2.9148237800598142\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.133711194992065\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15540  --------------------------\n",
      "Train loss: 2.8662904487337384\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.323722174962361\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15550  --------------------------\n",
      "Train loss: 2.86499045916966\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.224666570027669\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15560  --------------------------\n",
      "Train loss: 2.854023804664612\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.08878880182902\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15570  --------------------------\n",
      "Train loss: 2.906238079752241\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.168977772394816\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15580  --------------------------\n",
      "Train loss: 2.885361855370658\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.24945546468099\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  15590  --------------------------\n",
      "Train loss: 2.8973666545322962\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.211033267974853\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15600  --------------------------\n",
      "Train loss: 2.8906999240602764\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.138744506835938\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15610  --------------------------\n",
      "Train loss: 2.888590439728328\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.12418903986613\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15620  --------------------------\n",
      "Train loss: 2.9113904656682696\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 8.078022168477377\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15630  --------------------------\n",
      "Train loss: 2.889933249609811\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.148599780400595\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15640  --------------------------\n",
      "Train loss: 2.8278999512536185\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.183222007751464\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15650  --------------------------\n",
      "Train loss: 2.8731380571637835\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.14412225564321\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  15660  --------------------------\n",
      "Train loss: 2.8777618650027685\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.209455397923788\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15670  --------------------------\n",
      "Train loss: 2.9079380771092005\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.08380002339681\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15680  --------------------------\n",
      "Train loss: 2.920461849485125\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.185811096827189\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15690  --------------------------\n",
      "Train loss: 2.882271383830479\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.126922232309978\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15700  --------------------------\n",
      "Train loss: 2.8930428058760507\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.105022128423055\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15710  --------------------------\n",
      "Train loss: 2.889166647025517\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.070655453999837\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15720  --------------------------\n",
      "Train loss: 2.8905191012791227\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.098755442301432\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15730  --------------------------\n",
      "Train loss: 2.841452331542969\n",
      "Train accuracy: 0.9542857142857143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 8.414622344970702\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15740  --------------------------\n",
      "Train loss: 2.9241142868995667\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.118344504038493\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15750  --------------------------\n",
      "Train loss: 2.848180922780718\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.232755273183187\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15760  --------------------------\n",
      "Train loss: 2.8641475691114153\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.08329994837443\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15770  --------------------------\n",
      "Train loss: 2.8832475978987557\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.22936666170756\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15780  --------------------------\n",
      "Train loss: 2.880719042505537\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.310911235809327\n",
      "Test accuracy: 0.92\n",
      "Epoch:  15790  --------------------------\n",
      "Train loss: 2.889223771776472\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.226999924977621\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15800  --------------------------\n",
      "Train loss: 2.9046999849591937\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.128144416809082\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15810  --------------------------\n",
      "Train loss: 2.868652399608067\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.151555404663085\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15820  --------------------------\n",
      "Train loss: 2.890595193590437\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.1485555934906\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15830  --------------------------\n",
      "Train loss: 2.8738571078436714\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.11154436747233\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15840  --------------------------\n",
      "Train loss: 2.830261903149741\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.255188808441162\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15850  --------------------------\n",
      "Train loss: 2.862819001334054\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.149477653503418\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15860  --------------------------\n",
      "Train loss: 2.8635856781687057\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.299899956385294\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15870  --------------------------\n",
      "Train loss: 2.844738042354584\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.116822134653727\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15880  --------------------------\n",
      "Train loss: 2.8617761397361754\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.290510985056558\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15890  --------------------------\n",
      "Train loss: 2.8658951895577567\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.273388897577922\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15900  --------------------------\n",
      "Train loss: 2.843866631644113\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.181799983978271\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15910  --------------------------\n",
      "Train loss: 2.8804237856183734\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.25523338953654\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15920  --------------------------\n",
      "Train loss: 2.8765475961140226\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.318088893890382\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  15930  --------------------------\n",
      "Train loss: 2.8927523415429253\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.250622262954712\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15940  --------------------------\n",
      "Train loss: 2.885495263848986\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.15481096903483\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15950  --------------------------\n",
      "Train loss: 2.8821571833746775\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.020044450759888\n",
      "Test accuracy: 0.9\n",
      "Epoch:  15960  --------------------------\n",
      "Train loss: 2.890914260319301\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.156844476064046\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  15970  --------------------------\n",
      "Train loss: 2.88479519707816\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.198888727823894\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15980  --------------------------\n",
      "Train loss: 2.8517142861230034\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.260077711741129\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  15990  --------------------------\n",
      "Train loss: 2.8711190182822093\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.275022017161051\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16000  --------------------------\n",
      "Train loss: 2.913861885751997\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.219144401550293\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16010  --------------------------\n",
      "Train loss: 2.8693667030334473\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.183588778177898\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16020  --------------------------\n",
      "Train loss: 2.8775618716648648\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.073722114562988\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16030  --------------------------\n",
      "Train loss: 2.866885698182242\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.14479996363322\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16040  --------------------------\n",
      "Train loss: 2.8238904442105976\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.275266647338867\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16050  --------------------------\n",
      "Train loss: 2.852752365384783\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.200966567993165\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16060  --------------------------\n",
      "Train loss: 2.8653761621883937\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.210177663167318\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16070  --------------------------\n",
      "Train loss: 2.8904856719289507\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.085244302749635\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16080  --------------------------\n",
      "Train loss: 2.873733249391828\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.161499869028727\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16090  --------------------------\n",
      "Train loss: 2.868090423856463\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.127977724075317\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16100  --------------------------\n",
      "Train loss: 2.8887904582704818\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.219755299886067\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16110  --------------------------\n",
      "Train loss: 2.851466648578644\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.191822201410929\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16120  --------------------------\n",
      "Train loss: 2.853171432699476\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.988444417317709\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  16130  --------------------------\n",
      "Train loss: 2.8394904623712813\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.093288923899333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16140  --------------------------\n",
      "Train loss: 2.90741904769625\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.118322216669718\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16150  --------------------------\n",
      "Train loss: 2.8619523651259287\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.186211147308349\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16160  --------------------------\n",
      "Train loss: 2.83880476134164\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.107944342295328\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16170  --------------------------\n",
      "Train loss: 2.8729666212626865\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.055566590627034\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  16180  --------------------------\n",
      "Train loss: 2.8707142312186105\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.041410926183065\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16190  --------------------------\n",
      "Train loss: 2.9217808968680243\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.147311086654662\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16200  --------------------------\n",
      "Train loss: 2.864852373940604\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.063055540720622\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16210  --------------------------\n",
      "Train loss: 2.8515475693770815\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.03529998143514\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16220  --------------------------\n",
      "Train loss: 2.886185716901507\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.009110984802247\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16230  --------------------------\n",
      "Train loss: 2.8345237381117685\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.056755339304607\n",
      "Test accuracy: 0.8933333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16240  --------------------------\n",
      "Train loss: 2.86645234142031\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.253222258885701\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16250  --------------------------\n",
      "Train loss: 2.903404766491481\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.129433218638102\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16260  --------------------------\n",
      "Train loss: 2.838066658973694\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.087811120351155\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16270  --------------------------\n",
      "Train loss: 2.841690449033465\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.120955530802409\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16280  --------------------------\n",
      "Train loss: 2.854328530856541\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.446877695719401\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16290  --------------------------\n",
      "Train loss: 2.8377618861198424\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.096633256276448\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16300  --------------------------\n",
      "Train loss: 2.8931428132738386\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.998822266260783\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  16310  --------------------------\n",
      "Train loss: 2.8729713562556674\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.240555458068847\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16320  --------------------------\n",
      "Train loss: 2.869719028813498\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.125077629089356\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16330  --------------------------\n",
      "Train loss: 2.876280958993094\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.196610991160075\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16340  --------------------------\n",
      "Train loss: 2.8886046988623484\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.025811052322387\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16350  --------------------------\n",
      "Train loss: 2.8760951903888157\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.086855564117432\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16360  --------------------------\n",
      "Train loss: 2.864152321134295\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.217344563802083\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16370  --------------------------\n",
      "Train loss: 2.873366634505136\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.082233282725015\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16380  --------------------------\n",
      "Train loss: 2.859190456867218\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.059188645680745\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16390  --------------------------\n",
      "Train loss: 2.882866606712341\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.057100098927815\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16400  --------------------------\n",
      "Train loss: 2.9084190150669644\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.98442232131958\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16410  --------------------------\n",
      "Train loss: 2.890566645349775\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.070033315022787\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16420  --------------------------\n",
      "Train loss: 2.8761951766695293\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.053744411468506\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16430  --------------------------\n",
      "Train loss: 2.8611714322226387\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.991144618988037\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16440  --------------------------\n",
      "Train loss: 2.88505238873618\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.02273338317871\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16450  --------------------------\n",
      "Train loss: 2.884547573157719\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.0959778881073\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16460  --------------------------\n",
      "Train loss: 2.8636713848795208\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.963566548029582\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16470  --------------------------\n",
      "Train loss: 2.86359993321555\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.0629332669576\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16480  --------------------------\n",
      "Train loss: 2.8769713721956527\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.149711049397787\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16490  --------------------------\n",
      "Train loss: 2.862823784010751\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.11989984035492\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16500  --------------------------\n",
      "Train loss: 2.8662380821364266\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.111566638946533\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16510  --------------------------\n",
      "Train loss: 2.876014255114964\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.171533387502034\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16520  --------------------------\n",
      "Train loss: 2.8321761626856667\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.916722259521484\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16530  --------------------------\n",
      "Train loss: 2.87552859715053\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.148288873036703\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16540  --------------------------\n",
      "Train loss: 2.8545285633632114\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.04491106669108\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16550  --------------------------\n",
      "Train loss: 2.876576153210231\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.961010971069336\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16560  --------------------------\n",
      "Train loss: 2.875428547859192\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.047866611480712\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16570  --------------------------\n",
      "Train loss: 2.8945047170775275\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.084522151947022\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16580  --------------------------\n",
      "Train loss: 2.886285685811724\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 7.978722235361735\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16590  --------------------------\n",
      "Train loss: 2.8563523255075727\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.012577775319418\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16600  --------------------------\n",
      "Train loss: 2.875799992765699\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.019899940490722\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16610  --------------------------\n",
      "Train loss: 2.8683713722229003\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.254122212727864\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16620  --------------------------\n",
      "Train loss: 2.8451571491786414\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.111588837305705\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16630  --------------------------\n",
      "Train loss: 2.9065190029144286\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.08034432411194\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16640  --------------------------\n",
      "Train loss: 2.869261863572257\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.06715550104777\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16650  --------------------------\n",
      "Train loss: 2.8444856902531215\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.080388600031535\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16660  --------------------------\n",
      "Train loss: 2.842780876159668\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.927733319600423\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16670  --------------------------\n",
      "Train loss: 2.8799333279473442\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.108699919382731\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16680  --------------------------\n",
      "Train loss: 2.883552312169756\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.139910990397135\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16690  --------------------------\n",
      "Train loss: 2.8858523494856696\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.036344464619955\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16700  --------------------------\n",
      "Train loss: 2.853371387209211\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.15864431699117\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16710  --------------------------\n",
      "Train loss: 2.8875333322797503\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.107077773412069\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16720  --------------------------\n",
      "Train loss: 2.8667666384152004\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.117122008005778\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16730  --------------------------\n",
      "Train loss: 2.84217615876879\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.112122205098471\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16740  --------------------------\n",
      "Train loss: 2.876171366146633\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.023844292958577\n",
      "Test accuracy: 0.8966666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  16750  --------------------------\n",
      "Train loss: 2.8222714315141952\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.179421981175741\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16760  --------------------------\n",
      "Train loss: 2.8432761570385523\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.040811204910279\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16770  --------------------------\n",
      "Train loss: 2.908018974576678\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.02404450416565\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16780  --------------------------\n",
      "Train loss: 2.8840475508144925\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.165266609191894\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16790  --------------------------\n",
      "Train loss: 2.850047593797956\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.08785540898641\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16800  --------------------------\n",
      "Train loss: 2.8102808713912966\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.141366640726725\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16810  --------------------------\n",
      "Train loss: 2.855571398735046\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.037422205607097\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16820  --------------------------\n",
      "Train loss: 2.8592380217143467\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.401122067769368\n",
      "Test accuracy: 0.8833333333333333\n",
      "Epoch:  16830  --------------------------\n",
      "Train loss: 2.810809528487069\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.146877797444661\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  16840  --------------------------\n",
      "Train loss: 2.8923809402329583\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.076766554514567\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16850  --------------------------\n",
      "Train loss: 2.842904725074768\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.133466520309447\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16860  --------------------------\n",
      "Train loss: 2.8652332803181237\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.100366560618083\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16870  --------------------------\n",
      "Train loss: 2.8192714146205358\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.074744561513265\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16880  --------------------------\n",
      "Train loss: 2.891161874021803\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.012999928792318\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16890  --------------------------\n",
      "Train loss: 2.8285237639290948\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.114255447387695\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16900  --------------------------\n",
      "Train loss: 2.8301999609810964\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.109188760121663\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16910  --------------------------\n",
      "Train loss: 2.8472047233581543\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.01894427617391\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16920  --------------------------\n",
      "Train loss: 2.844138082436153\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.065244280497232\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  16930  --------------------------\n",
      "Train loss: 2.835952343940735\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.00907772699992\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16940  --------------------------\n",
      "Train loss: 2.8057571816444398\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.190999984741211\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16950  --------------------------\n",
      "Train loss: 2.799328524725778\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.188088976542154\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16960  --------------------------\n",
      "Train loss: 2.8362523794174193\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.14899995803833\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  16970  --------------------------\n",
      "Train loss: 2.8401571123940603\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.097577667236328\n",
      "Test accuracy: 0.9\n",
      "Epoch:  16980  --------------------------\n",
      "Train loss: 2.8681904544149126\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.146155557632447\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  16990  --------------------------\n",
      "Train loss: 2.806104757104601\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.12739995320638\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17000  --------------------------\n",
      "Train loss: 2.848790429660252\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.953733463287353\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17010  --------------------------\n",
      "Train loss: 2.8313761363710674\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.161244347890218\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17020  --------------------------\n",
      "Train loss: 2.8275142315455843\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.244544417063395\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17030  --------------------------\n",
      "Train loss: 2.836538017817906\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.961033255259196\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17040  --------------------------\n",
      "Train loss: 2.903776138169425\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.992822192509969\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17050  --------------------------\n",
      "Train loss: 2.8200476465906417\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.168044233322144\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17060  --------------------------\n",
      "Train loss: 2.845909504209246\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.049900048573813\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17070  --------------------------\n",
      "Train loss: 2.844042797088623\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.169755325317382\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17080  --------------------------\n",
      "Train loss: 2.802047609601702\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.014677880605062\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17090  --------------------------\n",
      "Train loss: 2.8466904142924716\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.155855700174968\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17100  --------------------------\n",
      "Train loss: 2.8624427829469954\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.178777643839519\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17110  --------------------------\n",
      "Train loss: 2.7923285722732545\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 9.297988866170247\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  17120  --------------------------\n",
      "Train loss: 2.8366285143579755\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.148010857899983\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17130  --------------------------\n",
      "Train loss: 2.80627617086683\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.10657772064209\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17140  --------------------------\n",
      "Train loss: 2.8316904091835022\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.983766601880391\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17150  --------------------------\n",
      "Train loss: 2.8531332451956612\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.080333318710327\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17160  --------------------------\n",
      "Train loss: 2.815247566699982\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 8.04182238260905\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17170  --------------------------\n",
      "Train loss: 2.8082571176120212\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.161333185831706\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17180  --------------------------\n",
      "Train loss: 2.81648569720132\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.009500045776367\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17190  --------------------------\n",
      "Train loss: 2.8012951942852564\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.29557783126831\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17200  --------------------------\n",
      "Train loss: 2.8284856564658027\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.107455647786459\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17210  --------------------------\n",
      "Train loss: 2.8211952223096577\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.13897775967916\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17220  --------------------------\n",
      "Train loss: 2.8164380182538715\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.971455504099528\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17230  --------------------------\n",
      "Train loss: 2.8190713678087507\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.946088914871216\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17240  --------------------------\n",
      "Train loss: 2.84429043837956\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.083233331044514\n",
      "Test accuracy: 0.8966666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17250  --------------------------\n",
      "Train loss: 2.8778190108707973\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.114877653121948\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17260  --------------------------\n",
      "Train loss: 2.802414264678955\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.000033144950867\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  17270  --------------------------\n",
      "Train loss: 2.8002189997264315\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.091522146860758\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17280  --------------------------\n",
      "Train loss: 2.8539285520144873\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.9699667040507\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17290  --------------------------\n",
      "Train loss: 2.8427476140430996\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.96541109085083\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17300  --------------------------\n",
      "Train loss: 2.796323756149837\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.02902214050293\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17310  --------------------------\n",
      "Train loss: 2.787766611235482\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.0568665599823\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17320  --------------------------\n",
      "Train loss: 2.802104720047542\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.153833325703939\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17330  --------------------------\n",
      "Train loss: 2.8535523884637017\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.1267444674174\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17340  --------------------------\n",
      "Train loss: 2.8464047738483975\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.10111110051473\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17350  --------------------------\n",
      "Train loss: 2.7987047444071087\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.133444395065307\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17360  --------------------------\n",
      "Train loss: 2.824085668836321\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.005566641489665\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17370  --------------------------\n",
      "Train loss: 2.8598904497282844\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.111977856953938\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17380  --------------------------\n",
      "Train loss: 2.848142831666129\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.07185552597046\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17390  --------------------------\n",
      "Train loss: 2.83128093787602\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 8.098855476379395\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17400  --------------------------\n",
      "Train loss: 2.8464856597355435\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.266744375228882\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17410  --------------------------\n",
      "Train loss: 2.84087616784232\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.149122206370036\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17420  --------------------------\n",
      "Train loss: 2.8033190321922303\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.08491109530131\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17430  --------------------------\n",
      "Train loss: 2.8476570863383155\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.976088771820068\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17440  --------------------------\n",
      "Train loss: 2.790023766926357\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.968011065324148\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17450  --------------------------\n",
      "Train loss: 2.825190406867436\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.404866695404053\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17460  --------------------------\n",
      "Train loss: 2.8236285890851702\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.056922216415405\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17470  --------------------------\n",
      "Train loss: 2.8133333512714933\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.102866465250651\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17480  --------------------------\n",
      "Train loss: 2.820976175240108\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.127410971323648\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17490  --------------------------\n",
      "Train loss: 2.8065761634281703\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.012066586812336\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17500  --------------------------\n",
      "Train loss: 2.808942869050162\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.27231098651886\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17510  --------------------------\n",
      "Train loss: 2.825952364376613\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.2018110370636\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17520  --------------------------\n",
      "Train loss: 2.8427380507332938\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.966633459726969\n",
      "Test accuracy: 0.89\n",
      "Epoch:  17530  --------------------------\n",
      "Train loss: 2.7727761578559877\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.025566711425782\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  17540  --------------------------\n",
      "Train loss: 2.8316761561802455\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.020433460871379\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17550  --------------------------\n",
      "Train loss: 2.8246761676243373\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.104511127471923\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  17560  --------------------------\n",
      "Train loss: 2.8294571225983756\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.074910928408304\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  17570  --------------------------\n",
      "Train loss: 2.816342831339155\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.09267770131429\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17580  --------------------------\n",
      "Train loss: 2.8211904311180116\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.067477671305339\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17590  --------------------------\n",
      "Train loss: 2.844771429811205\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.115344444910685\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  17600  --------------------------\n",
      "Train loss: 2.833566598892212\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.12933336575826\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17610  --------------------------\n",
      "Train loss: 2.8164476019995552\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.991388948758443\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  17620  --------------------------\n",
      "Train loss: 2.8094904705456325\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.880511113802592\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  17630  --------------------------\n",
      "Train loss: 2.8004285546711514\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.929722283681234\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17640  --------------------------\n",
      "Train loss: 2.8313523633139472\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.057700030008952\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  17650  --------------------------\n",
      "Train loss: 2.833495216369629\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.994788862864176\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  17660  --------------------------\n",
      "Train loss: 2.801585679735456\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.921577609380086\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17670  --------------------------\n",
      "Train loss: 2.829128576006208\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.95981102625529\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17680  --------------------------\n",
      "Train loss: 2.807890476499285\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.093422145843506\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17690  --------------------------\n",
      "Train loss: 2.8191094630105153\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.908866720199585\n",
      "Test accuracy: 0.9233333333333333\n",
      "Epoch:  17700  --------------------------\n",
      "Train loss: 2.778228550638471\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.35274449189504\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17710  --------------------------\n",
      "Train loss: 2.798628533567701\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.919488855997721\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17720  --------------------------\n",
      "Train loss: 2.812823725087302\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.020755383173624\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  17730  --------------------------\n",
      "Train loss: 2.7692714037214006\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.175088806152344\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17740  --------------------------\n",
      "Train loss: 2.8006952224458965\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.077122325897216\n",
      "Test accuracy: 0.9033333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  17750  --------------------------\n",
      "Train loss: 2.795985691547394\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.057455514272053\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17760  --------------------------\n",
      "Train loss: 2.84856662273407\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.9455555788675944\n",
      "Test accuracy: 0.9233333333333333\n",
      "Epoch:  17770  --------------------------\n",
      "Train loss: 2.842404727935791\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.9731666946411135\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17780  --------------------------\n",
      "Train loss: 2.809414213725499\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.978099956512451\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17790  --------------------------\n",
      "Train loss: 2.8355047297477722\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.911344448725383\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17800  --------------------------\n",
      "Train loss: 2.83723806313106\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.078766848246257\n",
      "Test accuracy: 0.89\n",
      "Epoch:  17810  --------------------------\n",
      "Train loss: 2.8226333127702987\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.973399826685587\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17820  --------------------------\n",
      "Train loss: 2.818371387209211\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.980944315592448\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17830  --------------------------\n",
      "Train loss: 2.839942798614502\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.910455474853515\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17840  --------------------------\n",
      "Train loss: 2.8121856454440524\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.995166530609131\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17850  --------------------------\n",
      "Train loss: 2.8070476061957224\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.068588740030924\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17860  --------------------------\n",
      "Train loss: 2.7872714151654923\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.971655476888021\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17870  --------------------------\n",
      "Train loss: 2.832533299241747\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.9860110823313395\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  17880  --------------------------\n",
      "Train loss: 2.793509474481855\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.081922311782836\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17890  --------------------------\n",
      "Train loss: 2.8172618668419975\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.82737766901652\n",
      "Test accuracy: 0.9233333333333333\n",
      "Epoch:  17900  --------------------------\n",
      "Train loss: 2.8187571018082753\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.91531104405721\n",
      "Test accuracy: 0.9233333333333333\n",
      "Epoch:  17910  --------------------------\n",
      "Train loss: 2.8015190199443274\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.8828998438517255\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17920  --------------------------\n",
      "Train loss: 2.791452351297651\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.007544368108114\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17930  --------------------------\n",
      "Train loss: 2.766095199584961\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.956922067006429\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  17940  --------------------------\n",
      "Train loss: 2.7800523478644235\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.061377817789714\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17950  --------------------------\n",
      "Train loss: 2.7957332921028137\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.030822083155314\n",
      "Test accuracy: 0.9\n",
      "Epoch:  17960  --------------------------\n",
      "Train loss: 2.807619024344853\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.057977603276571\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  17970  --------------------------\n",
      "Train loss: 2.7503142172949655\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 7.920499992370606\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  17980  --------------------------\n",
      "Train loss: 2.839609498637063\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 7.994411052068075\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  17990  --------------------------\n",
      "Train loss: 2.7978666343007768\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.909066588083903\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  18000  --------------------------\n",
      "Train loss: 2.7988999465533664\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.804744323094686\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18010  --------------------------\n",
      "Train loss: 2.811328593662807\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.10349985440572\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18020  --------------------------\n",
      "Train loss: 2.783276162828718\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.935077772140503\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18030  --------------------------\n",
      "Train loss: 2.8375570958001273\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 8.072488867441812\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18040  --------------------------\n",
      "Train loss: 2.7746238027300154\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 7.9569109916687015\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18050  --------------------------\n",
      "Train loss: 2.8127999666758945\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.942766561508178\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18060  --------------------------\n",
      "Train loss: 2.802709488868713\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.048611062367756\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18070  --------------------------\n",
      "Train loss: 2.834952313899994\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 7.929255517323812\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18080  --------------------------\n",
      "Train loss: 2.806485685961587\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.914311180114746\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18090  --------------------------\n",
      "Train loss: 2.8358332562446593\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.035844300587971\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18100  --------------------------\n",
      "Train loss: 2.764285695893424\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.833511079152425\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18110  --------------------------\n",
      "Train loss: 2.7811047097614834\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.891933383941651\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18120  --------------------------\n",
      "Train loss: 2.826466653857912\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.986155465443929\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18130  --------------------------\n",
      "Train loss: 2.783171409198216\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.858277928034465\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  18140  --------------------------\n",
      "Train loss: 2.7954380311284748\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.844188791910807\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18150  --------------------------\n",
      "Train loss: 2.793504749706813\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.983366502126058\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18160  --------------------------\n",
      "Train loss: 2.763109494618007\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 7.914200191497803\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18170  --------------------------\n",
      "Train loss: 2.7999904775619506\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.018677708307901\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18180  --------------------------\n",
      "Train loss: 2.7666618640082223\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.8426333395640055\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18190  --------------------------\n",
      "Train loss: 2.781223795754569\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.8776776949564615\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18200  --------------------------\n",
      "Train loss: 2.785157071522304\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.903811054229736\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18210  --------------------------\n",
      "Train loss: 2.794980926173074\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.9004219690958655\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18220  --------------------------\n",
      "Train loss: 2.7939190098217557\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.983444304466247\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18230  --------------------------\n",
      "Train loss: 2.8139952087402342\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.991288827260335\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18240  --------------------------\n",
      "Train loss: 2.836523777416774\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.978655446370443\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18250  --------------------------\n",
      "Train loss: 2.805561901501247\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.979722102483113\n",
      "Test accuracy: 0.8966666666666666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18260  --------------------------\n",
      "Train loss: 2.793157103061676\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.84940000851949\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18270  --------------------------\n",
      "Train loss: 2.8127856486184255\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 7.917677847544352\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18280  --------------------------\n",
      "Train loss: 2.7815428117343357\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.937066561381022\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18290  --------------------------\n",
      "Train loss: 2.793285662106105\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.978944339752197\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18300  --------------------------\n",
      "Train loss: 2.8147857403755188\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.892155469258626\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18310  --------------------------\n",
      "Train loss: 2.7833713929993764\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.045844217936198\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18320  --------------------------\n",
      "Train loss: 2.831680912630899\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.90789992014567\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18330  --------------------------\n",
      "Train loss: 2.7616142988204957\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.964577706654866\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18340  --------------------------\n",
      "Train loss: 2.786190439973559\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.892888819376628\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18350  --------------------------\n",
      "Train loss: 2.739909519127437\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.973366476694743\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18360  --------------------------\n",
      "Train loss: 2.7598666306904382\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.119366521835326\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18370  --------------------------\n",
      "Train loss: 2.776833315576826\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.9743664264678955\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18380  --------------------------\n",
      "Train loss: 2.8237713762692045\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.840366497039795\n",
      "Test accuracy: 0.92\n",
      "Epoch:  18390  --------------------------\n",
      "Train loss: 2.819642824445452\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.939777641296387\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18400  --------------------------\n",
      "Train loss: 2.796695214680263\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.956855328877767\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18410  --------------------------\n",
      "Train loss: 2.8486904467855183\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.070433254241943\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18420  --------------------------\n",
      "Train loss: 2.8249713587760925\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.829299847284953\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18430  --------------------------\n",
      "Train loss: 2.7634380715233937\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.08047773361206\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18440  --------------------------\n",
      "Train loss: 2.79607138974326\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.962233282725016\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18450  --------------------------\n",
      "Train loss: 2.7534809221540177\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.006988697052002\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18460  --------------------------\n",
      "Train loss: 2.771947592667171\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.851122150421142\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18470  --------------------------\n",
      "Train loss: 2.7712094579424176\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.016544326146443\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18480  --------------------------\n",
      "Train loss: 2.8016618858064923\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.793955529530843\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18490  --------------------------\n",
      "Train loss: 2.8064475672585623\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.876744419733683\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  18500  --------------------------\n",
      "Train loss: 2.807104744229998\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.033099845250447\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18510  --------------------------\n",
      "Train loss: 2.8221903930391585\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.783622045516967\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18520  --------------------------\n",
      "Train loss: 2.8116428320748463\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.8440889040629065\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18530  --------------------------\n",
      "Train loss: 2.7838856737954276\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.961355543136596\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18540  --------------------------\n",
      "Train loss: 2.767757077898298\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 7.902122238477071\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  18550  --------------------------\n",
      "Train loss: 2.7545761619295392\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.802377796173095\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18560  --------------------------\n",
      "Train loss: 2.771176150526319\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.846400127410889\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18570  --------------------------\n",
      "Train loss: 2.7713285524504525\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.074010944366455\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18580  --------------------------\n",
      "Train loss: 2.7899904326030187\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.869533263842265\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18590  --------------------------\n",
      "Train loss: 2.776695181982858\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.029555412928262\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18600  --------------------------\n",
      "Train loss: 2.809776175703321\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.511488869984944\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18610  --------------------------\n",
      "Train loss: 2.7993999906948637\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 8.000911026000976\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18620  --------------------------\n",
      "Train loss: 2.782142826829638\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.987266654968262\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18630  --------------------------\n",
      "Train loss: 2.8352714252471922\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 7.86598893960317\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18640  --------------------------\n",
      "Train loss: 2.781680956568037\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.84585555712382\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18650  --------------------------\n",
      "Train loss: 2.7671904379980905\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.913055712381999\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18660  --------------------------\n",
      "Train loss: 2.771833289350782\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.818177789052328\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  18670  --------------------------\n",
      "Train loss: 2.7777237595830644\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.858611176808675\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18680  --------------------------\n",
      "Train loss: 2.7849333098956515\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.85835540453593\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18690  --------------------------\n",
      "Train loss: 2.7828809472492764\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.072633339564005\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18700  --------------------------\n",
      "Train loss: 2.781461875779288\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.933966509501139\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18710  --------------------------\n",
      "Train loss: 2.783728497709547\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.92317786693573\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18720  --------------------------\n",
      "Train loss: 2.780128526687622\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.9563443597157795\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18730  --------------------------\n",
      "Train loss: 2.7860428421837944\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.865422115325928\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18740  --------------------------\n",
      "Train loss: 2.756261873245239\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.86825558980306\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18750  --------------------------\n",
      "Train loss: 2.763033264705113\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.963388859430949\n",
      "Test accuracy: 0.8933333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  18760  --------------------------\n",
      "Train loss: 2.7669713640213014\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.85051121711731\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18770  --------------------------\n",
      "Train loss: 2.766647595337459\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.778388878504435\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18780  --------------------------\n",
      "Train loss: 2.822299942629678\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.922822081247966\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18790  --------------------------\n",
      "Train loss: 2.797228538649423\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.866855462392171\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18800  --------------------------\n",
      "Train loss: 2.7588666003090996\n",
      "Train accuracy: 0.95\n",
      "Test loss: 8.151522137324015\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18810  --------------------------\n",
      "Train loss: 2.7623047644751413\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.840377906163534\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18820  --------------------------\n",
      "Train loss: 2.7578952169418334\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.909544537862142\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18830  --------------------------\n",
      "Train loss: 2.7897190281323025\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.758833306630453\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18840  --------------------------\n",
      "Train loss: 2.790476142678942\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.873377817471822\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18850  --------------------------\n",
      "Train loss: 2.767533358165196\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.786055657068888\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18860  --------------------------\n",
      "Train loss: 2.7761999576432363\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.82629997253418\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  18870  --------------------------\n",
      "Train loss: 2.766785731315613\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.841299940745036\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18880  --------------------------\n",
      "Train loss: 2.7503571156093054\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.8401000150044755\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18890  --------------------------\n",
      "Train loss: 2.8011666359220233\n",
      "Train accuracy: 0.9428571428571428\n",
      "Test loss: 7.949588861465454\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18900  --------------------------\n",
      "Train loss: 2.762590439319611\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.809622217814128\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  18910  --------------------------\n",
      "Train loss: 2.736933299813952\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 7.749111119906107\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18920  --------------------------\n",
      "Train loss: 2.8107857469149997\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.063122148513793\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18930  --------------------------\n",
      "Train loss: 2.7226380596842086\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 7.90948896408081\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18940  --------------------------\n",
      "Train loss: 2.771995201792036\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.934766616821289\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  18950  --------------------------\n",
      "Train loss: 2.739161858218057\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.868599901199341\n",
      "Test accuracy: 0.9\n",
      "Epoch:  18960  --------------------------\n",
      "Train loss: 2.7833095182691303\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.935955435434977\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18970  --------------------------\n",
      "Train loss: 2.754404752254486\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.96\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  18980  --------------------------\n",
      "Train loss: 2.7681571306501116\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.874288686116537\n",
      "Test accuracy: 0.9166666666666666\n",
      "Epoch:  18990  --------------------------\n",
      "Train loss: 2.7658666334833417\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.8989555470148725\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19000  --------------------------\n",
      "Train loss: 2.74445711680821\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.94091111501058\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19010  --------------------------\n",
      "Train loss: 2.7799713853427344\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 8.263288822174072\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  19020  --------------------------\n",
      "Train loss: 2.7543332835606167\n",
      "Train accuracy: 0.9571428571428572\n",
      "Test loss: 7.824389022191365\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19030  --------------------------\n",
      "Train loss: 2.740704723766872\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.029288794199626\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19040  --------------------------\n",
      "Train loss: 2.765271443980081\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.9794442780812584\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19050  --------------------------\n",
      "Train loss: 2.758590460164206\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.04193338394165\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19060  --------------------------\n",
      "Train loss: 2.8166714004107885\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.918777860005696\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19070  --------------------------\n",
      "Train loss: 2.772866610118321\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.9141555023193355\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19080  --------------------------\n",
      "Train loss: 2.78575712782996\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.016655432383219\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19090  --------------------------\n",
      "Train loss: 2.767280914102282\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 8.030599943796794\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19100  --------------------------\n",
      "Train loss: 2.7665475920268467\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.999455684026082\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19110  --------------------------\n",
      "Train loss: 2.755380937712533\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.074600003560384\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19120  --------------------------\n",
      "Train loss: 2.77585237128394\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.9601664352417\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19130  --------------------------\n",
      "Train loss: 2.7385761199678695\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.772144502003988\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19140  --------------------------\n",
      "Train loss: 2.7652095311028617\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.812566566467285\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19150  --------------------------\n",
      "Train loss: 2.7285190313202996\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.920688746770223\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19160  --------------------------\n",
      "Train loss: 2.7645142652307237\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.907733319600423\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19170  --------------------------\n",
      "Train loss: 2.7629618665150235\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.849855442047119\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19180  --------------------------\n",
      "Train loss: 2.7169904657772608\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.936222219467163\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19190  --------------------------\n",
      "Train loss: 2.730257078749793\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.795955541928609\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19200  --------------------------\n",
      "Train loss: 2.7791666102409365\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.817833148638408\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19210  --------------------------\n",
      "Train loss: 2.721342814649854\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.942322149276733\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19220  --------------------------\n",
      "Train loss: 2.768238081250872\n",
      "Train accuracy: 0.9442857142857143\n",
      "Test loss: 7.844344422022502\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19230  --------------------------\n",
      "Train loss: 2.7555666211673193\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.766833311716716\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19240  --------------------------\n",
      "Train loss: 2.7840380440439496\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.883711099624634\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19250  --------------------------\n",
      "Train loss: 2.749242844241006\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 8.022555602391561\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19260  --------------------------\n",
      "Train loss: 2.7961047557422094\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.956333230336507\n",
      "Test accuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19270  --------------------------\n",
      "Train loss: 2.781095220361437\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.880833346048991\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19280  --------------------------\n",
      "Train loss: 2.7461571529933386\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.7562999947865805\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19290  --------------------------\n",
      "Train loss: 2.774704773085458\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.882988850275676\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19300  --------------------------\n",
      "Train loss: 2.771309474876949\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.799122145970663\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19310  --------------------------\n",
      "Train loss: 2.7724428360802786\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.03740001042684\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19320  --------------------------\n",
      "Train loss: 2.766447606767927\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.968644278844198\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19330  --------------------------\n",
      "Train loss: 2.8045095109939577\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.8320444901784265\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19340  --------------------------\n",
      "Train loss: 2.7798522979872566\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.869533332188924\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19350  --------------------------\n",
      "Train loss: 2.7376476189068386\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.176444524129233\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19360  --------------------------\n",
      "Train loss: 2.746180920600891\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.943666725158692\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19370  --------------------------\n",
      "Train loss: 2.72560474055154\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.751455478668213\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19380  --------------------------\n",
      "Train loss: 2.770271386759622\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.910244329770406\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19390  --------------------------\n",
      "Train loss: 2.749685661452157\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.749122320810954\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19400  --------------------------\n",
      "Train loss: 2.7198618728773933\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.777410977681478\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19410  --------------------------\n",
      "Train loss: 2.7605475868497575\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.885744450887044\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19420  --------------------------\n",
      "Train loss: 2.747971384865897\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 8.005511067708333\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19430  --------------------------\n",
      "Train loss: 2.758076152460916\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.852377713521322\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19440  --------------------------\n",
      "Train loss: 2.7285475833075385\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.740977767308553\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  19450  --------------------------\n",
      "Train loss: 2.7518142114366806\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.8607000096638995\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19460  --------------------------\n",
      "Train loss: 2.7504190492630003\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.745055567423503\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19470  --------------------------\n",
      "Train loss: 2.8315523317881994\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.95837781906128\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19480  --------------------------\n",
      "Train loss: 2.748052320820945\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.77744436899821\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19490  --------------------------\n",
      "Train loss: 2.7334428559030806\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.88843322912852\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19500  --------------------------\n",
      "Train loss: 2.748419031756265\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.883477681477864\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19510  --------------------------\n",
      "Train loss: 2.7062237954139707\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.883388945261637\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19520  --------------------------\n",
      "Train loss: 2.738623799766813\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.734422299067179\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19530  --------------------------\n",
      "Train loss: 2.7926094341278076\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.936844390233357\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19540  --------------------------\n",
      "Train loss: 2.790199932370867\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.805955497423808\n",
      "Test accuracy: 0.89\n",
      "Epoch:  19550  --------------------------\n",
      "Train loss: 2.749252325977598\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.894133338928222\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19560  --------------------------\n",
      "Train loss: 2.742280890601022\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.836666577657064\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19570  --------------------------\n",
      "Train loss: 2.719371408735003\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.906222225824992\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19580  --------------------------\n",
      "Train loss: 2.756157148224967\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.845955521265665\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19590  --------------------------\n",
      "Train loss: 2.736252329349518\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.950477752685547\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19600  --------------------------\n",
      "Train loss: 2.714980969088418\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.775877596537272\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19610  --------------------------\n",
      "Train loss: 2.716119006701878\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.864088795979818\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19620  --------------------------\n",
      "Train loss: 2.7592666365419114\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.942388804753621\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19630  --------------------------\n",
      "Train loss: 2.7517332897867477\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.869800047874451\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19640  --------------------------\n",
      "Train loss: 2.7378142510141643\n",
      "Train accuracy: 0.9457142857142857\n",
      "Test loss: 7.880733149846395\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19650  --------------------------\n",
      "Train loss: 2.7361379991258894\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.91848876953125\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19660  --------------------------\n",
      "Train loss: 2.743709510053907\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.7844443639119465\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19670  --------------------------\n",
      "Train loss: 2.7091951979909625\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.8721555296579995\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19680  --------------------------\n",
      "Train loss: 2.773366652556828\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.935633271535238\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19690  --------------------------\n",
      "Train loss: 2.680499964100974\n",
      "Train accuracy: 0.9585714285714285\n",
      "Test loss: 7.91051108678182\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19700  --------------------------\n",
      "Train loss: 2.7618570934023174\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.854711265563965\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19710  --------------------------\n",
      "Train loss: 2.735557144709996\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.296100002924602\n",
      "Test accuracy: 0.8866666666666667\n",
      "Epoch:  19720  --------------------------\n",
      "Train loss: 2.726785707133157\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.821988957722982\n",
      "Test accuracy: 0.9133333333333333\n",
      "Epoch:  19730  --------------------------\n",
      "Train loss: 2.72143335546766\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.730989004770914\n",
      "Test accuracy: 0.92\n",
      "Epoch:  19740  --------------------------\n",
      "Train loss: 2.7468809069905964\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.838866704305013\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19750  --------------------------\n",
      "Train loss: 2.7556380612509592\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.942988761266073\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19760  --------------------------\n",
      "Train loss: 2.7391476137297492\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.860233351389567\n",
      "Test accuracy: 0.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  19770  --------------------------\n",
      "Train loss: 2.7589238003322056\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.800788911183675\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19780  --------------------------\n",
      "Train loss: 2.7506714214597427\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.919122236569723\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19790  --------------------------\n",
      "Train loss: 2.7420903955187117\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.822011165618896\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19800  --------------------------\n",
      "Train loss: 2.7134904905727932\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.841444466908773\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19810  --------------------------\n",
      "Train loss: 2.7863713802610124\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.985044275919597\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19820  --------------------------\n",
      "Train loss: 2.7755142498016356\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.835133339564005\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19830  --------------------------\n",
      "Train loss: 2.749809465408325\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.881244510014852\n",
      "Test accuracy: 0.91\n",
      "Epoch:  19840  --------------------------\n",
      "Train loss: 2.7594761432920185\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.842833251953125\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19850  --------------------------\n",
      "Train loss: 2.73943329504558\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.966788864135742\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19860  --------------------------\n",
      "Train loss: 2.712642798083169\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.744800087610881\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19870  --------------------------\n",
      "Train loss: 2.7180332694734846\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.036088873545328\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  19880  --------------------------\n",
      "Train loss: 2.7595570938927785\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.771155567169189\n",
      "Test accuracy: 0.9066666666666666\n",
      "Epoch:  19890  --------------------------\n",
      "Train loss: 2.7326047689574104\n",
      "Train accuracy: 0.9557142857142857\n",
      "Test loss: 7.723177687327067\n",
      "Test accuracy: 0.9033333333333333\n",
      "Epoch:  19900  --------------------------\n",
      "Train loss: 2.7109761602537974\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.82021118481954\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19910  --------------------------\n",
      "Train loss: 2.7377904415130616\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.8718443202972415\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19920  --------------------------\n",
      "Train loss: 2.747895202296121\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.859477694829305\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19930  --------------------------\n",
      "Train loss: 2.7597285648754664\n",
      "Train accuracy: 0.9471428571428572\n",
      "Test loss: 7.930811128616333\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19940  --------------------------\n",
      "Train loss: 2.7491142501149857\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 8.025033315022787\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19950  --------------------------\n",
      "Train loss: 2.7418237611225673\n",
      "Train accuracy: 0.9528571428571428\n",
      "Test loss: 7.913822333017985\n",
      "Test accuracy: 0.9\n",
      "Epoch:  19960  --------------------------\n",
      "Train loss: 2.7235095027514866\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 7.894577547709147\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19970  --------------------------\n",
      "Train loss: 2.7315142498697553\n",
      "Train accuracy: 0.9542857142857143\n",
      "Test loss: 8.121466627120972\n",
      "Test accuracy: 0.8933333333333333\n",
      "Epoch:  19980  --------------------------\n",
      "Train loss: 2.761242803164891\n",
      "Train accuracy: 0.9485714285714286\n",
      "Test loss: 7.93277769724528\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  19990  --------------------------\n",
      "Train loss: 2.7545094844273157\n",
      "Train accuracy: 0.9514285714285714\n",
      "Test loss: 7.846010974248251\n",
      "Test accuracy: 0.8966666666666666\n",
      "Epoch:  20000  --------------------------\n",
      "Train loss: 2.7217999410629274\n",
      "Train accuracy: 0.95\n",
      "Test loss: 7.964222329457601\n",
      "Test accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "train_losses=[]\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "for epoch in range(20001):\n",
    "    net.train()\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "    loss_train = 0\n",
    "    for i, (tact, target, label) in enumerate(train_loader):\n",
    "        \n",
    "        tact = tact.to(device)\n",
    "        target = target.to(device)\n",
    "        #print(tact.shape)\n",
    "        #tact = tact.permute(0, 3, 1, 2, 4)\n",
    "#         print(tact.shape)\n",
    "        tact = net.get_spike(tact)\n",
    "        tact_new = torch.zeros((tact.shape[0],tact.shape[1],1,1,tact.shape[-1]*2)).to(device)\n",
    "        tact_new[...,::2]  = tact\n",
    "        \n",
    "        output = net.forward(tact_new)\n",
    "        correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "        num_samples += len(label)\n",
    "        loss = error.numSpikes(output, target)\n",
    "        loss_train += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "                \n",
    "    if epoch%10 == 0:\n",
    "        print('Epoch: ', epoch, ' --------------------------')\n",
    "        print('Train loss:', loss_train/len(train_dataset))\n",
    "        print('Train accuracy:', correct/len(train_dataset))\n",
    "    train_accs.append(correct/len(train_dataset))\n",
    "    train_losses.append(loss_train/len(train_dataset))\n",
    "        \n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    num_samples = 0\n",
    "    loss_test = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (tact, target, label) in enumerate(test_loader):\n",
    "\n",
    "            tact = tact.to(device)\n",
    "            #tact = tact.permute(0, 3, 1, 2, 4)\n",
    "            target = target.to(device)\n",
    "            tact = net.get_spike(tact)\n",
    "            tact_new = torch.zeros((tact.shape[0],tact.shape[1],1,1,tact.shape[-1]*2)).to(device)\n",
    "            tact_new[...,::2]  = tact\n",
    "        \n",
    "            output = net.forward(tact_new)\n",
    "            correct += torch.sum(snn.predict.getClass(output) == label).data.item()\n",
    "            num_samples += len(label)\n",
    "            loss = error.numSpikes(output, target)\n",
    "            loss_test += loss.item()\n",
    "            \n",
    "    if epoch%10 == 0:\n",
    "        print('Test loss:', loss_test/len(test_dataset))\n",
    "        print('Test accuracy:', correct/len(test_dataset))\n",
    "    test_accs.append(correct/len(test_dataset))\n",
    "    test_losses.append(loss_test/len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, figsize=(15,7))\n",
    "\n",
    "ax[0].plot(train_losses)\n",
    "ax[0].plot(test_losses)\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].legend(['Train', 'Test'])\n",
    "\n",
    "ax[1].plot(train_accs)\n",
    "ax[1].plot(test_accs)\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].legend(['Train', 'Test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266666666666666"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9657142857142857"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(train_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
